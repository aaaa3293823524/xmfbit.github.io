<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>来呀，快活呀~</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://xmfbit.github.io/"/>
  <updated>2018-04-09T06:08:31.851Z</updated>
  <id>https://xmfbit.github.io/</id>
  
  <author>
    <name>一个脱离了高级趣味的人</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>JupyterNotebook设置Python环境</title>
    <link href="https://xmfbit.github.io/2018/04/09/set-env-in-jupyternotebook/"/>
    <id>https://xmfbit.github.io/2018/04/09/set-env-in-jupyternotebook/</id>
    <published>2018-04-09T05:44:04.000Z</published>
    <updated>2018-04-09T06:08:31.851Z</updated>
    
    <content type="html"><![CDATA[<p>使用Python时，常遇到的一个问题就是Python和库的版本不同。Anaconda的env算是解决这个问题的一个好用的方法。但是，在使用Jupyter Notebook的时候，我却发现加载的仍然是默认的Python Kernel。这篇博客记录了如何在Jupyter Notebook中也能够设置相应的虚拟环境。<br><a id="more"></a></p><h2 id="conda的虚拟环境"><a href="#conda的虚拟环境" class="headerlink" title="conda的虚拟环境"></a>conda的虚拟环境</h2><p>在Anaconda中，我们可以使用<code>conda create -n your_env_name python=your_python_version</code>的方法创建虚拟环境，并使用<code>source activate your_env_name</code>方式激活该虚拟环境，并在其中安装与默认（主）python环境不同的软件包等。</p><p>当激活该虚拟环境时，ipython下是可以正常加载的。但是打开Jupyter Notebook，会发现其加载的仍然是默认的Python kernel，而我们需要在notebook中也能使用新添加的虚拟环境。</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>解决方法见这个帖子：<a href="https://stackoverflow.com/questions/39604271/conda-environments-not-showing-up-in-jupyter-notebook" target="_blank" rel="external">Conda environments not showing up in Jupyter Notebook</a>.</p><p>首先，安装<code>nb_conda_kernels</code>包：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">conda install nb_conda_kernels</div></pre></td></tr></table></figure></p><p>然后，打开Notebook，点击<code>New</code>，会出现当前所有安装的虚拟环境以供选择，如下所示。<br><img src="/img/set-env-in-notebook-choose-kernel.png" alt="选择特定的kernel加载"></p><p>如果是已经编辑过的notebook，只需要打开该笔记本，在菜单栏中选择<code>Kernel -&gt; choose kernel -&gt; your env kernel</code>即可。<br><img src="/img/set-env-in-notebook-change-kernel.png" alt="改变当前notebook的kernel"></p><p>关于<code>nb_conda_kernels</code>的详细信息，可以参考其GitHub页面：<a href="https://github.com/Anaconda-Platform/nb_conda_kernels" target="_blank" rel="external">nb_conda_kernels</a>。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用Python时，常遇到的一个问题就是Python和库的版本不同。Anaconda的env算是解决这个问题的一个好用的方法。但是，在使用Jupyter Notebook的时候，我却发现加载的仍然是默认的Python Kernel。这篇博客记录了如何在Jupyter Notebook中也能够设置相应的虚拟环境。&lt;br&gt;
    
    </summary>
    
    
      <category term="python" scheme="https://xmfbit.github.io/tags/python/"/>
    
      <category term="tool" scheme="https://xmfbit.github.io/tags/tool/"/>
    
  </entry>
  
  <entry>
    <title>数值优化之牛顿方法</title>
    <link href="https://xmfbit.github.io/2018/04/03/newton-method/"/>
    <id>https://xmfbit.github.io/2018/04/03/newton-method/</id>
    <published>2018-04-03T13:43:16.000Z</published>
    <updated>2018-04-04T05:11:00.599Z</updated>
    
    <content type="html"><![CDATA[<p>简要介绍一下优化方法中的牛顿方法（Newton’s Method）。下面的动图demo来源于<a href="https://zh.wikipedia.org/wiki/%E7%89%9B%E9%A1%BF%E6%B3%95" target="_blank" rel="external">Wiki页面</a>。<br><img src="/img/newton-method-demo.gif" width="400" height="300" alt="牛顿法动图" align="center"><br><a id="more"></a></p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>牛顿方法，是一种用来求解方程$f(x) = 0$的根的方法。从题图可以看出它是如何使用的。</p><p>首先，需要给定根的初始值$x_0$。接下来，在函数曲线上找到其所对应的点$(x_0, f(x_0))$，并过该点做切线交$x$轴于一点$x_1$。从$x_1$出发，重复上述操作，直至收敛。</p><p>根据图上的几何关系和导数的几何意义，有：</p><script type="math/tex; mode=display">x_{n+1} = x_n - \frac{f(x_n)}{f^\prime(x_n)}</script><h2 id="优化上的应用"><a href="#优化上的应用" class="headerlink" title="优化上的应用"></a>优化上的应用</h2><p>做优化的时候，我们常常需要的是求解某个损失函数$L$的极值。在极值点处，函数的导数为$0$。所以这个问题被转换为了求解$L$的导数的零点。我们有</p><script type="math/tex; mode=display">\theta_{n+1} = \theta_n - \frac{L^\prime(\theta_n)}{L^{\prime\prime}(\theta_n)}</script><h2 id="推广到向量形式"><a href="#推广到向量形式" class="headerlink" title="推广到向量形式"></a>推广到向量形式</h2><p>机器学习中的优化问题常常是在高维空间进行，可以将其推广到向量形式：</p><script type="math/tex; mode=display">\theta_{n+1} = \theta_n - H^{-1}\nabla_\theta L(\theta_n)</script><p>其中，$H$表示海森矩阵，是一个$n\times n$的矩阵，其中元素为：</p><script type="math/tex; mode=display">H_{ij} = \frac{\partial^2 L}{\partial \theta_i \partial \theta_j}</script><p>特别地，当海森矩阵为正定时，此时的极值为极小值（可以使用二阶的泰勒展开式证明）。</p><p>PS:忘了什么是正定矩阵了吗？想想二次型的概念，对于$\forall x$不为$0$向量，都有$x^THx &gt; 0$。</p><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>牛顿方法的收敛速度较SGD为快（二阶收敛），但是会涉及到求解一个$n\times n$的海森矩阵的逆，所以虽然需要的迭代次数更少，但反而可能比较耗时（$n$的大小）。</p><h2 id="L-BFGS"><a href="#L-BFGS" class="headerlink" title="L-BFGS"></a>L-BFGS</h2><p>由于牛顿方法中需要计算海森矩阵的逆，所以很多时候并不实用。大家就想出了一些近似计算$H^{-1}$的方法，如L-BFGS等。</p><p><em>推导过程待续。。。</em></p><p>L-BFGS的资料网上还是比较多的，这里有一个PyTorch中L-BFGS方法的实现：<a href="https://github.com/pytorch/pytorch/blob/master/torch/optim/lbfgs.py" target="_blank" rel="external">optim.lbfgs</a>。</p><p>这里有一篇不错的文章<a href="http://www.hankcs.com/ml/l-bfgs.html" target="_blank" rel="external">数值优化：理解L-BFGS算法</a>，本博客写作过程参考很多。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;简要介绍一下优化方法中的牛顿方法（Newton’s Method）。下面的动图demo来源于&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E7%89%9B%E9%A1%BF%E6%B3%95&quot;&gt;Wiki页面&lt;/a&gt;。&lt;br&gt;&lt;img src=&quot;/img/newton-method-demo.gif&quot; width = &quot;400&quot; height = &quot;300&quot; alt=&quot;牛顿法动图&quot; align=center /&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="math" scheme="https://xmfbit.github.io/tags/math/"/>
    
  </entry>
  
  <entry>
    <title>论文 - Feature Pyramid Networks for Object Detection (FPN)</title>
    <link href="https://xmfbit.github.io/2018/04/02/paper-fpn/"/>
    <id>https://xmfbit.github.io/2018/04/02/paper-fpn/</id>
    <published>2018-04-02T02:12:03.000Z</published>
    <updated>2018-04-03T06:33:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>图像金字塔或特征金字塔是传统CV方法中常用的技巧，例如求取<a href="https://xmfbit.github.io/2017/01/30/cs131-sift/">SIFT特征</a>就用到了DoG图像金字塔。但是在Deep Learning统治下的CV detection下，这种方法变得无人问津。一个重要的问题就是计算量巨大。而本文提出了一种仅用少量额外消耗建立特征金字塔的方法，提高了detector的性能。<br><a id="more"></a></p><h2 id="Pyramid-or-not-It’s-a-question"><a href="#Pyramid-or-not-It’s-a-question" class="headerlink" title="Pyramid or not? It’s a question."></a>Pyramid or not? It’s a question.</h2><p>在DL席卷CV之前，特征大多需要研究人员手工设计，如SIFT/Harr/HoG等。人们在使用这些特征的时候发现，往往需要使用图像金字塔，在multi scale下进行检测，才能得到不错的结果。然而，使用CNN时，由于其本身具有的一定的尺度不变性，大家常常是只在单一scale下（也就是原始图像作为输入），就可以达到不错的结果。不过很多时候参加COCO等竞赛的队伍还是会在TEST的时候使用这项技术，能够取得更好的成绩。但是这样会造成计算时间的巨大开销，TRAIN和TEST的不一致。TRAIN中引入金字塔，内存就会吃紧。所以主流的Fast/Faster RCNN并没有使用金字塔。</p><p>换个角度，我们知道在CNN中，输入会逐层处理，经过Conv/Pooling的操作后，不同深度的layer产生的feature map的spatial dimension是不一样的，这就是作者在摘要中提到的“inherent multi-scale pyramidal hierarchy of deep CNN”。不过，还有一个问题，就是深层和浅层的feature map虽然构成了一个feature pyramid，但是它们的语义并不对等：深层layer的feature map有更抽象的语义信息，而浅层feature map有较高的resolution，但是语义信息还是too yong too simple。</p><p>SSD做过这方面的探索。但是它采用的方法是从浅层layer引出，又加了一些layer，导致无法reuse high resolution的feature map。我们发现，浅层的high resolution feature map对检测小目标很有用处。</p><p>那我们想要怎样呢？</p><ul><li>高层的low resolution，strong semantic info特征如何和浅层的high resolution，weak semantic info自然地结合？</li><li>不引入过多的额外计算，最好也只需要用single scale的原始输入。</li></ul><p>用一张图总结一下。下图中蓝色的轮廓线框起来的就是不同layer输出的feature map。蓝色线越粗，代表其语义信息越强。在（a）中，是将图像做成金字塔，分别跑一个NN来做，这样计算量极大。（b）中是目前Faster RCNN等采用的方法，只在single scale上做。（c）中是直接将各个layer输出的层级feature map自然地看做feature pyramid来做。（d）是本文的方法，不同层级的feature map做了merge，能够使得每个level的语义信息都比较强（注意看蓝色线的粗细）。<br><img src="/img/paper-fpn-different-pyramids.png" alt="不同金字塔方法"></p><p>我们使用这种名为FPN的技术，不用什么工程上的小花招，就打败了目前COCO上的最好结果。不止detection，FPN也能用在图像分割上（当然，现在我们知道，MaskRCNN中的关键技术之一就是FPN）。</p><h2 id="FPN"><a href="#FPN" class="headerlink" title="FPN"></a>FPN</h2><p>有人可能会想，其实前面的网络有人也做过不同深度layer的merge啊，通过skip connection就可以了。作者指出，那种方法仍然是只能在最终的single scale的output feature map上做，而我们的方法是在all level上完成，如下图所示。<br><img src="/img/paper-fpn-different-with-related-work.png" alt="我们才是真正的金字塔"></p><h3 id="Bottom-up-pathway"><a href="#Bottom-up-pathway" class="headerlink" title="Bottom-up pathway"></a>Bottom-up pathway</h3><p> Bottom-up pathway指的是网络的前向计算部分，会产生一系列scale相差2x的feature map。当然，在这些downsample中间，还会有layer的输出spatial dimension是一致的。那些连续的有着相同spatial dimension输出的layer是一个stage。这样，我们就完成了传统金字塔方法和CNN网络的名词的对应。</p><p> 以ResNet为例，我们用每个stage中最后一个residual block的输出作为构建金字塔的feature map，也就是<code>C2~C5</code>。它们的步长分别是$4, 8, 16, 32$。我们没用<code>conv1</code>。</p><h3 id="Top-down-pathway和lateral-connection"><a href="#Top-down-pathway和lateral-connection" class="headerlink" title="Top-down pathway和lateral connection"></a>Top-down pathway和lateral connection</h3><p>Top-down pathway是指将深层的有更强语义信息的feature经过upsampling变成higher resolution的过程。然后再与bottom-up得到的feature经过lateral connection（侧边连接）进行增强。</p><p>下面这张图展示了做lateral connection的过程。注意在图中，越深的layer位于图的上部。我们以框出来放大的那部分举例子。从更深的层输出的feature经过<code>2x up</code>处理（spatial dimension一致了），从左面来的浅层的feature经过<code>1x1 conv</code>处理（channel dimension一致了），再进行element-wise的相加，得到了该stage最后用于prediction的feature（其实还要经过一个<code>3x3 conv</code>的处理，见下引文）。<br><img src="/img/paper-fpn-lateral-connection.png" alt="lateral connection"></p><p>一些细节，直接引用：</p><blockquote><p>To start the iteration, we simply attach a 1x1 convolutional layer on C5 to produce the coarsest resolution map. Finally, we append a 3x3 convolution on each merged map to generate the final feature map, which is to reduce the aliasing effect of upsampling.</p></blockquote><p>此外，由于金字塔上的所有feature共享classifier和regressor，要求它们的channel dimension必须一致。本文固定使用$256$。而且这些外的conv layer没有使用非线性激活。</p><p>这里给出一个基于PyTorch的FPN的第三方实现<a href="https://github.com/kuangliu/pytorch-fpn/blob/master/fpn.py" target="_blank" rel="external">kuangliu/pytorch-fpn</a>，可以对照论文捋一遍。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## ResNet的block</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bottleneck</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    expansion = <span class="number">4</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_planes, planes, stride=<span class="number">1</span>)</span>:</span></div><div class="line">        super(Bottleneck, self).__init__()</div><div class="line">        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=<span class="number">1</span>, bias=<span class="keyword">False</span>)</div><div class="line">        self.bn1 = nn.BatchNorm2d(planes)</div><div class="line">        self.conv2 = nn.Conv2d(planes, planes, kernel_size=<span class="number">3</span>, stride=stride, padding=<span class="number">1</span>, bias=<span class="keyword">False</span>)</div><div class="line">        self.bn2 = nn.BatchNorm2d(planes)</div><div class="line">        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=<span class="number">1</span>, bias=<span class="keyword">False</span>)</div><div class="line">        self.bn3 = nn.BatchNorm2d(self.expansion*planes)</div><div class="line"></div><div class="line">        self.shortcut = nn.Sequential()</div><div class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> in_planes != self.expansion*planes:</div><div class="line">            self.shortcut = nn.Sequential(</div><div class="line">                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="keyword">False</span>),</div><div class="line">                nn.BatchNorm2d(self.expansion*planes)</div><div class="line">            )</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        out = F.relu(self.bn1(self.conv1(x)))</div><div class="line">        out = F.relu(self.bn2(self.conv2(out)))</div><div class="line">        out = self.bn3(self.conv3(out))</div><div class="line">        out += self.shortcut(x)</div><div class="line">        out = F.relu(out)</div><div class="line">        <span class="keyword">return</span> out</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">FPN</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, block, num_blocks)</span>:</span></div><div class="line">        super(FPN, self).__init__()</div><div class="line">        self.in_planes = <span class="number">64</span></div><div class="line"></div><div class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>, bias=<span class="keyword">False</span>)</div><div class="line">        self.bn1 = nn.BatchNorm2d(<span class="number">64</span>)</div><div class="line"></div><div class="line">        <span class="comment"># Bottom-up layers, backbone of the network</span></div><div class="line">        self.layer1 = self._make_layer(block,  <span class="number">64</span>, num_blocks[<span class="number">0</span>], stride=<span class="number">1</span>)</div><div class="line">        self.layer2 = self._make_layer(block, <span class="number">128</span>, num_blocks[<span class="number">1</span>], stride=<span class="number">2</span>)</div><div class="line">        self.layer3 = self._make_layer(block, <span class="number">256</span>, num_blocks[<span class="number">2</span>], stride=<span class="number">2</span>)</div><div class="line">        self.layer4 = self._make_layer(block, <span class="number">512</span>, num_blocks[<span class="number">3</span>], stride=<span class="number">2</span>)</div><div class="line"></div><div class="line">        <span class="comment"># Top layer</span></div><div class="line">        <span class="comment"># 我们需要在C5后面接一个1x1, 256 conv，得到金字塔最顶端的feature</span></div><div class="line">        self.toplayer = nn.Conv2d(<span class="number">2048</span>, <span class="number">256</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)  <span class="comment"># Reduce channels</span></div><div class="line"></div><div class="line">        <span class="comment"># Smooth layers</span></div><div class="line">        <span class="comment"># 这个是上面引文中提到的抗aliasing的3x3卷积</span></div><div class="line">        self.smooth1 = nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</div><div class="line">        self.smooth2 = nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</div><div class="line">        self.smooth3 = nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</div><div class="line"></div><div class="line">        <span class="comment"># Lateral layers</span></div><div class="line">        <span class="comment"># 为了匹配channel dimension引入的1x1卷积</span></div><div class="line">        <span class="comment"># 注意这些backbone之外的extra conv，输出都是256 channel</span></div><div class="line">        self.latlayer1 = nn.Conv2d(<span class="number">1024</span>, <span class="number">256</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</div><div class="line">        self.latlayer2 = nn.Conv2d( <span class="number">512</span>, <span class="number">256</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</div><div class="line">        self.latlayer3 = nn.Conv2d( <span class="number">256</span>, <span class="number">256</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_make_layer</span><span class="params">(self, block, planes, num_blocks, stride)</span>:</span></div><div class="line">        strides = [stride] + [<span class="number">1</span>]*(num_blocks<span class="number">-1</span>)</div><div class="line">        layers = []</div><div class="line">        <span class="keyword">for</span> stride <span class="keyword">in</span> strides:</div><div class="line">            layers.append(block(self.in_planes, planes, stride))</div><div class="line">            self.in_planes = planes * block.expansion</div><div class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</div><div class="line"></div><div class="line">    <span class="comment">## FPN的lateral connection部分: upsample以后，element-wise相加</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_upsample_add</span><span class="params">(self, x, y)</span>:</span></div><div class="line">        <span class="string">'''Upsample and add two feature maps.</span></div><div class="line">        Args:</div><div class="line">          x: (Variable) top feature map to be upsampled.</div><div class="line">          y: (Variable) lateral feature map.</div><div class="line">        Returns:</div><div class="line">          (Variable) added feature map.</div><div class="line">        Note in PyTorch, when input size is odd, the upsampled feature map</div><div class="line">        with `F.upsample(..., scale_factor=2, mode='nearest')`</div><div class="line">        maybe not equal to the lateral feature map size.</div><div class="line">        e.g.</div><div class="line">        original input size: [N,_,15,15] -&gt;</div><div class="line">        conv2d feature map size: [N,_,8,8] -&gt;</div><div class="line">        upsampled feature map size: [N,_,16,16]</div><div class="line">        So we choose bilinear upsample which supports arbitrary output sizes.</div><div class="line">        '''</div><div class="line">        _,_,H,W = y.size()</div><div class="line">        <span class="keyword">return</span> F.upsample(x, size=(H,W), mode=<span class="string">'bilinear'</span>) + y</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        <span class="comment"># Bottom-up</span></div><div class="line">        c1 = F.relu(self.bn1(self.conv1(x)))</div><div class="line">        c1 = F.max_pool2d(c1, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</div><div class="line">        c2 = self.layer1(c1)</div><div class="line">        c3 = self.layer2(c2)</div><div class="line">        c4 = self.layer3(c3)</div><div class="line">        c5 = self.layer4(c4)</div><div class="line">        <span class="comment"># Top-down</span></div><div class="line">        <span class="comment"># P5: 金字塔最顶上的feature</span></div><div class="line">        p5 = self.toplayer(c5)</div><div class="line">        <span class="comment"># P4: 上一层 p5 + 侧边来的 c4</span></div><div class="line">        <span class="comment"># 其余同理</span></div><div class="line">        p4 = self._upsample_add(p5, self.latlayer1(c4))</div><div class="line">        p3 = self._upsample_add(p4, self.latlayer2(c3))</div><div class="line">        p2 = self._upsample_add(p3, self.latlayer3(c2))</div><div class="line">        <span class="comment"># Smooth</span></div><div class="line">        <span class="comment"># 输出做一下smooth</span></div><div class="line">        p4 = self.smooth1(p4)</div><div class="line">        p3 = self.smooth2(p3)</div><div class="line">        p2 = self.smooth3(p2)</div><div class="line">        <span class="keyword">return</span> p2, p3, p4, p5</div></pre></td></tr></table></figure></p><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>下面作者会把FPN应用到FasterRCNN的两个重要步骤：RPN和Fast RCNN。</p><h3 id="FPN加持的RPN"><a href="#FPN加持的RPN" class="headerlink" title="FPN加持的RPN"></a>FPN加持的RPN</h3><p>在Faster RCNN中，RPN用来提供ROI的proposal。backbone网络输出的single feature map上接了$3\times 3$大小的卷积核来实现sliding window的功能，后面接两个$1\times 1$的卷积分别用来做objectness的分类和bounding box基于anchor box的回归。我们把最后的classifier和regressor部分叫做head。</p><p>使用FPN时，我们在金字塔每层的输出feature map上都接上这样的head结构（$3\times 3$的卷积 + two sibling $1\times 1$的卷积）。同时，我们不再使用多尺度的anchor box，而是在每个level上分别使用不同大小的anchor box。具体说，对应于特征金字塔的$5$个level的特征，<code>P2 - P6</code>，anchor box的大小分别是$32^2, 64^2, 128^2, 256^2, 512^2$。不过每层的anchor box仍然要照顾到不同的长宽比例，我们使用了$3$个不同的比例：$1:2, 1:1, 2:1$（和原来一样）。这样，我们一共有$5\times 3 = 15$个anchor box。</p><p>训练过程中，我们需要给anchor boxes赋上对应的正负标签。对于那些与ground truth有最大IoU或者与任意一个ground truth的IoU超过$0.7$的anchor boxes，是positive label；那些与所有ground truth的IoU都小于$0.3$的是negtive label。</p><p>有一个疑问是head的参数是否要在不同的level上共享。我们试验了共享与不共享两个方法，accuracy是相近的。这也说明不同level之间语义信息是相似的，只是resolution不同。</p><h3 id="FPN加持的Fast-RCNN"><a href="#FPN加持的Fast-RCNN" class="headerlink" title="FPN加持的Fast RCNN"></a>FPN加持的Fast RCNN</h3>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;图像金字塔或特征金字塔是传统CV方法中常用的技巧，例如求取&lt;a href=&quot;https://xmfbit.github.io/2017/01/30/cs131-sift/&quot;&gt;SIFT特征&lt;/a&gt;就用到了DoG图像金字塔。但是在Deep Learning统治下的CV detection下，这种方法变得无人问津。一个重要的问题就是计算量巨大。而本文提出了一种仅用少量额外消耗建立特征金字塔的方法，提高了detector的性能。&lt;br&gt;
    
    </summary>
    
    
      <category term="deep learning" scheme="https://xmfbit.github.io/tags/deep-learning/"/>
    
      <category term="paper" scheme="https://xmfbit.github.io/tags/paper/"/>
    
      <category term="detection" scheme="https://xmfbit.github.io/tags/detection/"/>
    
  </entry>
  
  <entry>
    <title>论文 - YOLO v3</title>
    <link href="https://xmfbit.github.io/2018/04/01/paper-yolov3/"/>
    <id>https://xmfbit.github.io/2018/04/01/paper-yolov3/</id>
    <published>2018-04-01T08:48:45.000Z</published>
    <updated>2018-04-02T05:21:27.536Z</updated>
    
    <content type="html"><![CDATA[<p>YOLO的作者又放出了V3版本，在之前的版本上做出了一些改进，达到了更好的性能。这篇博客介绍这篇论文：<a href="https://pjreddie.com/media/files/papers/YOLOv3.pdf" target="_blank" rel="external">YOLOv3: An Incremental Improvement</a>。下面这张图是YOLO V3与RetinaNet的比较。<br><img src="/img/paper-yolov3-comparison-retinanet.png" alt="YOLO v3和RetinaNet的比较"></p><p>可以使用搜索功能，在本博客内搜索YOLO前作的论文阅读和代码。<br><a id="more"></a></p><h2 id="YOLO-v3比你们不知道高到哪里去了"><a href="#YOLO-v3比你们不知道高到哪里去了" class="headerlink" title="YOLO v3比你们不知道高到哪里去了"></a>YOLO v3比你们不知道高到哪里去了</h2><p>YOLO v3在保持其一贯的检测速度快的特点前提下，性能又有了提升：输入图像为$320\times 320$大小的图像，可以在$22$ms跑完，mAP达到了$28.2$，这个数据和SSD相同，但是快了$3$倍。在TitanX上，YOLO v3可以在$51$ms内完成，$AP_{50}$的值为$57.9$。而RetinaNet需要$198$ms，$AP_{50}$近似却略低，为$57.5$。</p><h3 id="ps：啥是AP"><a href="#ps：啥是AP" class="headerlink" title="ps：啥是AP"></a>ps：啥是AP</h3><p>AP就是average precision啦。在detection中，我们认为当预测的bounding box和ground truth的IoU大于某个阈值（如取为$0.5$）时，认为是一个True Positive。如果小于这个阈值，就是一个False Positive。</p><p>所谓precision，就是指检测出的框框中有多少是True Positive。另外，还有一个指标叫做recall，是指所有的ground truth里面，有多少被检测出来了。这两个概念都是来自于classification问题，通过设定上面IoU的阈值，就可以迁移到detection中了。</p><p>我们可以取不同的阈值，这样就可以绘出一条precisio vs recall的曲线，计算曲线下的面积，就是AP值。COCO中使用了<code>0.5:0.05:0.95</code>十个离散点近似计算（参考<a href="http://cocodataset.org/#detections-eval" target="_blank" rel="external">COCO的说明文档网页</a>）。detection中常常需要同时检测图像中多个类别的物体，我们将不同类别的AP求平均，就是mAP。</p><p>如果我们只看某个固定的阈值，如$0.5$，计算所有类别的平均AP，那么就用$AP_{50}$来表示。所以YOLO v3单拿出来$AP_{50}$说事，是为了证明虽然我的bounding box不如你RetinaNet那么精准（IoU相对较小），但是如果你对框框的位置不是那么敏感（$0.5$的阈值很多时候够用了），那么我是可以做到比你更好更快的。</p><h2 id="Bounding-Box位置的回归"><a href="#Bounding-Box位置的回归" class="headerlink" title="Bounding Box位置的回归"></a>Bounding Box位置的回归</h2><p>这里和原来v2基本没区别。仍然使用聚类产生anchor box的长宽（下式的$p_w$和$p_h$）。网络预测四个值：$t_x$，$t_y$，$t_w$，$t_h$。我们知道，YOLO网络最后输出是一个$M\times M$的feature map，对应于$M \times M$个cell。如果某个cell距离image的top left corner距离为$(c_x, c_y)$（也就是cell的坐标），那么该cell内的bounding box的位置和形状参数为：</p><script type="math/tex; mode=display">\begin{aligned}b_x &= \sigma(t_x) + c_x\\ b_y &= \sigma(t_y) + c_y\\ b_w &= p_w e^{t_w}\\ b_h &= p_h e^{t_h}\end{aligned}</script><p>PS：这里有一个问题，不管FasterRCNN还是YOLO，都不是直接回归bounding box的长宽（就像这样：$b_w = p_w t_w^\prime$），而是要做一个对数变换，实际预测的是$\log(\cdot)$。这里小小解释一下。</p><p>这是因为如果不做变换，直接预测相对形变$t_w^\prime$，那么要求$t_w^\prime &gt; 0$，因为你的框框的长宽不可能是负数。这样，是在做一个有不等式条件约束的优化问题，没法直接用SGD来做。所以先取一个对数变换，将其不等式约束去掉，就可以了。</p><p><img src="/img/paper=yolov3-bbox-regression.png" alt="bounding box的回归"></p><p>在训练的时候，使用平方误差损失。</p><p>另外，YOLO会对每个bounding box给出是否是object的置信度预测，用来区分objects和背景。这个值使用logistic回归。当某个bounding box与ground truth的IoU大于其他所有bounding box时，target给$1$；如果某个bounding box不是IoU最大的那个，但是IoU也大于了某个阈值（我们取$0.5$），那么我们忽略它（既不惩罚，也不奖励），这个做法是从Faster RCNN借鉴的。我们对每个ground truth只分配一个最好的bounding box与其对应（这与Faster RCNN不同）。如果某个bounding box没有倍assign到任何一个ground truth对应，那么它对边框位置大小的回归和class的预测没有贡献，我们只惩罚它的objectness，即试图减小其confidence。</p><h2 id="分类预测"><a href="#分类预测" class="headerlink" title="分类预测"></a>分类预测</h2><p>我们不用softmax做分类了，而是使用独立的logisitc做二分类。这种方法的好处是可以处理重叠的多标签问题，如Open Image Dataset。在其中，会出现诸如<code>Woman</code>和<code>Person</code>这样的重叠标签。</p><h2 id="FPN加持的多尺度预测"><a href="#FPN加持的多尺度预测" class="headerlink" title="FPN加持的多尺度预测"></a>FPN加持的多尺度预测</h2><p>之前YOLO的一个弱点就是缺少多尺度变换，使用<a href="https://arxiv.org/abs/1612.03144" target="_blank" rel="external">FPN</a>中的思路，v3在$3$个不同的尺度上做预测。在COCO上，我们每个尺度都预测$3$个框框，所以一共是$9$个。所以输出的feature map的大小是$N\times N\times [3\times (4+1+80)]$。</p><p>然后我们从两层前那里拿feature map，upsample 2x，并与更前面输出的feature map通过element-wide的相加做merge。这样我们能够从后面的层拿到更多的高层语义信息，也能从前面的层拿到细粒度的信息（更大的feature map，更小的感受野）。然后在后面接一些conv做处理，最终得到和上面相似大小的feature map，只不过spatial dimension变成了$2$倍。</p><p>照上一段所说方法，再一次在final scale尺度下给出预测。</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>在v3中，作者新建了一个名为<code>yolo</code>的layer，其参数如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[yolo]</div><div class="line">mask = 0,1,2</div><div class="line">## 9组anchor对应9个框框</div><div class="line">anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326</div><div class="line">classes=20   ## VOC20类</div><div class="line">num=9</div><div class="line">jitter=.3</div><div class="line">ignore_thresh = .5</div><div class="line">truth_thresh = 1</div><div class="line">random=1</div></pre></td></tr></table></figure></p><p>打开<code>yolo_layer.c</code>文件，找到<code>forward</code><a href="">部分代码</a>。可以看到，首先，对输入进行activation。注意，如论文所说，对类别进行预测的时候，没有使用v2中的softmax或softmax tree，而是直接使用了logistic变换。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> (b = <span class="number">0</span>; b &lt; l.batch; ++b)&#123;</div><div class="line">    <span class="keyword">for</span>(n = <span class="number">0</span>; n &lt; l.n; ++n)&#123;</div><div class="line">        <span class="keyword">int</span> index = entry_index(l, b, n*l.w*l.h, <span class="number">0</span>);</div><div class="line">        <span class="comment">// 对 tx, ty进行logistic变换</span></div><div class="line">        activate_array(l.output + index, <span class="number">2</span>*l.w*l.h, LOGISTIC);</div><div class="line">        index = entry_index(l, b, n*l.w*l.h, <span class="number">4</span>);</div><div class="line">        <span class="comment">// 对confidence和C类进行logistic变换</span></div><div class="line">        activate_array(l.output + index, (<span class="number">1</span>+l.classes)*l.w*l.h, LOGISTIC);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><p>我们看一下如何计算梯度。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; l.h; ++j) &#123;</div><div class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; l.w; ++i) &#123;</div><div class="line">        <span class="keyword">for</span> (n = <span class="number">0</span>; n &lt; l.n; ++n) &#123;</div><div class="line">            <span class="comment">// 对每个预测的bounding box</span></div><div class="line">            <span class="comment">// 找到与其IoU最大的ground truth</span></div><div class="line">            <span class="keyword">int</span> box_index = entry_index(l, b, n*l.w*l.h + j*l.w + i, <span class="number">0</span>);</div><div class="line">            box pred = get_yolo_box(l.output, l.biases, l.mask[n], box_index, i, j, l.w, l.h, net.w, net.h, l.w*l.h);</div><div class="line">            <span class="keyword">float</span> best_iou = <span class="number">0</span>;</div><div class="line">            <span class="keyword">int</span> <span class="keyword">best_t</span> = <span class="number">0</span>;</div><div class="line">            <span class="keyword">for</span>(t = <span class="number">0</span>; t &lt; l.max_boxes; ++t)&#123;</div><div class="line">                box truth = float_to_box(net.truth + t*(<span class="number">4</span> + <span class="number">1</span>) + b*l.truths, <span class="number">1</span>);</div><div class="line">                <span class="keyword">if</span>(!truth.x) <span class="keyword">break</span>;</div><div class="line">                <span class="keyword">float</span> iou = box_iou(pred, truth);</div><div class="line">                <span class="keyword">if</span> (iou &gt; best_iou) &#123;</div><div class="line">                    best_iou = iou;</div><div class="line">                    <span class="keyword">best_t</span> = t;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">int</span> obj_index = entry_index(l, b, n*l.w*l.h + j*l.w + i, <span class="number">4</span>);</div><div class="line">            avg_anyobj += l.output[obj_index];</div><div class="line">            <span class="comment">// 计算梯度</span></div><div class="line">            <span class="comment">// 如果大于ignore_thresh, 那么忽略</span></div><div class="line">            <span class="comment">// 如果小于ignore_thresh，target = 0</span></div><div class="line">            <span class="comment">// diff = -gradient = target - output</span></div><div class="line">            <span class="comment">// 为什么是上式，见下面的数学分析</span></div><div class="line">            l.delta[obj_index] = <span class="number">0</span> - l.output[obj_index];</div><div class="line">            <span class="keyword">if</span> (best_iou &gt; l.ignore_thresh) &#123;</div><div class="line">                l.delta[obj_index] = <span class="number">0</span>;</div><div class="line">            &#125;</div><div class="line">            <span class="comment">// 这里仍然有疑问，为何使用truth_thresh?这个值是1</span></div><div class="line">            <span class="comment">// 按道理，iou无论如何不可能大于1啊。。。</span></div><div class="line">            <span class="keyword">if</span> (best_iou &gt; l.truth_thresh) &#123;</div><div class="line">                <span class="comment">// confidence target = 1</span></div><div class="line">                l.delta[obj_index] = <span class="number">1</span> - l.output[obj_index];</div><div class="line">                <span class="keyword">int</span> <span class="keyword">class</span> = net.truth[<span class="keyword">best_t</span>*(<span class="number">4</span> + <span class="number">1</span>) + b*l.truths + <span class="number">4</span>];</div><div class="line">                <span class="keyword">if</span> (l.<span class="built_in">map</span>) <span class="keyword">class</span> = l.<span class="built_in">map</span>[<span class="keyword">class</span>];</div><div class="line">                <span class="keyword">int</span> class_index = entry_index(l, b, n*l.w*l.h + j*l.w + i, <span class="number">4</span> + <span class="number">1</span>);</div><div class="line">                <span class="comment">// 对class进行求导</span></div><div class="line">                delta_yolo_class(l.output, l.delta, class_index, <span class="keyword">class</span>, l.classes, l.w*l.h, <span class="number">0</span>);</div><div class="line">                box truth = float_to_box(net.truth + <span class="keyword">best_t</span>*(<span class="number">4</span> + <span class="number">1</span>) + b*l.truths, <span class="number">1</span>);</div><div class="line">                <span class="comment">// 对box位置参数进行求导</span></div><div class="line">                delta_yolo_box(truth, l.output, l.biases, l.mask[n], box_index, i, j, l.w, l.h, net.w, net.h, l.delta, (<span class="number">2</span>-truth.w*truth.h), l.w*l.h);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><p>我们首先来说一下为何confidence（包括后面的classification）的<code>diff</code>计算为何是<code>target - output</code>的形式。对于logistic regression，假设logistic函数的输入是$o = f(x;\theta)$。其中，$\theta$是网络的参数。那么输出$y = h(o)$，其中$h$指logistic激活函数（或sigmoid函数）。那么，我们有：</p><script type="math/tex; mode=display">\begin{aligned}P(y=1|x) &= h(o)\\ P(y=0|x) &= 1-h(o)\end{aligned}</script><p>写出对数极大似然函数，我们有：</p><script type="math/tex; mode=display">\log L = \sum y\log h+(1-y)\log(1-h)</script><p>为了使用SGD，上式两边取相反数，我们有损失函数：</p><script type="math/tex; mode=display">J = -\log L = \sum -y\log h-(1-y)\log(1-h)</script><p>对第$i$个输入$o_i$求导，我们有：</p><script type="math/tex; mode=display">\begin{aligned}\frac{\partial J}{\partial o_i} &= \frac{\partial J}{\partial h_i}\frac{\partial h_i}{\partial o_i}\\&= [-y_i/h_i-(y_i-1)/(1-h_i)] \frac{\partial h_i}{\partial o_i} \\&= \frac{h_i-y_i}{h_i(1-h_i)} \frac{\partial h_i}{\partial o_i}\end{aligned}</script><p>根据logistic函数的求导性质，有：</p><script type="math/tex; mode=display">\frac{\partial h_i}{\partial o_i} = h_i(1-h_i)</script><p>所以，有</p><script type="math/tex; mode=display">\frac{\partial J}{\partial o_i} = h_i-y_i</script><p>其中，$h_i$即为logistic激活后的输出，$y_i$为target。由于YOLO代码中均使用<code>diff</code>，也就是<code>-gradient</code>，所以有<code>delta = target - output</code>。</p><p>关于logistic回归，还可以参考我的博客：<a href="https://xmfbit.github.io/2018/03/21/cs229-supervised-learning/">CS229 简单的监督学习方法</a>。</p><p>下面，我们看下两个关键的子函数，<code>delta_yolo_class</code>和<code>delta_yolo_box</code>的实现。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// class是类别的ground truth</span></div><div class="line"><span class="comment">// classes是类别总数</span></div><div class="line"><span class="comment">// index是feature map一维数组里面class prediction的起始索引</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">delta_yolo_class</span><span class="params">(<span class="keyword">float</span> *output, <span class="keyword">float</span> *delta, <span class="keyword">int</span> index, </span></span></div><div class="line">  <span class="keyword">int</span> <span class="keyword">class</span>, <span class="keyword">int</span> classes, <span class="keyword">int</span> stride, <span class="keyword">float</span> *avg_cat) &#123;</div><div class="line">    <span class="keyword">int</span> n;</div><div class="line">    <span class="comment">// 这里暂时不懂</span></div><div class="line">    <span class="keyword">if</span> (delta[index])&#123;</div><div class="line">        delta[index + stride*<span class="keyword">class</span>] = <span class="number">1</span> - output[index + stride*<span class="keyword">class</span>];</div><div class="line">        <span class="keyword">if</span>(avg_cat) *avg_cat += output[index + stride*<span class="keyword">class</span>];</div><div class="line">        <span class="keyword">return</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">for</span>(n = <span class="number">0</span>; n &lt; classes; ++n)&#123;</div><div class="line">        <span class="comment">// 见上，diff = target - prediction</span></div><div class="line">        delta[index + stride*n] = ((n == <span class="keyword">class</span>)?<span class="number">1</span> : <span class="number">0</span>) - output[index + stride*n];</div><div class="line">        <span class="keyword">if</span>(n == <span class="keyword">class</span> &amp;&amp; avg_cat) *avg_cat += output[index + stride*n];</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// box delta这里没什么可说的，就是square error的求导</span></div><div class="line"><span class="function"><span class="keyword">float</span> <span class="title">delta_yolo_box</span><span class="params">(box truth, <span class="keyword">float</span> *x, <span class="keyword">float</span> *biases, <span class="keyword">int</span> n, </span></span></div><div class="line">  <span class="keyword">int</span> index, <span class="keyword">int</span> i, <span class="keyword">int</span> j, <span class="keyword">int</span> lw, <span class="keyword">int</span> lh, <span class="keyword">int</span> w, <span class="keyword">int</span> h, </div><div class="line">  <span class="keyword">float</span> *delta, <span class="keyword">float</span> scale, <span class="keyword">int</span> stride) &#123;</div><div class="line">    box pred = get_yolo_box(x, biases, n, index, i, j, lw, lh, w, h, stride);</div><div class="line">    <span class="keyword">float</span> iou = box_iou(pred, truth);</div><div class="line">    <span class="keyword">float</span> tx = (truth.x*lw - i);</div><div class="line">    <span class="keyword">float</span> ty = (truth.y*lh - j);</div><div class="line">    <span class="keyword">float</span> tw = <span class="built_in">log</span>(truth.w*w / biases[<span class="number">2</span>*n]);</div><div class="line">    <span class="keyword">float</span> th = <span class="built_in">log</span>(truth.h*h / biases[<span class="number">2</span>*n + <span class="number">1</span>]);</div><div class="line"></div><div class="line">    delta[index + <span class="number">0</span>*stride] = scale * (tx - x[index + <span class="number">0</span>*stride]);</div><div class="line">    delta[index + <span class="number">1</span>*stride] = scale * (ty - x[index + <span class="number">1</span>*stride]);</div><div class="line">    delta[index + <span class="number">2</span>*stride] = scale * (tw - x[index + <span class="number">2</span>*stride]);</div><div class="line">    delta[index + <span class="number">3</span>*stride] = scale * (th - x[index + <span class="number">3</span>*stride]);</div><div class="line">    <span class="keyword">return</span> iou;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><p>上面，我们遍历了每一个prediction的bounding box，下面我们还要遍历每个ground truth，根据IoU，为其分配一个最佳的匹配。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 遍历ground truth</span></div><div class="line"><span class="keyword">for</span>(t = <span class="number">0</span>; t &lt; l.max_boxes; ++t)&#123;</div><div class="line">    box truth = float_to_box(net.truth + t*(<span class="number">4</span> + <span class="number">1</span>) + b*l.truths, <span class="number">1</span>);</div><div class="line">    <span class="keyword">if</span>(!truth.x) <span class="keyword">break</span>;</div><div class="line">    <span class="comment">// 找到iou最大的那个bounding box</span></div><div class="line">    <span class="keyword">float</span> best_iou = <span class="number">0</span>;</div><div class="line">    <span class="keyword">int</span> best_n = <span class="number">0</span>;</div><div class="line">    i = (truth.x * l.w);</div><div class="line">    j = (truth.y * l.h);</div><div class="line">    box truth_shift = truth;</div><div class="line">    truth_shift.x = truth_shift.y = <span class="number">0</span>;</div><div class="line">    <span class="keyword">for</span>(n = <span class="number">0</span>; n &lt; l.total; ++n)&#123;</div><div class="line">        box pred = &#123;<span class="number">0</span>&#125;;</div><div class="line">        pred.w = l.biases[<span class="number">2</span>*n]/net.w;</div><div class="line">        pred.h = l.biases[<span class="number">2</span>*n+<span class="number">1</span>]/net.h;</div><div class="line">        <span class="keyword">float</span> iou = box_iou(pred, truth_shift);</div><div class="line">        <span class="keyword">if</span> (iou &gt; best_iou)&#123;</div><div class="line">            best_iou = iou;</div><div class="line">            best_n = n;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    <span class="keyword">int</span> mask_n = int_index(l.mask, best_n, l.n);</div><div class="line">    <span class="keyword">if</span>(mask_n &gt;= <span class="number">0</span>)&#123;</div><div class="line">        <span class="keyword">int</span> box_index = entry_index(l, b, mask_n*l.w*l.h + j*l.w + i, <span class="number">0</span>);</div><div class="line">        <span class="keyword">float</span> iou = delta_yolo_box(truth, l.output, l.biases, best_n, </div><div class="line">          box_index, i, j, l.w, l.h, net.w, net.h, l.delta, </div><div class="line">          (<span class="number">2</span>-truth.w*truth.h), l.w*l.h);</div><div class="line">        <span class="keyword">int</span> obj_index = entry_index(l, b, mask_n*l.w*l.h + j*l.w + i, <span class="number">4</span>);</div><div class="line">        avg_obj += l.output[obj_index];</div><div class="line">        <span class="comment">// 对应objectness target = 1</span></div><div class="line">        l.delta[obj_index] = <span class="number">1</span> - l.output[obj_index];</div><div class="line">        <span class="keyword">int</span> <span class="keyword">class</span> = net.truth[t*(<span class="number">4</span> + <span class="number">1</span>) + b*l.truths + <span class="number">4</span>];</div><div class="line">        <span class="keyword">if</span> (l.<span class="built_in">map</span>) <span class="keyword">class</span> = l.<span class="built_in">map</span>[<span class="keyword">class</span>];</div><div class="line">        <span class="keyword">int</span> class_index = entry_index(l, b, mask_n*l.w*l.h + j*l.w + i, <span class="number">4</span> + <span class="number">1</span>);</div><div class="line">        delta_yolo_class(l.output, l.delta, class_index, <span class="keyword">class</span>, l.classes, l.w*l.h, &amp;avg_cat);</div><div class="line">        ++count;</div><div class="line">        ++class_count;</div><div class="line">        <span class="keyword">if</span>(iou &gt; <span class="number">.5</span>) recall += <span class="number">1</span>;</div><div class="line">        <span class="keyword">if</span>(iou &gt; <span class="number">.75</span>) recall75 += <span class="number">1</span>;</div><div class="line">        avg_iou += iou;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><h2 id="Darknet网络架构"><a href="#Darknet网络架构" class="headerlink" title="Darknet网络架构"></a>Darknet网络架构</h2><p>引入了ResidualNet的思路（$3\times 3$和$1\times 1$的卷积核，shortcut连接），构建了Darknet-53网络。<br><img src="/img/paper-yolov3-darknet53.png" alt="darknet-63"></p><h2 id="YOLO的优势和劣势"><a href="#YOLO的优势和劣势" class="headerlink" title="YOLO的优势和劣势"></a>YOLO的优势和劣势</h2><p>把YOLO v3和其他方法比较，优势在于快快快。当你不太在乎IoU一定要多少多少的时候，YOLO可以做到又快又好。作者还在文章的结尾发起了这样的牢骚：</p><blockquote><p>Russakovsky et al report that that humans have a hard time distinguishing an IOU of .3 from .5! “Training humans to visually inspect a bounding box with IOU of 0.3 and distinguish it from one with IOU 0.5 is surprisingly difficult.” [16] If humans have a hard time telling the difference, how much does it matter?</p></blockquote><p>使用了多尺度预测，v3对于小目标的检测结果明显变好了。不过对于medium和large的目标，表现相对不好。这是需要后续工作进一步挖局的地方。</p><p>下面是具体的数据比较。<br><img src="/img/paper-yolov3-comparisons.png" alt="具体数据比较"></p><h2 id="我们是身经百战，见得多了"><a href="#我们是身经百战，见得多了" class="headerlink" title="我们是身经百战，见得多了"></a>我们是身经百战，见得多了</h2><p>作者还贴心地给出了什么方法没有奏效。</p><ul><li>anchor box坐标$(x, y)$的预测。预测anchor box的offset，no stable，不好。</li><li>线性offset预测，而不是logistic。精度下降。</li><li>focal loss。精度下降。</li><li>双IoU阈值，像Faster RCNN那样。效果不好。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>下面是一些可供利用的参考资料：</p><ul><li>YOLO的项目主页<a href="https://pjreddie.com/darknet/yolo/" target="_blank" rel="external">Darknet YOLO</a></li><li>作者主页上的<a href="https://pjreddie.com/media/files/papers/YOLOv3.pdf" target="_blank" rel="external">paper链接</a></li><li>知乎专栏上的<a href="https://zhuanlan.zhihu.com/p/34945787" target="_blank" rel="external">全文翻译</a></li><li>FPN论文<a href="https://arxiv.org/abs/1612.03144" target="_blank" rel="external">Feature pyramid networks for object detection</a></li><li>知乎上的解答：<a href="https://www.zhihu.com/question/41540197" target="_blank" rel="external">AP是什么，怎么计算</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;YOLO的作者又放出了V3版本，在之前的版本上做出了一些改进，达到了更好的性能。这篇博客介绍这篇论文：&lt;a href=&quot;https://pjreddie.com/media/files/papers/YOLOv3.pdf&quot;&gt;YOLOv3: An Incremental Improvement&lt;/a&gt;。下面这张图是YOLO V3与RetinaNet的比较。&lt;br&gt;&lt;img src=&quot;/img/paper-yolov3-comparison-retinanet.png&quot; alt=&quot;YOLO v3和RetinaNet的比较&quot;&gt;&lt;/p&gt;
&lt;p&gt;可以使用搜索功能，在本博客内搜索YOLO前作的论文阅读和代码。&lt;br&gt;
    
    </summary>
    
    
      <category term="deep learning" scheme="https://xmfbit.github.io/tags/deep-learning/"/>
    
      <category term="paper" scheme="https://xmfbit.github.io/tags/paper/"/>
    
      <category term="yolo" scheme="https://xmfbit.github.io/tags/yolo/"/>
    
      <category term="detection" scheme="https://xmfbit.github.io/tags/detection/"/>
    
  </entry>
  
  <entry>
    <title>论文 - SqueezeNet, AlexNet-level accuracy with 50x fewer parameters and &lt;0.5MB model size</title>
    <link href="https://xmfbit.github.io/2018/03/24/paper-squeezenet/"/>
    <id>https://xmfbit.github.io/2018/03/24/paper-squeezenet/</id>
    <published>2018-03-24T06:02:53.000Z</published>
    <updated>2018-03-26T03:18:10.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/1602.07360" target="_blank" rel="external">SqueezeNet</a>由HanSong等人提出，和AlexNet相比，用少于$50$倍的参数量，在ImageNet上实现了comparable的accuracy。比较本文和HanSoing其他的工作，可以看出，其他工作，如Deep Compression是对已有的网络进行压缩，减小模型size；而SqueezeNet是从网络设计入手，从设计之初就考虑如何使用较少的参数实现较好的性能。可以说是模型压缩的两个不同思路。</p><a id="more"></a><h2 id="模型压缩相关工作"><a href="#模型压缩相关工作" class="headerlink" title="模型压缩相关工作"></a>模型压缩相关工作</h2><p>模型压缩的好处主要有以下几点：</p><ul><li>更好的分布式训练。server之间的通信往往限制了分布式训练的提速比例，较少的网络参数能够降低对server间通信需求。</li><li>云端向终端的部署，需要更低的带宽，例如手机app更新或无人车的软件包更新。</li><li>更易于在FPGA等硬件上部署，因为它们往往都有着非常受限的片上RAM。</li></ul><p>相关工作主要有两个方向，即模型压缩和模型结构自身探索。</p><p>模型压缩方面的工作主要有，使用SVD分解，Deep Compression等。模型结构方面比较有意义的工作是GoogLeNet的Inception module（可在博客内搜索<em>Xception</em>查看Xception的作者是如何受此启发发明Xception结构的）。</p><p>本文的作者从网络设计角度出发，提出了名为SqueezeNet的网络结构，使用比AlexNet少$50$倍的参数，在ImageNet上取得了comparable的结果。此外，还探究了CNN的arch是如何影响model size和最终的accuracy的。主要从两个方面进行了探索，分别是<em>CNN microarch</em>和<em>CNN macroarch</em>。前者意为在更小的粒度上，如每一层的layer怎么设计，来考察；后者是在更为宏观的角度，如一个CNN中的不同layer该如何组织来考察。</p><p><em>PS: 吐槽：看完之后觉得基本没探索出什么太有用的可以迁移到其他地方的规律。。。只是比较了自己的SqueezeNet在不同参数下的性能，有些标题党之嫌，题目很大，但是里面的内容并不完全是这样。CNN的设计还是实验实验再实验。</em></p><h2 id="SqueezeNet"><a href="#SqueezeNet" class="headerlink" title="SqueezeNet"></a>SqueezeNet</h2><p>为了简单，下文简称<em>SNet</em>。SNet的基本组成是叫做<em>Fire</em>的module。我们知道，对于一个CONV layer，它的参数数量计算应该是：$K \times K \times M \times N$。其中，$K$是filter的spatial size，$M$和$N$分别是输入feature map和输出activation的channel size。由此，设计SNet时，作者的依据主要是以下几点：</p><ul><li>把$3\times 3$的卷积替换成$1\times 1$，相当于减小上式中的$K$。</li><li>减少$3\times 3$filter对应的输入feature map的channel，相当于减少上式的$M$。</li><li>delayed downsample。使得activation的feature map能够足够大，这样对提高accuracy有益。CNN中的downsample主要是通过CONV layer或pooling layer中stride设置大于$1$得到的，作者指出，应将这种操作尽量后移。</li></ul><blockquote><p>Our intuition is that large activation maps (due to delayed downsampling) can lead to higher classification accuracy, with all else held equal.</p></blockquote><h3 id="Fire-Module"><a href="#Fire-Module" class="headerlink" title="Fire Module"></a>Fire Module</h3><p>Fire Module是SNet的基本组成单元，如下图所示。可以分为两个部分，一个是上面的<em>squeeze</em>部分，是一组$1\times 1$的卷积，用来将输入的channel squeeze到一个较小的值。后面是<em>expand</em>部分，由$1\times 1$和$3\times 3$卷积mix起来。使用$s<em>{1 x 1}$，$e</em>{1x1}$和$e<em>{3x3}$表示squeeze和expand中两种不同卷积的channel数量，令$s</em>{1x1} &lt; e<em>{1x1} + e</em>{3x3}$，用来实现上述策略2.<br><img src="/img/paper-squeezenet-fire-module.png" alt="Fire Module示意"></p><p>下面，对照PyTorch实现的SNet代码看下Fire的实现，注意上面说的CONV后面都接了ReLU。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Fire</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, inplanes, squeeze_planes,</span></span></div><div class="line">                 expand1x1_planes, expand3x3_planes):</div><div class="line">        super(Fire, self).__init__()</div><div class="line">        self.inplanes = inplanes</div><div class="line">        <span class="comment">## squeeze 部分</span></div><div class="line">        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=<span class="number">1</span>)</div><div class="line">        self.squeeze_activation = nn.ReLU(inplace=<span class="keyword">True</span>)</div><div class="line">        <span class="comment">## expand 1x1 部分</span></div><div class="line">        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,</div><div class="line">                                   kernel_size=<span class="number">1</span>)</div><div class="line">        self.expand1x1_activation = nn.ReLU(inplace=<span class="keyword">True</span>)</div><div class="line">        <span class="comment">## expand 3x3部分</span></div><div class="line">        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,</div><div class="line">                                   kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</div><div class="line">        self.expand3x3_activation = nn.ReLU(inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        x = self.squeeze_activation(self.squeeze(x))</div><div class="line">        <span class="comment">## 将expand 部分1x1和3x3的cat到一起</span></div><div class="line">        <span class="keyword">return</span> torch.cat([</div><div class="line">            self.expand1x1_activation(self.expand1x1(x)),</div><div class="line">            self.expand3x3_activation(self.expand3x3(x))], <span class="number">1</span>)</div></pre></td></tr></table></figure></p><h3 id="SNet"><a href="#SNet" class="headerlink" title="SNet"></a>SNet</h3><p>有了Fire Module这个基础材料，我们就可以搭建SNet了。一个单独的<code>conv1</code> layer，后面接了$8$个连续的Fire Module，最后再接一个<code>conv10</code> layer。此外，在<code>conv1</code>，<code>fire4</code>, <code>fire8</code>和<code>conv10</code>后面各有一个<code>stride=2</code>的MAX Pooling layer。这些pooling的位置相对靠后，是对上述策略$3$的实践。我们还可以在不同的Fire Module中加入ResNet中的bypass结构。这样，形成了下图三种不同的SNet结构。<br><img src="/img/paper-squeezenet-macroarch.png" alt="SNet的三种形式"></p><p>一些细节：</p><ul><li>为了使得$1\times 1$和$3\times 3$的卷积核能够有相同spatial size的输出，$3\times 3$的卷积输入加了<code>padding=1</code>。</li><li>在squeeze layer和expand layer中加入了ReLU。</li><li>在<code>fire 9</code>后加入了drop ratio为$0.5$的Dropout layer。</li><li>受NIN启发，SNet中没有fc层。</li><li>更多的细节和训练参数的设置可以参考GitHub上的<a href="https://github.com/DeepScale/SqueezeNet" target="_blank" rel="external">官方repo</a>。</li></ul><p>同样的，我们可以参考PyTorch中的实现。注意下面实现了v1.0和v1.1版本，两者略有不同。v1.1版本参数更少，也能够达到v1.0的精度。</p><blockquote><p>SqueezeNet v1.1 (in this repo), which requires 2.4x less computation than SqueezeNet v1.0 without diminshing accuracy.</p></blockquote><figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SqueezeNet</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, version=<span class="number">1.0</span>, num_classes=<span class="number">1000</span>)</span>:</span></div><div class="line">        super(SqueezeNet, self).__init__()</div><div class="line">        <span class="keyword">if</span> version <span class="keyword">not</span> <span class="keyword">in</span> [<span class="number">1.0</span>, <span class="number">1.1</span>]:</div><div class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"Unsupported SqueezeNet version &#123;version&#125;:"</span></div><div class="line">                             <span class="string">"1.0 or 1.1 expected"</span>.format(version=version))</div><div class="line">        self.num_classes = num_classes</div><div class="line">        <span class="keyword">if</span> version == <span class="number">1.0</span>:</div><div class="line">            self.features = nn.Sequential(</div><div class="line">                nn.Conv2d(<span class="number">3</span>, <span class="number">96</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>),</div><div class="line">                nn.ReLU(inplace=<span class="keyword">True</span>),</div><div class="line">                nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="keyword">True</span>),</div><div class="line">                Fire(<span class="number">96</span>, <span class="number">16</span>, <span class="number">64</span>, <span class="number">64</span>),</div><div class="line">                Fire(<span class="number">128</span>, <span class="number">16</span>, <span class="number">64</span>, <span class="number">64</span>),</div><div class="line">                Fire(<span class="number">128</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>),</div><div class="line">                nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="keyword">True</span>),</div><div class="line">                Fire(<span class="number">256</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>),</div><div class="line">                Fire(<span class="number">256</span>, <span class="number">48</span>, <span class="number">192</span>, <span class="number">192</span>),</div><div class="line">                Fire(<span class="number">384</span>, <span class="number">48</span>, <span class="number">192</span>, <span class="number">192</span>),</div><div class="line">                Fire(<span class="number">384</span>, <span class="number">64</span>, <span class="number">256</span>, <span class="number">256</span>),</div><div class="line">                nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="keyword">True</span>),</div><div class="line">                Fire(<span class="number">512</span>, <span class="number">64</span>, <span class="number">256</span>, <span class="number">256</span>),</div><div class="line">            )</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            self.features = nn.Sequential(</div><div class="line">                nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</div><div class="line">                nn.ReLU(inplace=<span class="keyword">True</span>),</div><div class="line">                nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="keyword">True</span>),</div><div class="line">                Fire(<span class="number">64</span>, <span class="number">16</span>, <span class="number">64</span>, <span class="number">64</span>),</div><div class="line">                Fire(<span class="number">128</span>, <span class="number">16</span>, <span class="number">64</span>, <span class="number">64</span>),</div><div class="line">                nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="keyword">True</span>),</div><div class="line">                Fire(<span class="number">128</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>),</div><div class="line">                Fire(<span class="number">256</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>),</div><div class="line">                nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="keyword">True</span>),</div><div class="line">                Fire(<span class="number">256</span>, <span class="number">48</span>, <span class="number">192</span>, <span class="number">192</span>),</div><div class="line">                Fire(<span class="number">384</span>, <span class="number">48</span>, <span class="number">192</span>, <span class="number">192</span>),</div><div class="line">                Fire(<span class="number">384</span>, <span class="number">64</span>, <span class="number">256</span>, <span class="number">256</span>),</div><div class="line">                Fire(<span class="number">512</span>, <span class="number">64</span>, <span class="number">256</span>, <span class="number">256</span>),</div><div class="line">            )</div><div class="line">        <span class="comment"># Final convolution is initialized differently form the rest</span></div><div class="line">        final_conv = nn.Conv2d(<span class="number">512</span>, self.num_classes, kernel_size=<span class="number">1</span>)</div><div class="line">        self.classifier = nn.Sequential(</div><div class="line">            nn.Dropout(p=<span class="number">0.5</span>),</div><div class="line">            final_conv,</div><div class="line">            nn.ReLU(inplace=<span class="keyword">True</span>),</div><div class="line">            nn.AvgPool2d(<span class="number">13</span>, stride=<span class="number">1</span>)</div><div class="line">)</div></pre></td></tr></table></figure><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>把SNet和AlexNet分别经过Deep Compression，在ImageNet上测试结果如下。可以看到，未被压缩时，SNet比AlexNet少了$50$倍，accuracy是差不多的。经过压缩，SNet更是可以进一步瘦身成不到$0.5$M，比原始的AlexNet瘦身了$500+$倍。<br><img src="/img/paper-squeezenet-benchmark.png" alt="性能比较"></p><p>注意上述结果是使用HanSong的Deep Compression技术（聚类+codebook）得到的。这种方法得到的模型在通用计算平台（CPU/GPU）上的优势并不明显，需要在作者提出的EIE硬件上才能充分发挥其性能。对于线性的量化（直接用量化后的$8$位定点存储模型），<a href="http://lepsucd.com/?page_id=630" target="_blank" rel="external">Ristretto</a>实现了SNet的量化，但是有一个点的损失。</p><h2 id="Micro-Arch探索"><a href="#Micro-Arch探索" class="headerlink" title="Micro Arch探索"></a>Micro Arch探索</h2><p>所谓CNN的Micro Arch，是指如何确定各层的参数，如filter的个数，kernel size的大小等。在SNet中，主要是filter的个数，即上文提到的$s<em>{1x1}$，$e</em>{1x1}$和$e_{3x3}$。这样，$8$个Fire Module就有$24$个超参数，数量太多，我们需要加一些约束，暴露主要矛盾，把问题变简单一点。</p><p>我们设定$base_e$是第一个Fire Module的expand layer的filter个数，每隔$freq$个Fire Module，会加上$incr_e$这么多。那么任意一个Fire Module的expand layer filter的个数为$e_i = base_e + (incr_e \times \lfloor \frac{i}{freq}\rfloor)$。</p><p>在expand layer，我们有$e<em>i = e</em>{i,1x1} + e<em>{i,3x3}$，设定$pct</em>{3x3} = e_{i,3x3}/e_i$为$3\times 3$的conv占的比例。</p><p>设定$SR = s_{i,1x1} / e_i$，为squeeze和expand filter个数比例。</p><h3 id="SR的影响"><a href="#SR的影响" class="headerlink" title="SR的影响"></a>SR的影响</h3><p>$SR$于区间$[0.125, 1]$之间取，accuracy基本随着$SR$增大而提升，同时模型的size也在变大。但$SR$从$0.75$提升到$1.0$，accuracy无提升。publish的SNet使用了$SR=0.125$。<br><img src="/img/paper-squeeze-sr-impact.png" alt="SR"></p><h3 id="1X1和3x3的比例pct的影响"><a href="#1X1和3x3的比例pct的影响" class="headerlink" title="1X1和3x3的比例pct的影响"></a>1X1和3x3的比例pct的影响</h3><p>为了减少参数，我们把部分$3\times 3$的卷积换成了$1\times 1$的，构成了expand layer。那么两者的比例对模型的影响？$pct$在$[0.01, 0.99]$之间变化。同样，accuracy和model size基本都随着$pct$增大而提升。当大于$0.5$时，模型的accuracy基本无提升。<br><img src="/img/paper-squeezenet-pct-impact.png" alt="pct"></p><h2 id="Macro-Arch探索"><a href="#Macro-Arch探索" class="headerlink" title="Macro Arch探索"></a>Macro Arch探索</h2><p>这里主要讨论了是否使用ResNet中的bypass结构。<br><img src="/img/paper-squeezenet-bypass.png" alt="bypass比较"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1602.07360&quot;&gt;SqueezeNet&lt;/a&gt;由HanSong等人提出，和AlexNet相比，用少于$50$倍的参数量，在ImageNet上实现了comparable的accuracy。比较本文和HanSoing其他的工作，可以看出，其他工作，如Deep Compression是对已有的网络进行压缩，减小模型size；而SqueezeNet是从网络设计入手，从设计之初就考虑如何使用较少的参数实现较好的性能。可以说是模型压缩的两个不同思路。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>论文 - MobileNets, Efficient Convolutional Neural Networks for Mobile Vision Applications</title>
    <link href="https://xmfbit.github.io/2018/03/23/paper-mobilenet/"/>
    <id>https://xmfbit.github.io/2018/03/23/paper-mobilenet/</id>
    <published>2018-03-23T02:53:43.000Z</published>
    <updated>2018-03-26T06:05:26.339Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/1704.04861" target="_blank" rel="external">MobileNet</a>是建立在Depthwise Separable Conv基础之上的一个轻量级网络。在本论文中，作者定量计算了使用这一技术带来的计算量节省，提出了MobileNet的结构，同时提出了两个简单的超参数，可以灵活地进行模型性能和inference时间的折中。后续改进的<a href="https://arxiv.org/abs/1801.04381" target="_blank" rel="external">MobileNet v2</a>以后讨论。<br><a id="more"></a></p><h2 id="Depthwise-Separable-Conv"><a href="#Depthwise-Separable-Conv" class="headerlink" title="Depthwise Separable Conv"></a>Depthwise Separable Conv</h2><p>Depthwise Separable Conv把卷积操作拆成两个部分。第一部分，depthwise conv时，每个filter只在一个channel上进行操作。第二部分，pointwise conv是使用$1\times 1$的卷积核做channel上的combination。在Caffe等DL框架中，一般是设定卷积层的<code>group</code>参数，使其等于input的channel数来实现depthwise conv的。而pointwise conv和使用标准卷积并无不同，只是需要设置<code>kernel size = 1</code>。如下，是使用PyTorch的一个<a href="https://github.com/marvis/pytorch-mobilenet/blob/master/main.py#L67" target="_blank" rel="external">例子</a>。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_dw</span><span class="params">(inp, oup, stride)</span>:</span></div><div class="line">    <span class="keyword">return</span> nn.Sequential(</div><div class="line">        <span class="comment">## 通过设置group=input channels来实现depthwise conv</span></div><div class="line">        nn.Conv2d(inp, inp, <span class="number">3</span>, stride, <span class="number">1</span>, groups=inp, bias=<span class="keyword">False</span>),</div><div class="line">        nn.BatchNorm2d(inp),</div><div class="line">        nn.ReLU(inplace=<span class="keyword">True</span>),</div><div class="line">    </div><div class="line">        nn.Conv2d(inp, oup, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, bias=<span class="keyword">False</span>),</div><div class="line">        nn.BatchNorm2d(oup),</div><div class="line">        nn.ReLU(inplace=<span class="keyword">True</span>),</div><div class="line">    )</div></pre></td></tr></table></figure><p>这样做的好处就是能够大大减少计算量。假设原始conv的filter个数为$N$，kernel size大小为$D_k$，输入的维度为$D_F\times D_F\times M$，那么总的计算量是$D_K\times D_K\times M\times N\times D_F\times D_F$（设定<code>stride=1</code>，即输入输出的feature map在spatial两个维度上相同）。</p><p>改成上述Depthwise Separable Conv后，计算量变为两个独立操作之和，即$D_K\times D_K\times M\times D_F \times D_F + M\times N\times D_F\times D_F$，计算量是原来的$\frac{1}{N} + \frac{1}{D_K^2} &lt; 1$。<br><img src="/img/paper-mobilenet-depthwise-separable-conv.png" alt="Depthwise Separable Conv示意图"></p><p>在实际使用时，我们在两个卷积操作之间加上BN和非线性变换层，如下图所示：<br><img src="/img/paper-mobilenet-conv-unit.png" alt="Conv-BN-ReLU"></p><h2 id="MobileNet"><a href="#MobileNet" class="headerlink" title="MobileNet"></a>MobileNet</h2><p>下图展示了如何使用Depthwise Separable Conv构建MobileNet。表中的<code>dw</code>表示depthwise conv，后面接的<code>stride=1</code>的conv即为pointwise conv。可以看到，网络就是这样的单元堆叠而成的。最后使用了一个全局的均值pooling，后面接上fc-1000来做分类。<br><img src="/img/paper-mobilenet-net-arch.png" alt="body arch"></p><p>此外，作者指出目前的深度学习框架大多使用GEMM实现卷积层的计算（如Caffe等先使用im2col，再使用GEMM）。但是pointwis= conv其实不需要reordering，说明目前的框架这里还有提升的空间。（不清楚目前PyTorch，TensorFlow等对pointwise conv和depthwise conv的支持如何）</p><p>在训练的时候，一个注意的地方是，对depthwise conv layer，weight decay的参数要小，因为这层本来就没多少个参数。</p><p>这里，给出PyTorch的一个<a href="https://github.com/marvis/pytorch-mobilenet/blob/master/main.py#L78" target="_blank" rel="external">第三方实现</a>。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">self.model = nn.Sequential(</div><div class="line">    conv_bn(  <span class="number">3</span>,  <span class="number">32</span>, <span class="number">2</span>), </div><div class="line">    conv_dw( <span class="number">32</span>,  <span class="number">64</span>, <span class="number">1</span>),</div><div class="line">    conv_dw( <span class="number">64</span>, <span class="number">128</span>, <span class="number">2</span>),</div><div class="line">    conv_dw(<span class="number">128</span>, <span class="number">128</span>, <span class="number">1</span>),</div><div class="line">    conv_dw(<span class="number">128</span>, <span class="number">256</span>, <span class="number">2</span>),</div><div class="line">    conv_dw(<span class="number">256</span>, <span class="number">256</span>, <span class="number">1</span>),</div><div class="line">    conv_dw(<span class="number">256</span>, <span class="number">512</span>, <span class="number">2</span>),</div><div class="line">    conv_dw(<span class="number">512</span>, <span class="number">512</span>, <span class="number">1</span>),</div><div class="line">    conv_dw(<span class="number">512</span>, <span class="number">512</span>, <span class="number">1</span>),</div><div class="line">    conv_dw(<span class="number">512</span>, <span class="number">512</span>, <span class="number">1</span>),</div><div class="line">    conv_dw(<span class="number">512</span>, <span class="number">512</span>, <span class="number">1</span>),</div><div class="line">    conv_dw(<span class="number">512</span>, <span class="number">512</span>, <span class="number">1</span>),</div><div class="line">    conv_dw(<span class="number">512</span>, <span class="number">1024</span>, <span class="number">2</span>),</div><div class="line">    conv_dw(<span class="number">1024</span>, <span class="number">1024</span>, <span class="number">1</span>),</div><div class="line">    nn.AvgPool2d(<span class="number">7</span>),</div><div class="line">)</div><div class="line">self.fc = nn.Linear(<span class="number">1024</span>, <span class="number">1000</span>)</div></pre></td></tr></table></figure></p><h3 id="网络设计超参数的影响"><a href="#网络设计超参数的影响" class="headerlink" title="网络设计超参数的影响"></a>网络设计超参数的影响</h3><h4 id="wider？or-thinner？"><a href="#wider？or-thinner？" class="headerlink" title="wider？or thinner？"></a>wider？or thinner？</h4><p>描述网络，除了常见的深度，还有一个指标就是宽度。网络的宽度受filter个数的影响。更多的filter，说明网络更胖，提取feature的能力”看起来“就会越强。MobileNet使用一个超参数$\alpha$来实验。某个层的filter个数越多，带来的结果就是下一层filter的input channel会变多，$\alpha$就是前后input channel的数量比例。可以得到，计算量会大致变为原来的$\alpha^2$倍。</p><h4 id="resolution"><a href="#resolution" class="headerlink" title="resolution"></a>resolution</h4><p>如果输入的spatial dimension变成原来的$\rho$倍，也就是$D_F$变了，那么会对计算量带来影响。利用上面总结的计算公式不难发现，和$\alpha$一样，计算量会变成原来的$\rho^2$倍。</p><p>实际中，我们令$\alpha$和$\rho$都小于$1$，构建了更少参数的mobilenet。下面是一个具体参数设置下，网络计算量和参数数目的变化情况。<br><img src="/img/paper-mobilenet-alpha-rho-effect.png" alt="具体参数设置下的reduce情况"></p><h3 id="Depthwise-Separable-Conv真的可以？"><a href="#Depthwise-Separable-Conv真的可以？" class="headerlink" title="Depthwise Separable Conv真的可以？"></a>Depthwise Separable Conv真的可以？</h3><p>同样的网络结构，区别在于使用/不使用Depthwise Separable Conv技术，在ImageNet上的精度相差很少（使用这一技术，下降了$1$个点），但是参数和计算量却节省了很多。<br><img src="/img/paper-mobilenet-depthwise-vs-full-conv.png" alt="Depthwise Separable vs Full Convolution MobileNet"></p><h3 id="更浅的网络还是更瘦的网络"><a href="#更浅的网络还是更瘦的网络" class="headerlink" title="更浅的网络还是更瘦的网络"></a>更浅的网络还是更瘦的网络</h3><p>如果我们要缩减网络的参数，是更浅的网络更好，还是更瘦的网络更好呢？作者设计了参数和计算量相近的两个网络进行了比较，结论是相对而言，缩减网络深度不是个好主意。<br><img src="/img/paper-mobilenet-narrow-vs-shallow-net.png" alt="Narrow vs Shallow MobileNet"></p><h3 id="alpha和rho的定量影响"><a href="#alpha和rho的定量影响" class="headerlink" title="alpha和rho的定量影响"></a>alpha和rho的定量影响</h3><p>定量地比较了不同$\alpha$和$\rho$的设置下，网络的性能。$\alpha$越小，网络精度越低，而且下降速度是加快的。<br><img src="/img/paper-mobilenet-alpha-compact.png" alt="MobileNet Width Multiplier"></p><p>输入图像的resolution越小，网络精度也越低。<br><img src="/img/paper-mobilenet-rho-compact.png" alt="MobileNet Resolution"></p><h3 id="和其他网络的对比"><a href="#和其他网络的对比" class="headerlink" title="和其他网络的对比"></a>和其他网络的对比</h3><p>这里只贴出结果。一个值得注意的地方是，SqueezeNet虽然参数很少，但是计算量却很大。而MobileNet可以达到参数也很少。这是通过depthwise separable conv带来的好处。<br><img src="/img/paper-mobilenet-comparision-with-other-model.png" alt="与其他主流模型的比较"></p><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>接下来，论文讨论了MobileNet在多种不同任务上的表现，证明了它的泛化能力和良好表现。可以在网上找到很多基于MobileNet的detection，classification等的开源项目代码，这里就不再多说了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1704.04861&quot;&gt;MobileNet&lt;/a&gt;是建立在Depthwise Separable Conv基础之上的一个轻量级网络。在本论文中，作者定量计算了使用这一技术带来的计算量节省，提出了MobileNet的结构，同时提出了两个简单的超参数，可以灵活地进行模型性能和inference时间的折中。后续改进的&lt;a href=&quot;https://arxiv.org/abs/1801.04381&quot;&gt;MobileNet v2&lt;/a&gt;以后讨论。&lt;br&gt;
    
    </summary>
    
    
      <category term="deep learning" scheme="https://xmfbit.github.io/tags/deep-learning/"/>
    
      <category term="paper" scheme="https://xmfbit.github.io/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>论文 - Xception, Deep Learning with Depthwise separable Convolution</title>
    <link href="https://xmfbit.github.io/2018/03/22/paper-xception/"/>
    <id>https://xmfbit.github.io/2018/03/22/paper-xception/</id>
    <published>2018-03-22T01:44:38.000Z</published>
    <updated>2018-03-24T06:06:52.599Z</updated>
    
    <content type="html"><![CDATA[<p>在MobileNet, ShuffleMet等轻量级网络中，<strong>depthwise separable conv</strong>是一个很流行的设计。借助<a href="https://arxiv.org/abs/1610.02357" target="_blank" rel="external">Xception: Deep Learning with Depthwise separable Convolution</a>，对这种分解卷积的思路做一个总结。<br><a id="more"></a></p><h2 id="起源"><a href="#起源" class="headerlink" title="起源"></a>起源</h2><p>自从AlexNet以来，DNN的网络设计经过了ZFNet-&gt;VGGNet-&gt;GoogLeNet-&gt;ResNet等几个发展阶段。本文作者的思路正是受GoogLeNet中Inception结构启发。Inception结构是最早有别于VGG等“直筒型”结构的网络module。以Inception V3为例，一个典型的Inception模块长下面这个样子：<br><img src="/img/paper-xception-inception-module.png" alt="一个典型的Inception结构"></p><p>对于一个CONV层来说，它要学习的是一个$3D$的filter，包括两个空间维度（spatial dimension），即width和height；以及一个channel dimension。这个filter和输入在$3$个维度上进行卷积操作，得到最终的输出。可以用伪代码表示如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">// 对于第i个filter</div><div class="line">// 计算输入中心点(x, y)对应的卷积结果</div><div class="line">sum = 0</div><div class="line">for c in 1:C</div><div class="line">  for h in 1:K</div><div class="line">    for w in 1:K</div><div class="line">      sum += in[c, y-K/2+h, x-K/2+w] * filter_i[c, h, w]</div><div class="line">out[i, y, x] = sum</div></pre></td></tr></table></figure></p><p>可以看到，在$3D$卷积中，channel这个维度和spatial的两个维度并无不同。</p><p>在Inception中，卷积操作更加轻量级。输入首先被$1\times 1$的卷积核处理，得到了跨channel的组合(cross-channel correlation)，同时将输入的channel dimension减少了$3\sim 4$倍（一会$4$个支路要做<code>concat</code>操作）。这个结果被后续的$3\times 3$卷积和$5\times 5$卷积核处理，处理方法和普通的卷积一样，见上。</p><p>由此作者想到，Inception能够work证明后面的一条假设就是：卷积的channel相关性和spatial相关性是可以解耦的，我们没必要要把它们一起完成。</p><h2 id="简化Inception，提取主要矛盾"><a href="#简化Inception，提取主要矛盾" class="headerlink" title="简化Inception，提取主要矛盾"></a>简化Inception，提取主要矛盾</h2><p>接着，为了更好地分析问题，作者将Inception结构做了简化，保留了主要结构，去掉了AVE Pooling操作，如下所示。<br><img src="/img/paper-xception-simplified-inception-module.png" alt="简化后的Inception"></p><p>好的，我们现在将底层的$3$个$1\times 1$的卷积核组合起来，其实上面的图和下图是等价的。一个“大的”$1\times 1$的卷积核（channels数目变多），它的输出结果在channel上被分为若干组（group），每组分别和不同的$3\times 3$卷积核做卷积，再将这$3$份输出拼接起来，得到最后的输出。<br><img src="/img/paper-xception-equivalent-inception-module.png" alt="另一种形式"></p><p>那么，如果我们把分组数目继续调大呢？极限情况，我们可以使得group number = channel number，如下所示：<br><img src="/img/paper-xception-extreme-version.png" alt="极限模式"></p><h2 id="Depthwise-Separable-Conv"><a href="#Depthwise-Separable-Conv" class="headerlink" title="Depthwise Separable Conv"></a>Depthwise Separable Conv</h2><p>这种结构和一种名为<strong>depthwise separable conv</strong>的技术很相似，即首先使用group conv在spatial dimension上卷积，然后使用$1\times 1$的卷积核做cross channel的卷积（又叫做<em>pointwise conv</em>）。主要有两点不同：</p><ul><li>操作的顺序。在TensorFlow等框架中，depthwise separable conv的实现是先使用channelwise的filter只在spatial dimension上做卷积，再使用$1\times 1$的卷积核做跨channel的融合。而Inception中先使用$1\times 1$的卷积核。</li><li>非线性变换的缺席。在Inception中，每个conv操作后面都有ReLU的非线性变换，而depthwise separable conv没有。</li></ul><p>第一点不同不太重要，尤其是在深层网络中，这些block都是堆叠在一起的。第二点论文后面通过实验进行了比较。可以看出，去掉中间的非线性激活，能够取得更好的结果。<br><img src="/img/paper-xception-experiment-intermediate-activation.png" alt="非线性激活的影响"></p><h2 id="Xception网络架构"><a href="#Xception网络架构" class="headerlink" title="Xception网络架构"></a>Xception网络架构</h2><p>基于上面的分析，作者认为这样的假设是合理的：cross channel的相关和spatial的相关可以<strong>完全</strong>解耦。</p><blockquote><p>we make the following hypothesis: that the mapping of cross-channels correlations and spatial correlations in the feature maps of convolutional neural networks can be <em>entirely</em> decoupled. </p></blockquote><p>Xception的结构基于ResNet，但是将其中的卷积层换成了depthwise separable conv。如下图所示。整个网络被分为了三个部分：Entry，Middle和Exit。</p><blockquote><p>The Xception architecture: the data first goes through the entry flow, then through the middle flow which is repeated eight times, and finally through the exit flow. Note that all Convolution and SeparableConvolution layers are followed by batch normalization [7] (not included in the diagram). All SeparableConvolution layers use a depth multiplier of 1 (no depth expansion).</p></blockquote><p><img src="/img/paper-xception-arch.png" alt="Xception的网络结构"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在MobileNet, ShuffleMet等轻量级网络中，&lt;strong&gt;depthwise separable conv&lt;/strong&gt;是一个很流行的设计。借助&lt;a href=&quot;https://arxiv.org/abs/1610.02357&quot;&gt;Xception: Deep Learning with Depthwise separable Convolution&lt;/a&gt;，对这种分解卷积的思路做一个总结。&lt;br&gt;
    
    </summary>
    
    
      <category term="deep learning" scheme="https://xmfbit.github.io/tags/deep-learning/"/>
    
      <category term="paper" scheme="https://xmfbit.github.io/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>CS229 简单的监督学习方法</title>
    <link href="https://xmfbit.github.io/2018/03/21/cs229-supervised-learning/"/>
    <id>https://xmfbit.github.io/2018/03/21/cs229-supervised-learning/</id>
    <published>2018-03-21T03:08:14.000Z</published>
    <updated>2018-04-01T13:54:13.438Z</updated>
    
    <content type="html"><![CDATA[<p>回过头去复习一下基础的监督学习算法，主要包括最小二乘法和logistic回归。<br><a id="more"></a></p><h2 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h2><p>最小二乘法是一个线性模型，即：</p><script type="math/tex; mode=display">\hat{y} = h_\theta(x) = \sum_{i=1}^{m}\theta_i x_i = \theta^T x</script><p>定义损失函数为Mean Square Error(MSE)，如下所示。其中，不戴帽子的$y$表示给定的ground truth。</p><script type="math/tex; mode=display">J(\theta) = \frac{1}{2}(\hat{y}-y)^2</script><p>那么，最小二乘就是要找到这样的参数$\theta^*$，使得：</p><script type="math/tex; mode=display">\theta^* = \arg\min J(\theta)</script><h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><p>使用梯度下降方法求解上述优化问题，我们有：</p><script type="math/tex; mode=display">\theta_{i+1} = \theta_{i} - \alpha \nabla_\theta J(\theta)</script><p>求导，有：</p><script type="math/tex; mode=display">\begin{aligned}\nabla_\theta J(\theta) &= \frac{1}{2}\nabla_\theta (\theta^T x - y)^2 \\&= (\theta^T x - y) x\end{aligned}</script><p>由于这里的损失函数是一个凸函数，所以梯度下降方法能够保证到达全局的极值点。</p><p>上面的梯度下降只是对单个样本来做的。实际上，我们可以取整个训练集或者训练集的一部分，计算平均损失函数$J(\theta) = \frac{1}{N}\sum_{i=1}^{N}J_i(\theta)$，做梯度下降，道理是一样的，只不过相差了常数因子$\frac{1}{N}$。</p><h3 id="正则方程"><a href="#正则方程" class="headerlink" title="正则方程"></a>正则方程</h3><p>除了梯度下降方法之外，上述问题还存在着解析解。我们将所有的样本输入$x^{(i)}$作为行向量，构成矩阵$X \in \mathbb{R}^{N\times d}$。其中，$N$为样本总数，$d$为单个样本的特征个数。那么，对于参数$\theta\in\mathbb{R}^{d\times 1}$来说，$X\theta$的第$i$行就可以给出模型对第$i$个样本的预测结果。我们将ground truth排成一个$N\times 1$的矩阵，那么，损失函数可以写作：</p><script type="math/tex; mode=display">J(\theta) = \frac{1}{2N} \Vert X\theta-y \Vert_2^2</script><p>将$\Vert x\Vert_2^2$写作$x^T x$，同时略去常数项，我们有：</p><script type="math/tex; mode=display">\begin{aligned}J &= (X\theta - y)^T (X\theta - y) \\&= \theta^T X^T X\theta - 2\theta^T x^T y +y^T y\end{aligned}</script><p>对其求导，有：</p><script type="math/tex; mode=display">\nabla_\theta J = X^T X\theta - X^T y</script><p><img src="/img/cs229-supervised-learning-least-square-normal-equation.png" alt="具体计算过程贴图"></p><p>这其中，主要用到的矩阵求导性质如下：<br><img src="/img/cs229-supervised-learning-some-useful-matrix-derivatives.png" alt="一些典型求导结果"><br>令导数为$0$，求得极值点处：</p><script type="math/tex; mode=display">\theta^* = (X^TX)^{-1}X^T y</script><h3 id="概率解释"><a href="#概率解释" class="headerlink" title="概率解释"></a>概率解释</h3><p>这里对上述做法给出一个概率论上的解释。首先我们要引入似然函数（likelihood function）的概念。</p><p>似然函数是一个关于模型参数$\theta$的函数，它描述了某个参数$\theta$下，给出输入$x$，得到输出$y$的概率。用具体的公式表示如下：</p><script type="math/tex; mode=display">L(\theta) = \prod_{i=1}^{N}P(y^{(i)}|x^{(i)};\theta)</script><p>假设线性模型的预测结果和ground truth之间的误差服从Gaussian分布，也就是说，</p><script type="math/tex; mode=display">y - \theta^T x  =  \epsilon \sim \mathcal{N}(0, \sigma^2)</script><p>那么上面的似然函数可以写作：</p><script type="math/tex; mode=display">L(\theta) = \prod_{i=1}^{N}\frac{1}{\sqrt{2\pi\sigma}}\exp(\frac{(y^{(i)}-\theta^T x^{(i)})^2}{2\sigma^2})</script><p>如何估计参数$\theta$呢？我们可以认为，参数$\theta$使得出现样本点$(x^{(i)}, y^{(i)})$的概率变大，所以才能被我们观测到。自然，我们需要使得似然函数$L(\theta)$取得极大值，也就是说：</p><script type="math/tex; mode=display">\theta^* = \arg\max L(\theta)</script><p>通过引入$\log(\cdot)$，可以将连乘变成连加，同时不改变函数的单调性。这样，实际上我们操作的是对数似然函数$\log L(\theta)$。有：</p><script type="math/tex; mode=display">\begin{aligned} \mathcal{l} &= \log L(\theta) \\&= \sum_{i=1}^{N}\log \frac{1}{\sqrt{2\pi\sigma^2}} \exp (\frac{(y^{(i)}-\theta^T x^{(i)})^2}{2\sigma^2})\\&= N\log\frac{1}{\sqrt{2\pi\sigma^2}} -\frac{1}{\sigma^2}\frac{1}{2}\sum_{i=1}^{N}(y^{(i)}-\theta^T x^{(i)})^2 \end{aligned}</script><p>略去前面的常数项不管，后面一项正好是最小二乘法的损失函数。要想最大化对数似然函数，也就是要最小化上面的损失函数。</p><p>所以，最小二乘法的损失函数可以由数据集的噪声服从Gaussian分布自然地导出。</p><h3 id="加权最小二乘法"><a href="#加权最小二乘法" class="headerlink" title="加权最小二乘法"></a>加权最小二乘法</h3><p>加权最小二乘法是指对数据集中的数据赋予不同的权重，一个重要的用途是使用权重$w^{(i)} = \exp (-\frac{(x^{(i)}-x)^2}{2\tau^2})$做局部最小二乘。不再多说。</p><h2 id="logistic回归"><a href="#logistic回归" class="headerlink" title="logistic回归"></a>logistic回归</h2><p>虽然叫回归，但是logistic回归解决的问题是分类问题。</p><h3 id="logistic函数"><a href="#logistic函数" class="headerlink" title="logistic函数"></a>logistic函数</h3><p>logistic函数$\sigma(x) = \frac{1}{1+e^{-x}}$，又叫sigmoid函数，将输入$(-\infty, +\infty)$压缩到$(0, 1)$之间。它的形状如下：<br><img src="/img/cs229-supervised-learning-sigmoid.png" alt="sigmoid函数"></p><p>对其求导，发现导数值可以完全不依赖于输入$x$：</p><script type="math/tex; mode=display">\frac{d\sigma(x)} {dx} = \sigma(x)(1-\sigma(x))</script><p>我们将logistic函数的输入取做$x$的feature的线性组合，就得到了假设函数$h_\theta(x) = \sigma(\theta^T x)$。</p><h3 id="logistic回归-1"><a href="#logistic回归-1" class="headerlink" title="logistic回归"></a>logistic回归</h3><p>logistic函数的输出既然是在$(0,1)$上，我们可以将其作为概率。也就是说，我们认为它的输出是样本点属于类别$1$的概率：</p><script type="math/tex; mode=display">\begin{aligned}P(y=1|x) &= h_\theta(x) \\P(y=0|x) &= 1-h_\theta(x) \end{aligned}</script><p>或者我们写的更紧凑些：</p><script type="math/tex; mode=display">P(y|x) = (h_\theta(x))^y (1-h_\theta(x))^(1-y)</script><p>我们仍然使用上述极大似然的估计方法，求取参数$\theta$，为求简练，隐去了上标$(i)$。</p><script type="math/tex; mode=display">\begin{aligned}L(\theta) &= \prod_{i=1}^{N}P(y|x;\theta) \\&=\prod (h_\theta(x))^y (1-h_\theta(x))^{(1-y)} \end{aligned}</script><p>取对数：</p><script type="math/tex; mode=display">\log L(\theta) = \sum_{i=1}^{N}y\log(h(x)) + (1-y)\log(1-h(x))</script><p>所以，我们的损失函数为$J(\theta) = - [y\log(h(x)) + (1-y)\log(1-h(x))]$。把$h(x)$换成$P$，岂不就是深度学习中常用的交叉损失熵在二分类下的特殊情况？</p><p>回到logistic回归，使用梯度下降，我们可以得到更新参数的策略：</p><script type="math/tex; mode=display">\theta_{i+1} = \theta_i - \alpha (h_\theta(x) - y)x</script><p>啊哈！形式和最小二乘法完全一样。只不过要注意，现在的$h_\theta(x)$已经变成了一个非线性函数。</p><h3 id="感知机"><a href="#感知机" class="headerlink" title="感知机"></a>感知机</h3><p>在上述logistic回归基础上，我们强制将其输出映射到$\lbrace 1, -1\rbrace$。即将$\sigma(x)$换成$g(x)$：</p><script type="math/tex; mode=display">g(x) = \begin{cases} 1, \quad\text{if}\quad x \ge 0\\ 0, \quad\text{if}\quad x < 0\end{cases}</script><p>使用同样的更新方法，我们就得到了感知机模型（perceptron machine）。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;回过头去复习一下基础的监督学习算法，主要包括最小二乘法和logistic回归。&lt;br&gt;
    
    </summary>
    
    
      <category term="公开课" scheme="https://xmfbit.github.io/tags/%E5%85%AC%E5%BC%80%E8%AF%BE/"/>
    
      <category term="cs229" scheme="https://xmfbit.github.io/tags/cs229/"/>
    
  </entry>
  
  <entry>
    <title>Hack PyCaffe</title>
    <link href="https://xmfbit.github.io/2018/03/16/caffe-hack-python-interface/"/>
    <id>https://xmfbit.github.io/2018/03/16/caffe-hack-python-interface/</id>
    <published>2018-03-16T11:01:32.000Z</published>
    <updated>2018-03-16T12:37:52.000Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章主要是<a href="https://github.com/nitnelave/pycaffe_tutorial/blob/master/04%20Hacking%20the%20Python%20API.ipynb" target="_blank" rel="external">Github: PyCaffe Tutorial</a>中Hack Pycaffe的翻译整理。后续可能会加上一些使用boost和C++为Python接口提供后端的解释。这里主要讨论如何为Pycaffe添加自己想要的功能。至于Pycaffe的使用，留待以后的文章整理。<br><img src="/img/caffe-hack-pycaffe-python-cpp-binding.jpg" alt="Python&amp;&amp;CPP binding"><br><a id="more"></a></p><h2 id="PyCaffe的代码组织结构"><a href="#PyCaffe的代码组织结构" class="headerlink" title="PyCaffe的代码组织结构"></a>PyCaffe的代码组织结构</h2><p>见Caffe的<code>python</code>目录。下面这张图是与PyCaffe相关的代码的分布。其中<code>src</code>和<code>include</code>是Caffe框架的后端C++实现，<code>python</code>目录中是与PyCaffe关系更密切的代码。可以看到，除了<code>_caffe.cpp</code>以外，其他都是纯python代码。<code>_caffe.cpp</code>使用boost提供了C++与python的绑定，而其他python脚本在此层的抽象隔离之上，继续完善了相关功能，提供了更加丰富的API、<br><img src="/img/hack-pycaffe-code-organization.png" alt="代码组织结构"></p><h2 id="添加纯Python功能"><a href="#添加纯Python功能" class="headerlink" title="添加纯Python功能"></a>添加纯Python功能</h2><p>首先，我们介绍如何在C++构建的PyCaffe隔离之上，用纯python实现想要的功能。</p><h3 id="添加的功能和PyCaffe基本平行，不需要改变已有代码"><a href="#添加的功能和PyCaffe基本平行，不需要改变已有代码" class="headerlink" title="添加的功能和PyCaffe基本平行，不需要改变已有代码"></a>添加的功能和PyCaffe基本平行，不需要改变已有代码</h3><p>有的时候想加入的功能和PyCaffe的关系基本是平行的，比如想仿照<code>PyTorch</code>等框架，加入对数据进行预处理的<code>Transformer</code>功能（这个API其实已经在PyCaffe中实现了，这里只是举个例子）。为了实现这个功能，我们可能需要使用<code>numpy</code>和<code>opencv</code>等包装图像的预处理操作，但是和Caffe本身基本没什么关系。在这样的情况下，我们直接编写即可。要注意在<code>python/caffe/__init__.py</code>中import相关的子模块或函数。这个例子可以参考<code>caffe.io</code>的实现（见<code>python/caffe/io.py</code>文件）。</p><h3 id="添加的功能需要Caffe的支持，向已有的类中添加函数"><a href="#添加的功能需要Caffe的支持，向已有的类中添加函数" class="headerlink" title="添加的功能需要Caffe的支持，向已有的类中添加函数"></a>添加的功能需要Caffe的支持，向已有的类中添加函数</h3><p>如果添加的功能需要Caffe的支持，可以在<code>pycaffe.py</code>内添加，详见<code>Net</code>的例子。由于python的灵活性，我们可以参考<code>Net</code>的实现方式，待函数实现完成后，使用<code>&lt;class&gt;.&lt;function&gt; = my_function</code>动态地添加。如下所示，注意<code>_Net_forward</code>函数的第一个参数必须是<code>self</code>。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_Net_forward</span><span class="params">(self, blobs=None, start=None, end=None, **kwargs)</span>:</span></div><div class="line">    <span class="comment"># do something</span></div><div class="line">Net.forward = _Net_forward</div></pre></td></tr></table></figure><p>与之相似，我们还可以为已经存在的类添加字段。注意，函数用<code>@property</code>装饰，且参数有且只有一个<code>self</code>，</p><figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># This function will be called when accessing net.blobs</span></div><div class="line"><span class="meta">@property</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_Net_blobs</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    An OrderedDict (bottom to top, i.e., input to output) of network</div><div class="line">    blobs indexed by name</div><div class="line">    """</div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> hasattr(self, <span class="string">'_blobs_dict'</span>):</div><div class="line">        self._blobs_dict = OrderedDict(zip(self._blob_names, self._blobs))</div><div class="line">    <span class="keyword">return</span> self._blobs_dict </div><div class="line"></div><div class="line"><span class="comment"># Set the field `blobs` to call _Net_blobs</span></div><div class="line">Net.blobs = _Net_blobs</div></pre></td></tr></table></figure><p>PyCaffe中已经实现的类主要有：<code>Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver</code>。</p><h2 id="使用C-添加功能"><a href="#使用C-添加功能" class="headerlink" title="使用C++添加功能"></a>使用C++添加功能</h2><p>当遇到如下情况时，可能需要修改C++代码：</p><ul><li>为了获取更底层的权限控制，如一些私有字段。</li><li>性能考虑。</li></ul><p>这时，你应该去修改<code>python/caffe/_caffe.cpp</code>文件。这个文件使用了boost实现了python与C++的绑定。</p><p>为了添加一个字段，可以在<code>Blob</code>部分添加如下的代码。这样，就会将python中<code>Blob</code>类的<code>num</code>字段绑定到C++的<code>Blob&lt;Dtype&gt;::num()</code>方法上。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">.add_property(<span class="string">"num"</span>, &amp;Blob&lt;Dtype&gt;::num)</div></pre></td></tr></table></figure></p><p>使用<code>.def</code>可以为python相应的类绑定方法。在下面的代码中，首先实现了<code>Net_Save</code>方法，然后将其绑定到了python中<code>Net</code>类的<code>save</code>方法上。这样，通过python调用<code>net.save(filename)</code>即可。</p><p>注意，当你修改了<code>_caffe,cpp</code>后，记得使用<code>make pycaffe</code>重新生成动态链接库。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># <span class="function">Declare the function</span></div><div class="line"><span class="keyword">void</span> <span class="title">Net_Save</span><span class="params">(<span class="keyword">const</span> Net&lt;Dtype&gt;&amp; net, <span class="built_in">string</span> filename)</span> &#123;</div><div class="line">    <span class="comment">// ...</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// ...</span></div><div class="line"></div><div class="line">bp::class_&lt;Net&lt;Dtype&gt;&gt;(<span class="string">"Net"</span>, bp::no_init)</div><div class="line"># Now we can call net.save(file)</div><div class="line">.def(<span class="string">"save"</span>, &amp;Net_Save)</div></pre></td></tr></table></figure><p>当然，上面介绍的这些还很基础，关于boost的python绑定，可以参考官方的文档：<a href="http://www.boost.org/doc/libs/1_58_0/libs/python/doc/tutorial/doc/html/index.html" target="_blank" rel="external">boost: python binding</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇文章主要是&lt;a href=&quot;https://github.com/nitnelave/pycaffe_tutorial/blob/master/04%20Hacking%20the%20Python%20API.ipynb&quot;&gt;Github: PyCaffe Tutorial&lt;/a&gt;中Hack Pycaffe的翻译整理。后续可能会加上一些使用boost和C++为Python接口提供后端的解释。这里主要讨论如何为Pycaffe添加自己想要的功能。至于Pycaffe的使用，留待以后的文章整理。&lt;br&gt;&lt;img src=&quot;/img/caffe-hack-pycaffe-python-cpp-binding.jpg&quot; alt=&quot;Python&amp;amp;&amp;amp;CPP binding&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="caffe" scheme="https://xmfbit.github.io/tags/caffe/"/>
    
      <category term="python" scheme="https://xmfbit.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>论文 - Learning both Weights and Connections for Efficient Neural Networks</title>
    <link href="https://xmfbit.github.io/2018/03/14/paper-network-prune-hansong/"/>
    <id>https://xmfbit.github.io/2018/03/14/paper-network-prune-hansong/</id>
    <published>2018-03-14T08:18:53.000Z</published>
    <updated>2018-04-02T02:17:59.866Z</updated>
    
    <content type="html"><![CDATA[<p>Han Song的Deep Compression是模型压缩方面很重要的论文。在Deep Compression中，作者提出了三个步骤来进行模型压缩：剪枝，量化和霍夫曼编码。其中，剪枝对应的方法就是基于本文要总结的这篇论文：<a href="https://arxiv.org/abs/1506.02626" target="_blank" rel="external">Learning both Weights and Connections for Efficient Neural Networks</a>。在这篇论文中，作者介绍了如何在不损失精度的前提下，对深度学习的网络模型进行剪枝，从而达到减小模型大小的目的。<br><img src="/img/paper-pruning-network-demo.png" alt="Pruning的主要过程"><br><a id="more"></a></p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>DNN虽然能够解决很多以前很难解决的问题，但是一个应用方面的问题就是这些模型通常都太大了。尤其是当运行在手机等移动设备上时，对电源和网络带宽都是负担。对于电源来说，由于模型巨大，所以只能在外部内存DRAM中加载，造成能耗上升。具体数值见下表。所以模型压缩很有必要。本文就是使用剪枝的方法，将模型中不重要的权重设置为$0$，将原来的dense model转变为sparse model，达到压缩的目的。<br><img src="/img/paper-pruning-network-energy-for-different-memory-hieracy.png" alt="操作数地址的不同造成的功耗对比"></p><h3 id="解决什么问题？"><a href="#解决什么问题？" class="headerlink" title="解决什么问题？"></a>解决什么问题？</h3><p>如何在不损失精度的前提下，对DNN进行剪枝（或者说稀疏化），从而压缩模型。</p><h3 id="为什么剪枝是work的？"><a href="#为什么剪枝是work的？" class="headerlink" title="为什么剪枝是work的？"></a>为什么剪枝是work的？</h3><p>为什么能够通过剪枝的方法来压缩模型呢？难道剪掉的那些连接真的不重要到可以去掉吗？论文中，作者指出，DNN模型广泛存在着参数过多的问题，具有很大的冗余（见参考文献NIPS 2013的一篇文章<a href="https://arxiv.org/abs/1306.0543" target="_blank" rel="external">Predicting parameters in deep learning</a>）。</p><blockquote><p>Neural networks are typically over-parameterized, and there is significant redundancy for deep learning models </p></blockquote><p>另外，作者也为自己的剪枝方法找到了生理学上的依据，生理学上发现，对于哺乳动物来说，婴儿期会产生许多的突触连接，在后续的成长过程中，不怎么用的那些突出会退化消失。</p><h3 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h3><p>作者的方法分为三个步骤：</p><ul><li>Train Connectivity: 按照正常方法训练初始模型。作者认为该模型中权重的大小表征了其重要程度</li><li>Prune Connection: 将初始模型中那些低于某个阈值的的权重参数置成$0$（即所谓剪枝）</li><li>Re-Train: 重新训练，以期其他未被剪枝的权重能够补偿pruning带来的精度下降</li></ul><p>为了达到一个满意的压缩比例和精度要求，$2$和$3$要重复多次。</p><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>为了减少网络的冗余，减小模型的size，有以下相关工作：</p><ul><li>定点化。将weight使用8bit定点表示，32bit浮点表示activation。</li><li>低秩近似。使用矩阵分解等方法。</li><li>网络设计上，NIN等使用Global Average Pooling取代FC层，可以大大减少参数量，这种结构已经得到了广泛使用。而FC也并非无用。在Pooling后面再接一个fc层，便于后续做迁移学习transfer learning。</li><li>从优化上下手，使用损失函数的Hessian矩阵，比直接用weight decay更好。</li><li>HashedNet等工作，这里不再详述。</li></ul><h2 id="如何Prune"><a href="#如何Prune" class="headerlink" title="如何Prune"></a>如何Prune</h2><p>主要分为三步，上面 概述 中 怎么做 部分已经简单列出。下面的算法流程摘自作者的博士论文，可能更加详细清楚。<br><img src="/img/paper-pruning-network-algrithem.png" alt="剪枝算法"></p><h3 id="正则项的选择"><a href="#正则项的选择" class="headerlink" title="正则项的选择"></a>正则项的选择</h3><p>L1和L2都可以用来做正则，惩罚模型的复杂度。使用不同的正则方法会对pruning和retraining产生影响。实验发现，采用L2做正则项较好。见下图，可以看到详细的比较结果，分别是with/without retrain下L1和L2正则对精度的影响。还可以看到一个共性的地方，就是当pruning的比例大于某个阈值后，模型的精度会快速下降。</p><p><img src="/img/paper-pruning-network-regularization.png" alt="L1/L2 Regularization"></p><h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h3><p>Dropout是一项防止过拟合的技术。要注意的是，在retraining的时候，我们需要对Dropout ratio做出调整。因为网络中的很多连接都被剪枝剪下来了，所以dropout的比例要变小。下面给出定量的估计。</p><p>对于FC层来说，如果第$i$层的神经元个数是$N_i$，那么该层的连接数$C_i$用乘法原理可以很容易得到：$C_i = N_{i-1}N_i$。也就是说，连接数$C\sim N^2$。而dropout是作用于神经元的（dropout是将$N_i$个神经元输出按照概率dropout掉）。所以，比例$D^2 \sim C$，最后得到：</p><script type="math/tex; mode=display">D_r = D_o \sqrt{\frac{C_{ir}}{C_{io}}}</script><p>其中，下标$r$表示retraining，$o$表示初始模型(original)。</p><h2 id="Local-Pruning"><a href="#Local-Pruning" class="headerlink" title="Local Pruning"></a>Local Pruning</h2><p>在retraining部分，在初始模型基础上继续fine tune较好。为了能够更有效地训练，在训练FC层的时候，可以将CONV的参数固定住。反之亦然。</p><p>另外，不同深度和类型的layer对剪枝的敏感度是不一样的。作者指出，CONV比FC更敏感，第$1$个CONV比后面的要敏感。下图是AlexNet中各个layer剪枝比例和模型精度下降之间的关系。可以印证上面的结论。</p><p><img src="/img/paper-pruning-network-layer-sensitivity.png" alt="CONV和FC的prune和精度下降的关系"></p><h2 id="多次迭代剪枝"><a href="#多次迭代剪枝" class="headerlink" title="多次迭代剪枝"></a>多次迭代剪枝</h2><p>应该迭代地进行多次剪枝 + 重新训练这套组合拳。作者还尝试过根据参数的绝对值依概率进行剪枝，效果不好。<br><img src="/img/paper-pruning-network-iterative-pruning.png" alt="迭代剪枝"></p><h2 id="对神经元进行剪枝"><a href="#对神经元进行剪枝" class="headerlink" title="对神经元进行剪枝"></a>对神经元进行剪枝</h2><p>将神经元之间的connection剪枝后（或者说将权重稀疏化了），那些$0$输入$0$输出的神经元也应该被剪枝了。然后，我们又可以继续以这个神经元出发，剪掉与它相关的connection。这个步骤可以在训练的时候自动发生。因为如果某个神经元已经是dead状态，那么它的梯度也会是$0$。那么只有正则项推着它向$0$的方向。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>使用Caffe实现，需要加入一个<code>mask</code>来表示剪枝。剪枝的阈值，是该layer的权重标准差乘上某个超参数。这里：<a href="https://github.com/BVLC/caffe/pull/4294/files" target="_blank" rel="external">Add pruning possibilities at inner_product_layer #4294 </a>，有人基于Caffe官方的repo给FC层加上了剪枝。这里：<a href="https://github.com/may0324/DeepCompression-caffe" target="_blank" rel="external">Github: DeepCompression</a>,，有人实现了Deep Compression，可以参考他们的实现思路。</p><p>对于实验结果，论文中比对了LeNet和AlexNet。此外，作者的博士论文中给出了更加详细的实验结果，在更多的流行的模型上取得了不错的压缩比例。直接引用如下，做一个mark：</p><blockquote><p>On the ImageNet dataset, the pruning method reduced the number of parameters of AlexNet by a factor of 9× (61 to 6.7 million), without incurring accuracy loss. Similar experiments with VGG-16 found that the total number of parameters can be reduced by 13× (138 to 10.3 million), again with no loss of accuracy. We also experimented with the more efficient fully-convolutional neural networks: GoogleNet (Inception-V1), SqueezeNet, and ResNet-50, which have zero or very thin fully connected layers. From these experiments we find that they share very similar pruning ratios before the accuracy drops: 70% of the parameters in those fully-convolutional neural networks can be pruned. GoogleNet is pruned from 7 million to 2 million parameters, SqueezeNet from 1.2 million to 0.38 million, and ResNet-50 from 25.5 million to 7.47 million, all with no loss of Top-1 and Top-5 accuracy on Imagenet.</p></blockquote><p><img src="/img/paper-pruning-network-results.png" alt="Results"></p><p>下面 参考资料 部分也给出了作者在GitHub上放出的Deep Compression的结果，可以前去参考。</p><h3 id="学习率的设置"><a href="#学习率的设置" class="headerlink" title="学习率的设置"></a>学习率的设置</h3><p>跑模型跑实验，一个重要的超参数就是学习率$LR$。这里作者也给了一个经验规律。一般在训练初始模型的时候，学习率都是逐渐下降的。刚开始是一个较大的值$LR_1$，最后是一个较小的值$LR_2$。它们之间可能有数量级的差别。作者指出，retraining的学习率应该介于两者之间。可以取做比$LR_1$小$1 \sim 2$个数量级。</p><h3 id="RNN和LSTM"><a href="#RNN和LSTM" class="headerlink" title="RNN和LSTM"></a>RNN和LSTM</h3><p>在博士论文中，作者还是用这一技术对RNN/LSTM在Neural Talk任务上做了剪枝，取得了不错的结果。<br><img src="/img/paper-pruning-network-lstm.png" alt="LSTM"></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li>HanSong的个人主页：<a href="http://stanford.edu/~songhan/" target="_blank" rel="external">Homepage</a></li><li>HanSong的博士论文：<a href="https://purl.stanford.edu/qf934gh3708" target="_blank" rel="external">Efficient Methods and Hardware for Deep Learning</a></li><li>后续的Deep Compression论文：<a href="https://arxiv.org/abs/1510.00149" target="_blank" rel="external">DEEP COMPRESSION- COMPRESSING DEEP NEURAL NETWORKS WITH PRUNING, TRAINED QUANTIZATION AND HUFFMAN CODING</a></li><li>Deep Compression AlexNet: <a href="https://github.com/songhan/Deep-Compression-AlexNet" target="_blank" rel="external">Github: Deep-Compression-AlexNet</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Han Song的Deep Compression是模型压缩方面很重要的论文。在Deep Compression中，作者提出了三个步骤来进行模型压缩：剪枝，量化和霍夫曼编码。其中，剪枝对应的方法就是基于本文要总结的这篇论文：&lt;a href=&quot;https://arxiv.org/abs/1506.02626&quot;&gt;Learning both Weights and Connections for Efficient Neural Networks&lt;/a&gt;。在这篇论文中，作者介绍了如何在不损失精度的前提下，对深度学习的网络模型进行剪枝，从而达到减小模型大小的目的。&lt;br&gt;&lt;img src=&quot;/img/paper-pruning-network-demo.png&quot; alt=&quot;Pruning的主要过程&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="deep learning" scheme="https://xmfbit.github.io/tags/deep-learning/"/>
    
      <category term="paper" scheme="https://xmfbit.github.io/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>Caffe中的Net实现</title>
    <link href="https://xmfbit.github.io/2018/02/28/caffe-net/"/>
    <id>https://xmfbit.github.io/2018/02/28/caffe-net/</id>
    <published>2018-02-28T02:16:43.000Z</published>
    <updated>2018-03-15T06:54:37.449Z</updated>
    
    <content type="html"><![CDATA[<p>Caffe中使用<code>Net</code>实现神经网络，这篇文章对应Caffe代码总结<code>Net</code>的实现。<br><img src="/img/caffe-net-demo.jpg" width="300" height="200" alt="Net示意" align="center"><br><a id="more"></a></p><h2 id="proto中定义的参数"><a href="#proto中定义的参数" class="headerlink" title="proto中定义的参数"></a>proto中定义的参数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">message NetParameter &#123;</div><div class="line">  // net的名字</div><div class="line">  optional string name = 1; // consider giving the network a name</div><div class="line">  // 以下几个都是弃用的参数，为了定义输入的blob（大小）</div><div class="line">  // 下面有使用推荐`InputParameter`进行输入设置的方法</div><div class="line">  // DEPRECATED. See InputParameter. The input blobs to the network.</div><div class="line">  repeated string input = 3;</div><div class="line">  // DEPRECATED. See InputParameter. The shape of the input blobs.</div><div class="line">  repeated BlobShape input_shape = 8;</div><div class="line"></div><div class="line">  // 4D input dimensions -- deprecated.  Use &quot;input_shape&quot; instead.</div><div class="line">  // If specified, for each input blob there should be four</div><div class="line">  // values specifying the num, channels, height and width of the input blob.</div><div class="line">  // Thus, there should be a total of (4 * #input) numbers.</div><div class="line">  repeated int32 input_dim = 4;</div><div class="line">  </div><div class="line">  // Whether the network will force every layer to carry out backward operation.</div><div class="line">  // If set False, then whether to carry out backward is determined</div><div class="line">  // automatically according to the net structure and learning rates.</div><div class="line">  optional bool force_backward = 5 [default = false];</div><div class="line">  // The current &quot;state&quot; of the network, including the phase, level, and stage.</div><div class="line">  // Some layers may be included/excluded depending on this state and the states</div><div class="line">  // specified in the layers&apos; include and exclude fields.</div><div class="line">  optional NetState state = 6;</div><div class="line"></div><div class="line">  // Print debugging information about results while running Net::Forward,</div><div class="line">  // Net::Backward, and Net::Update.</div><div class="line">  optional bool debug_info = 7 [default = false];</div><div class="line"></div><div class="line">  // The layers that make up the net.  Each of their configurations, including</div><div class="line">  // connectivity and behavior, is specified as a LayerParameter.</div><div class="line">  repeated LayerParameter layer = 100;  // ID 100 so layers are printed last.</div><div class="line"></div><div class="line">  // DEPRECATED: use &apos;layer&apos; instead.</div><div class="line">  repeated V1LayerParameter layers = 2;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h3 id="Input的定义"><a href="#Input的定义" class="headerlink" title="Input的定义"></a>Input的定义</h3><p>在<code>train</code>和<code>deploy</code>的时候，输入的定义常常是不同的。在<code>train</code>时，我们需要提供数据$x$和真实值$y$，这样网络的输出$\hat{y} = \mathcal{F}_\theta (x)$与真实值$y$计算损失，bp，更新网络参数$\theta$。</p><p>在<code>deploy</code>时，推荐使用<code>InputLayer</code>定义网络的输入，下面是<code>$CAFFE/models/bvlc_alexnet/deploy.prototxt</code>中的输入定义：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">  name: &quot;data&quot;</div><div class="line">  type: &quot;Input&quot;</div><div class="line">  // 该层layer的输出blob名称为data，供后续layer使用</div><div class="line">  top: &quot;data&quot;</div><div class="line">  // 定义输入blob的大小：10 x 3 x 227 x 227</div><div class="line">  // 说明batch size = 10</div><div class="line">  // 输入彩色图像，channel = 3, RGB</div><div class="line">  // 输入image的大小：227 x 227</div><div class="line">  input_param &#123; shape: &#123; dim: 10 dim: 3 dim: 227 dim: 227 &#125; &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><h2 id="头文件"><a href="#头文件" class="headerlink" title="头文件"></a>头文件</h2><p><code>Net</code>的描述头文件位于<code>$CAFFE/include/caffe/net.hpp</code>中。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Caffe中使用&lt;code&gt;Net&lt;/code&gt;实现神经网络，这篇文章对应Caffe代码总结&lt;code&gt;Net&lt;/code&gt;的实现。&lt;br&gt;&lt;img src=&quot;/img/caffe-net-demo.jpg&quot; width = &quot;300&quot; height = &quot;200&quot; alt=&quot;Net示意&quot; align=center /&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="caffe" scheme="https://xmfbit.github.io/tags/caffe/"/>
    
  </entry>
  
  <entry>
    <title>捉bug记 - JupyterNotebook中使用pycaffe加载多个模型一直等待的现象</title>
    <link href="https://xmfbit.github.io/2018/02/27/bug-pycaffe-jupyternotebook-awaiting-for-data/"/>
    <id>https://xmfbit.github.io/2018/02/27/bug-pycaffe-jupyternotebook-awaiting-for-data/</id>
    <published>2018-02-27T05:30:25.000Z</published>
    <updated>2018-04-02T02:14:02.907Z</updated>
    
    <content type="html"><![CDATA[<p>JupyteNotebook是个很好的工具，但是在使用pycaffe试图在notebook中同时加载多个caffemodel模型的时候，却出现了无法加载的问题。</p><h2 id="bug重现"><a href="#bug重现" class="headerlink" title="bug重现"></a>bug重现</h2><p>我想在notebook中比较两个使用不同方法训练出来的模型，它们使用了同样的LMDB文件进行训练。加载第一个模型没有问题，但当加载第二个模型时，却一直等待。在StackOverflow上我发现了类似的问题，可以见：<a href="https://stackoverflow.com/questions/37260158/cant-load-2-models-in-pycaffe" target="_blank" rel="external">Can’t load 2 models in pycaffe</a>。</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>这是由于pycaffe（是否要加上jupyter-notebook？因为不用notebook，以前没有出现过类似问题）不能并发读取同样的LMDB所导致的。但是很遗憾，没有发现太好的解决办法。最后只能是将LMDB重新copy了一份，并修改prototxt文件，使得两个模型分别读取不同的LMDB。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;JupyteNotebook是个很好的工具，但是在使用pycaffe试图在notebook中同时加载多个caffemodel模型的时候，却出现了无法加载的问题。&lt;/p&gt;
&lt;h2 id=&quot;bug重现&quot;&gt;&lt;a href=&quot;#bug重现&quot; class=&quot;headerlink&quot; t
      
    
    </summary>
    
    
      <category term="caffe" scheme="https://xmfbit.github.io/tags/caffe/"/>
    
      <category term="python" scheme="https://xmfbit.github.io/tags/python/"/>
    
      <category term="debug" scheme="https://xmfbit.github.io/tags/debug/"/>
    
  </entry>
  
  <entry>
    <title>Caffe中卷积的大致实现思路</title>
    <link href="https://xmfbit.github.io/2018/02/26/conv-in-caffe/"/>
    <id>https://xmfbit.github.io/2018/02/26/conv-in-caffe/</id>
    <published>2018-02-26T07:26:09.000Z</published>
    <updated>2018-04-02T02:14:55.542Z</updated>
    
    <content type="html"><![CDATA[<p>参考资料：知乎：<a href="https://www.zhihu.com/question/28385679" target="_blank" rel="external">在Caffe中如何计算卷积</a>。<br><img src="/img/conv-in-caffe-naive-loop.png" alt="Naive Loop"><br><a id="more"></a></p><p>使用<code>im2col</code>将输入的图像或特征图转换为矩阵，后续就可以使用现成的线代运算优化库，如BLAS中的GEMM，来快速计算。<br><img src="/img/conv-in-caffe-im2col-followed-gemm.png" alt="im2col-&gt;gemm"></p><p>im2col的工作原理如下：每个要和卷积核做卷积的patch被抻成了一个feature vector。不同位置的patch，顺序堆叠起来，<br><img src="/img/conv-in-caffe-im2col-1.png" alt="patches堆起来"></p><p>最后就变成了这样：<br><img src="/img/conv-in-caffe-im2col-2.png" alt="最后的样子"></p><p>同样的，对卷积核也做类似的变换。将单一的卷积核抻成一个行向量，然后把<code>c_out</code>个卷积核顺序排列起来。<br><img src="/img/conv-in-caffe-im2col-3.png" alt="卷积核 to col"></p><p>我们记图像那个矩阵是<code>A</code>，记卷积那个矩阵是<code>F</code>。那么，对于第<code>i</code>个卷积核来说，它现在实际上是<code>F</code>里面的第<code>i</code>个行向量。为了计算它在原来图像上的各个位置的卷积，现在我们需要它和矩阵<code>A</code>中的每行做点积。也就是 <code>F_i * [A_1^T, A_2^T, … A_i^T]</code> （也就是<code>A</code>的转置）。推广到其他的卷积核，就是说，最后的结果是<code>F*A^T</code>.</p><p>我们可以用矩阵维度验证。<code>F</code>的维度是<code>Cout x (C x K x K)</code>. 输入的Feature map matrix的维度是<code>(H x W) x (C x K x K)</code>。那么上述矩阵乘法的结果就是 <code>Cout x (H x W)</code>。正好可以看做输出的三维blob的大小：<code>Cout x H x W</code>。</p><p>这里<a href="https://github.com/Yangqing/caffe/wiki/Convolution-in-Caffe:-a-memo" target="_blank" rel="external">Convolution in Caffe: a memo</a>还有贾扬清对于自己当时在caffe中实现conv的”心路历程“，题图出自此处。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考资料：知乎：&lt;a href=&quot;https://www.zhihu.com/question/28385679&quot;&gt;在Caffe中如何计算卷积&lt;/a&gt;。&lt;br&gt;&lt;img src=&quot;/img/conv-in-caffe-naive-loop.png&quot; alt=&quot;Naive Loop&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="caffe" scheme="https://xmfbit.github.io/tags/caffe/"/>
    
  </entry>
  
  <entry>
    <title>论文 - Learning Structured Sparsity in Deep Neural Networks</title>
    <link href="https://xmfbit.github.io/2018/02/24/paper-ssl-dnn/"/>
    <id>https://xmfbit.github.io/2018/02/24/paper-ssl-dnn/</id>
    <published>2018-02-24T02:21:14.000Z</published>
    <updated>2018-03-15T06:54:37.459Z</updated>
    
    <content type="html"><![CDATA[<p>DNN的稀疏化？用L1正则项不就好了？在很多场合，这种方法的确可行。但是当试图使用FPGA/AISC加速DNN的前向计算时，我们希望DNN的参数能有一些结构化的稀疏性质。这样才能减少不必要的cache missing等问题。在<a href="https://arxiv.org/pdf/1608.03665.pdf" target="_blank" rel="external">这篇文章</a>中，作者提出了一种结构化稀疏的方法，能够在不损失精度的前提下，对深度神经网络进行稀疏化，达到加速的目的。本文作者<a href="http://www.pittnuts.com/" target="_blank" rel="external">温伟</a>，目前是杜克大学Chen Yiran组的博士生，做了很多关于结构化稀疏和DNN加速相关的工作。本文发表在NIPS 2016上。本文的代码已经公开：<a href="https://github.com/wenwei202/caffe/tree/scnn" target="_blank" rel="external">GitHub</a><br><img src="/img/paper-ssldnn.png" alt="SSL的原理示意图"><br><a id="more"></a></p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>为了满足DNN的计算速度要求，我们提出了Structure Sparisity Learning (SSL)技术来正则化DNN的“结构”（例如CNN filter的参数，filter的形状，包括channel和网络层深）。它可以带来：</p><ul><li>大的DNN —&gt; 紧凑的模型 —&gt; 计算开销节省</li><li>硬件友好的结构化稀疏 —&gt; 便于在专用硬件上加速</li><li>提供了正则化，提高网络泛化能力 —&gt; 提高了精度</li></ul><p>实验结果显示，这种方法可以在CPU/GPU上对AlexNet分别达到平均$5.1$和$3,1$倍的加速。在CIFAR10上训练ResNet，从$20$层减少到$18$层，并提高了精度。</p><h2 id="LASSO"><a href="#LASSO" class="headerlink" title="LASSO"></a>LASSO</h2><p>SSL是基于Group LASSO的，所以正式介绍文章之前，首先简单介绍LASSO和Group LASSO，<br><a href="https://en.wikipedia.org/wiki/Lasso_(statistics" target="_blank" rel="external">LASSO</a>)(least absolute shrinkage and selection operator)是指统计学习中的特征选择方法。以最小二乘法求解线性模型为例，可以加上L1 norm作为正则化约束，见下式，其中$\beta$是模型的参数。具体推导过程可以参见wiki页面。</p><script type="math/tex; mode=display">\min_{\beta \in R^p}\frac{1}{N} \Vert(y-X\beta)\Vert_2^2 + \lambda \Vert \beta \Vert_1</script><p>而Group LASSO就是将参数分组，进行LASSO操作。</p><p>这里只是简单介绍一下LASSO。SSL下面还会详细介绍，不必过多执着于LASSO。</p><h2 id="结构化稀疏"><a href="#结构化稀疏" class="headerlink" title="结构化稀疏"></a>结构化稀疏</h2><p>DNN通常参数很多，计算量很大。为了减少计算开销，目前的研究包括：稀疏化，connection pruning, low rank approximation等。然而前两种方法只能得到随机的稀疏，无规律的内存读取仍然制约了速度。下面这种图是一个例子。我们使用了L1正则进行稀疏。和原模型相比，精度损失了$2$个点。虽然稀疏度比较高，但是实际加速效果却很差。可以看到，在<code>conv3</code>，<code>conv4</code>和<code>conv5</code>中，有的情况下反而加速比是大于$1$的。<br><img src="/img/paper-ssldnn-random-sparity-is-bad.png" alt="随机稀疏的实际加速效果"></p><p>low rank approx利用矩阵分解，将预训练好的模型的参数分解为小矩阵的乘积。这种方法需要较多的迭代次数，同时，网络结构是不能更改的。</p><p>基于下面实验中观察的事实，我们提出了SSL来直接学习结构化稀疏。</p><ul><li>网络中的filter和channel存在冗余</li><li>filter稀疏化为别的形状能够去除不必要的计算</li><li>网络的深度虽然重要，但是并不意味着深层的layer对网络性能一定是好的</li></ul><p>假设第$l$个卷积层的参数是一个$4D$的Tensor，$W^{(l)}\in R^{N_l \times C_l \times M_l \times N_l}$，那么SSL方法可以表示为优化下面这个损失函数：</p><script type="math/tex; mode=display">E(W)=E_D{W} + \lambda R(W) + \lambda_g \sum_{l=1}^{L}R_g(W^{(l)})</script><p>这里，$W$代表DNN中所有权重的集合。$E_D(W)$代表在训练集上的loss。$R$是非结构化的正则项，例如L2 norm。$R_g$是指结构化稀疏的正则项，注意是逐层计算的。对于每一层来说（也就是上述最后一项求和的每一项），group LASSO可以表示为：</p><script type="math/tex; mode=display">R_g(w) = \sum_{g=1}^{G}\Vert w^{(g)} \Vert_g</script><p>其中，$w^{(g)}$是该层权重$W^{(l)}$的一部分，不同的分组可以重叠。$G$是分组的组数。$\Vert \cdot \Vert_g$指的是group LASSO，这里使用的是$\Vert w^{(g)}\Vert_g = \sqrt{\sum_{i=1}^{|w^{(g)}|}(w_i^{(g)})^2}$，也就是$2$范数。</p><h2 id="SSL"><a href="#SSL" class="headerlink" title="SSL"></a>SSL</h2><p>有了上面的损失函数，SSL就取决于如何对weight进行分组。对不同的分组情况分类讨论如下。图示见博客开头的题图。</p><h3 id="惩罚不重要的filter和channel"><a href="#惩罚不重要的filter和channel" class="headerlink" title="惩罚不重要的filter和channel"></a>惩罚不重要的filter和channel</h3><p>假设$W^{(l)}_{n_l,:,:,:}$是第$n$个filter，$W^{(l)}_{:, c_l, :,:}$是所有weight的第$c$个channel。可以通过下面的约束来去除相对不重要的filter和channel。注意，如果第$l$层的weight中某个filter变成了$0$，那么输出的feature map中就有一个全$0$，所以filter和channel的结构化稀疏要放到一起。下面是这种形式下的损失函数。为了简单，后面的讨论中都略去了正常的正则化项$R(W)$。</p><script type="math/tex; mode=display">E(W) = E_D(W) + \lambda_n \sum_{l=1}^{L}(\sum_{n_l=1}^{N_l}\Vert W^{(l)}_{n_l,:,:,:}\Vert_g) + \lambda_c\sum_{l=1}^{L}(\sum_{cl=1}^{C_l}\Vert W^{(l)}_{:,c_l,:,:}\Vert_g)</script><h3 id="任意形状的filter"><a href="#任意形状的filter" class="headerlink" title="任意形状的filter"></a>任意形状的filter</h3><p>所谓任意形状的filter，就是将filter中的一些权重置为$0$。可以使用下面的分组方法：</p><script type="math/tex; mode=display">E(W) = E_D(W) + \lambda_s \sum_{l=1}^{L}(\sum_{c_l=1}^{C_l}\sum_{m_l=1}^{M_l}\sum_{k_l=1}^{K_l})\Vert W^{(l)}_{:,c_l,m_l,k_l} \Vert_g</script><h3 id="网络深度"><a href="#网络深度" class="headerlink" title="网络深度"></a>网络深度</h3><p>损失函数如下：</p><script type="math/tex; mode=display">E(W) = E_D(W) + \lambda_d \sum_{l=1}^{L}\Vert W^{(l)}\Vert_g</script><p>不过要注意的是，某个layer被稀疏掉了，会切断信息的流通。所以受ResNet启发，加上了short-cut结构。即使SSL移去了该layer所有的filter，上层的feature map仍然可以传导到后面。</p><h3 id="两类特殊的稀疏规则"><a href="#两类特殊的稀疏规则" class="headerlink" title="两类特殊的稀疏规则"></a>两类特殊的稀疏规则</h3><p>特意提出下面两种稀疏规则，下面的实验即是基于这两种特殊的稀疏结构。</p><h4 id="2D-filter-sparsity"><a href="#2D-filter-sparsity" class="headerlink" title="2D filter sparsity"></a>2D filter sparsity</h4><p>卷积层中的3D卷积可以看做是2D卷积的组合（做卷积的时候spatial和channel是不相交的）。这种结构化稀疏是将该卷积层中的每个2D的filter，$W^{(l)}_{n_l,c_l,:,:}$，看做一个group，做group LASSO。这相当于是上述filter-wise和channel-wise的组合。</p><h4 id="filter-wise和shape-wise的组合加速GEMM"><a href="#filter-wise和shape-wise的组合加速GEMM" class="headerlink" title="filter-wise和shape-wise的组合加速GEMM"></a>filter-wise和shape-wise的组合加速GEMM</h4><p>在Caffe中，3D的权重tensor是reshape成了一个行向量，然后$N<em>l$个filter的行向量堆叠在一起，就成了一个2D的矩阵。这个矩阵的每一列对应的是$W^{(l)}</em>{:,c_l,m_l,k_l}$，称为shape sparsity。两者组合，矩阵的零行和零列可以被抽去，相当于GEMM的矩阵行列数少了，起到了加速的效果。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>分别在MNIST，CIFAR10和ImageNet上做了实验，使用公开的模型做baseline，并以此为基础使用SSL训练。</p><h3 id="LeNet-amp-MLP-MNIST"><a href="#LeNet-amp-MLP-MNIST" class="headerlink" title="LeNet&amp;MLP@MNIST"></a>LeNet&amp;MLP@MNIST</h3><p>分别使用Caffe中实现的LeNet和MLP做实验。</p><h4 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h4><p>限制SSL为filter-wise和channel-wise稀疏化，来惩罚不重要的filter。下表中，LeNet-1是baseline，2和3是使用不同强度得到的稀疏化结果。可以看到，精度基本没有损失($0.1%$)，但是filter和channel数量都有了较大减少，FLOP大大减少，加速效果比较明显。<br><img src="/img/paper-ssldnn-lenet-penalizing-unimportant-filter-channel.png" alt="实验结果1"></p><p>将网络<code>conv1</code>的filter可视化如下。可以看到，对于LeNet2来说，大多数filter都被稀疏掉了。<br><img src="/img/paper-ssldnn-experiment-on-lenet.png" alt="LeNet的实验结果"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;DNN的稀疏化？用L1正则项不就好了？在很多场合，这种方法的确可行。但是当试图使用FPGA/AISC加速DNN的前向计算时，我们希望DNN的参数能有一些结构化的稀疏性质。这样才能减少不必要的cache missing等问题。在&lt;a href=&quot;https://arxiv.org/pdf/1608.03665.pdf&quot;&gt;这篇文章&lt;/a&gt;中，作者提出了一种结构化稀疏的方法，能够在不损失精度的前提下，对深度神经网络进行稀疏化，达到加速的目的。本文作者&lt;a href=&quot;http://www.pittnuts.com/&quot;&gt;温伟&lt;/a&gt;，目前是杜克大学Chen Yiran组的博士生，做了很多关于结构化稀疏和DNN加速相关的工作。本文发表在NIPS 2016上。本文的代码已经公开：&lt;a href=&quot;https://github.com/wenwei202/caffe/tree/scnn&quot;&gt;GitHub&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;/img/paper-ssldnn.png&quot; alt=&quot;SSL的原理示意图&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="deep learning" scheme="https://xmfbit.github.io/tags/deep-learning/"/>
    
      <category term="paper" scheme="https://xmfbit.github.io/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>捉bug记 - Cannot create Cublas handle. Cublas won&#39;t be available.</title>
    <link href="https://xmfbit.github.io/2018/02/08/bug-pycaffe-using-cublas/"/>
    <id>https://xmfbit.github.io/2018/02/08/bug-pycaffe-using-cublas/</id>
    <published>2018-02-08T06:16:53.000Z</published>
    <updated>2018-04-02T02:13:57.381Z</updated>
    
    <content type="html"><![CDATA[<p>这两天在使用Caffe的时候出现了一个奇怪的bug。当使用C++接口时，完全没有问题；但是当使用python接口时，会出现错误提示如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">common.cpp:114] Cannot create Cublas handle. Cublas won&apos;t be available.</div><div class="line">common.cpp:121] Cannot create Curand generator. Curand won&apos;t be available.</div></pre></td></tr></table></figure></p><a id="more"></a><p>令人疑惑的是，这个python脚本我前段时间已经用过几次了，却没有这样的问题。</p><p>如果在Google上搜索这个问题，很多讨论都是把锅推给了驱动，不过我使用的这台服务器并没有更新过驱动或系统。本来想要试试重启大法，但是上面还有其他人在跑的任务，所以重启不太现实。</p><p>最后找到了这个issue: <a href="https://github.com/BVLC/caffe/issues/440" target="_blank" rel="external">Cannot use Caffe on another GPU when GPU 0 has full memory</a>。联想到我目前使用的服务器上GPU０也正是在跑着一项很吃显存的任务（如下所示），所以赶紧试了一下里面@longjon的方法。<br><img src="/img/bug_pycaffe_nvidia_smi_result.png" alt="nvidia-smi给出的显卡使用信息"></p><p>使用<code>CUDA_VISIBLE_DEVICES</code>变量，指定Caffe能看到的显卡设备。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">CUDA_VISIBLE_DEVICES=2 python my_script.py --gpu_id=0</div></pre></td></tr></table></figure></p><p>果然就可以了！</p><p>这个问题应该出在pycaffe的初始化上。这里不再深究。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这两天在使用Caffe的时候出现了一个奇怪的bug。当使用C++接口时，完全没有问题；但是当使用python接口时，会出现错误提示如下：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;common.cpp:114] Cannot create Cublas handle. Cublas won&amp;apos;t be available.&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;common.cpp:121] Cannot create Curand generator. Curand won&amp;apos;t be available.&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="caffe" scheme="https://xmfbit.github.io/tags/caffe/"/>
    
      <category term="python" scheme="https://xmfbit.github.io/tags/python/"/>
    
      <category term="debug" scheme="https://xmfbit.github.io/tags/debug/"/>
    
  </entry>
  
  <entry>
    <title>论文 - Visualizing and Understanding ConvNet</title>
    <link href="https://xmfbit.github.io/2018/02/08/paper-visualize-convnet/"/>
    <id>https://xmfbit.github.io/2018/02/08/paper-visualize-convnet/</id>
    <published>2018-02-08T02:48:21.000Z</published>
    <updated>2018-03-15T06:54:37.460Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/pdf/1311.2901.pdf" target="_blank" rel="external">Visualizing &amp; Understanding ConvNet</a>这篇文章是比较早期关于CNN调试的文章，作者利用可视化方法，设计了一个超过AlexNet性能的网络结构。</p><p><img src="/img/paper_visconvnet_demo.png" alt="可视化结果"><br><a id="more"></a></p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>继AlexNet之后，CNN在ImageNet竞赛中得到了广泛应用。AlextNet成功的原因包括以下三点：</p><ul><li>Large data。</li><li>硬件GPU性能。</li><li>一些技巧提升了模型的泛化能力，如Dropout技术。</li></ul><p>不过CNN仍然像一只黑盒子，缺少可解释性。这使得对CNN的调试变得比较困难。我们提出了一种思路，可以找出究竟input中的什么东西对应了激活后的Feature map。</p><p>(对于神经网络的可解释性，可以从基础理论入手，也可以从实践中的经验入手。本文作者实际上就是在探索如何能够更好得使用经验对CNN进行调试。这种方法仍然没有触及到CNN本质的可解释性的东西，不过仍然在工程实践中有很大的意义，相当于将黑盒子变成了灰盒子。从人工取火到炼金术到现代化学，也不是这么一个过程吗？)</p><p>在AlexNet中，每个卷积单元常常由以下几个部分组成：</p><ul><li>卷积层，使用一组学习到的$3D$滤波器与输入（上一层的输出或网络输入的数据）做卷积操作。</li><li>非线性激活层，通常使用<code>ReLU(x) = max(0, x)</code>。</li><li>可选的，池化层，缩小Feature map的尺寸。</li><li>可选的，LRN层（现在已经基本不使用）。</li></ul><h2 id="DeconvNet"><a href="#DeconvNet" class="headerlink" title="DeconvNet"></a>DeconvNet</h2><p>我们使用DeconvNet这项技术，寻找与输出的激活对应的输入模式。这样，我们可以看到，输入中的哪个部分被神经元捕获，产生了较强的激活。</p><p>如图所示，展示了DeconvNet是如何构造的。<br><img src="/img/paer_visconvnet_deconvnet_structure.png" alt="DeconvNet的构造"></p><p>首先，图像被送入卷积网络中，得到输出的feature map。对于输出的某个激活，我们可以将其他激活值置成全$0$，然后顺着deconvNet计算，得到与之对应的输入。具体来说，我们需要对三种不同的layer进行反向操作。</p><h3 id="Uppooling"><a href="#Uppooling" class="headerlink" title="Uppooling"></a>Uppooling</h3><p>在CNN中，max pooling操作是不可逆的（信息丢掉了）。我们可以使用近似操作：记录最大值的位置；在deconvNet中，保留该标记位置处的激活值。如下图所示。右侧为CNN中的max pooling操作。中间switches显示的是最大值的位置（用灰色标出）。在左侧的deconvNet中，激活值对应给到相应的灰色位置。这个操作被称为Uppooing。<br><img src="/img/paper_visconvnet_uppooling.png" alt="Uppooling示意图"></p><h3 id="Rectification"><a href="#Rectification" class="headerlink" title="Rectification"></a>Rectification</h3><p>在CNN中，一般使用relu作为非线性激活。deconvNet中也做同样的处理。</p><h3 id="Filtering"><a href="#Filtering" class="headerlink" title="Filtering"></a>Filtering</h3><p>在CNN中，一组待学习的filter用来与输入的feature map做卷积。得到输出。在deconvNet中，使用deconv操作，输入是整流之后的feature map。</p><p>对于最终输出的activation中的每个值，经过deconv的作用，最终会对应到输入pixel space上的一小块区域，显示了它们对最终输出的贡献。</p><h2 id="CNN的可视化"><a href="#CNN的可视化" class="headerlink" title="CNN的可视化"></a>CNN的可视化</h2><p>要想可视化，先要有训练好的CNN模型。这里用作可视化的模型基于AlexNet，但是去掉了group。另外，为了可视化效果，将layer $1$的filter size从$11\times 11$变成$7\times 7$，步长变成$2$。具体训练过程不再详述。</p><p>训练完之后，我们将ImageNet的validation数据集送入到网络中进行前向计算，</p><p>如下所示，是layer $1$的可视化结果。可以看到，右下方的可视化结果被分成了$9\times 9$的方格，每个方格内又细分成了$9\times 9$的小格子。其中，大格子对应的是$9$个filter，小格子对应的是top 9的激活利用deconvNet反算回去对应的image patch、因为layer 1的filter个数正好也是$9$，所以可能稍显迷惑。<br><img src="/img/paper_visconvnet_layer1_demo.png" alt="layer 1的可视化"></p><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p>这里是关于CNN可视化的一些额外资料：</p><ul><li>Zeiler关于本文的talk：<a href="https://www.youtube.com/watch?v=ghEmQSxT6tw" target="_blank" rel="external">Visualizing and Understanding Deep Neural Networks by Matt Zeiler</a></li><li>斯坦福CS231课程的讲义：<a href="http://cs231n.github.io/understanding-cnn/" target="_blank" rel="external">Visualizing what ConvNets learn</a></li><li>ICML 2015上的另一篇CNN可视化的paper：<a href="https://arxiv.org/pdf/1506.06579.pdf" target="_blank" rel="external">Understanding Neural Networks Through Deep Visualization</a>以及他们的开源工具：<a href="https://github.com/yosinski/deep-visualization-toolbox" target="_blank" rel="external">deep-visualization-toolbox</a></li><li>一篇知乎专栏的文章：<a href="https://zhuanlan.zhihu.com/p/24833574" target="_blank" rel="external">Deep Visualization:可视化并理解CNN</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1311.2901.pdf&quot;&gt;Visualizing &amp;amp; Understanding ConvNet&lt;/a&gt;这篇文章是比较早期关于CNN调试的文章，作者利用可视化方法，设计了一个超过AlexNet性能的网络结构。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/img/paper_visconvnet_demo.png&quot; alt=&quot;可视化结果&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="deep learning" scheme="https://xmfbit.github.io/tags/deep-learning/"/>
    
      <category term="paper" scheme="https://xmfbit.github.io/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>Incremental Network Quantization 论文阅读</title>
    <link href="https://xmfbit.github.io/2018/01/25/inq-paper/"/>
    <id>https://xmfbit.github.io/2018/01/25/inq-paper/</id>
    <published>2018-01-25T07:30:28.000Z</published>
    <updated>2018-04-02T02:17:11.124Z</updated>
    
    <content type="html"><![CDATA[<p>卷积神经网络虽然已经在很多任务上取得了很棒的效果，但是模型大小和运算量限制了它们在移动设备和嵌入式设备上的使用。模型量化压缩等问题自然引起了大家的关注。<a href="https://arxiv.org/abs/1702.03044" target="_blank" rel="external">Incremental Network Quantization</a>这篇文章关注的是如何使用更少的比特数进行模型参数量化以达到压缩模型，减少模型大小同时使得模型精度无损。如下图所示，使用5bit位数，INQ在多个模型上都取得了不逊于原始FP32模型的精度。实验结果还是很有说服力的。作者将其开源在了GitHub上，见<a href="https://github.com/Zhouaojun/Incremental-Network-Quantization" target="_blank" rel="external">Incremental-Network-Quantization</a>。<br><img src="/img/paper-inq-result.png" alt="实验结果"><br><a id="more"></a></p><h2 id="量化方法"><a href="#量化方法" class="headerlink" title="量化方法"></a>量化方法</h2><p>INQ论文中，作者采用的量化方法是将权重量化为$2$的幂次或$0$。具体来说，是将权重$W_l$（表示第$l$层的参数权重）舍入到下面这个有限集合中的元素（在下面的讨论中，我们认为$n_1 &gt; n_2$）：<br><img src="/img/paper-inq-quantize-set.png" alt="权重集合"></p><p>假设用$b$bit表示权重，我们分出$1$位单独表示$0$。</p><p>PS：这里插一句。关于为什么要单独分出$1$位表示$0$，毕竟这样浪费了($2^b$ vs $2^{b-1}+1$)。GitHub上有人发<a href="https://github.com/Zhouaojun/Incremental-Network-Quantization/issues/12" target="_blank" rel="external">issue</a>问，作者也没有正面回复这样做的原因。以我的理解，是方便判定$0$和移位。因为作者将权重都舍入到了$2$的幂次，那肯定是为了后续将乘法变成移位操作。而使用剩下的$b-1$表示，可以方便地读出移位的位数，进行操作。</p><p>这样，剩下的$b-1$位用来表示$2$的幂次。我们需要决定$n_1$和$n_2$。因为它俩决定了表示范围。它们之间的关系为：</p><script type="math/tex; mode=display">(n_1-n_2 + 1) \times 2 = 2^{b-1}</script><p>其中，乘以$2$是考虑到正负对称的表示范围。</p><p>如何确定$n_1$呢（由上式可知，有了$b$和$n_1$，$n_2$就确定了）。作者考虑了待量化权重中的最大值，我们需要设置$n_1$，使其刚好不溢出。所以有：</p><script type="math/tex; mode=display">n_1 = \lfloor \log_2(4s/3) \rfloor</script><p>其中，$s$是权重当中绝对值最大的那个，即$s = \max \vert W_l\vert$。</p><p>之后做最近舍入就可以了。对于小于最小分辨力$2^{n_2}$的那些权重，将其直接截断为$0$。</p><h2 id="训练方法"><a href="#训练方法" class="headerlink" title="训练方法"></a>训练方法</h2><p>量化完成后，网络的精度必然会下降。我们需要对其进行调整，使其精度能够恢复原始模型的水平。为此，作者提出了三个主要步骤，迭代地进行。即 weight partition（权重划分）, group-wise quantization（分组量化） 和re-training（训练）。</p><p>re-training好理解，就是量化之后要继续做finetuning。前面两个名词解释如下：weight partition是指我们不是对整个权重一股脑地做量化，而是将其划分为两个不相交的集合。group-wise quantization是指对其中一个集合中的权重做量化，另一组集合中的权重不变，仍然为FP32。注意，在re-training中，我们只对没有量化的那组参数做参数更新。下面是论文中的表述。</p><blockquote><p>Weight partition is to divide the weights in each layer of a pre-trained full-precision CNN model into two disjoint groups which play comple- mentary roles in our INQ. The weights in the first group are responsible for forming a low-precision base for the original model, thus they are quantized by using Equation (4). The weights in the second group adapt to compensate for the loss in model accuracy, thus they are the ones to be re-trained.</p></blockquote><p>训练步骤可以用下图来表示。在第一个迭代中，将所有的权重划分为黑色和白色两个部分（图$1$）。黑色部分的权重进行量化，白色部分不变（图$2$）。然后，使用SGD更新那些白色部分的权重（图$3$）。在第二次迭代中，我们扩大量化权重的范围，重复进行迭代$1$中的操作。在后面的迭代中，以此类推，只不过要不断调大量化权重的比例，最终使得所有权重都量化为止。<br><img src="/img/paper-inq-algorithm-demo.png" alt="训练图解"></p><h3 id="pruning-inspired-strategy"><a href="#pruning-inspired-strategy" class="headerlink" title="pruning-inspired strategy"></a>pruning-inspired strategy</h3><p>在权重划分步骤，作者指出，随机地将权重量化，不如根据权重的幅值，优先量化那些绝对值比较大的权重。比较结果见下图。<br><img src="/img/paper-inq-different-quantize.png" alt="两种量化方法的比较"></p><p>在代码部分，INQ基于Caffe框架，主要修改的地方集中于<code>blob.cpp</code>和<code>sgd_solver.cpp</code>中。量化部分的代码如下，首先根据要划分的比例计算出两个集合分界点处的权重大小。然后将大于该值的权重进行量化，小于该值的权重保持不变。下面的代码其实有点小问题，<code>data_copy</code>使用完之后没有释放。关于代码中<code>mask</code>的作用，下文介绍。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// blob.cpp</span></div><div class="line"><span class="comment">// INQ  </span></div><div class="line"><span class="keyword">if</span>(is_quantization)</div><div class="line">&#123;</div><div class="line">  Dtype* data_copy=(Dtype*) <span class="built_in">malloc</span>(count_*<span class="keyword">sizeof</span>(Dtype));</div><div class="line">  caffe_copy(count_,data_vec,data_copy);</div><div class="line">  caffe_abs(count_,data_copy,data_copy);</div><div class="line">  <span class="built_in">std</span>::sort(data_copy,data_copy+count_); <span class="comment">//data_copy order from small to large</span></div><div class="line">  </div><div class="line">  <span class="comment">//caculate the n1</span></div><div class="line">  Dtype max_data=data_copy[count_<span class="number">-1</span>];</div><div class="line">  <span class="keyword">int</span> n1=(<span class="keyword">int</span>)<span class="built_in">floor</span>(log2(max_data*<span class="number">4.0</span>/<span class="number">3.0</span>));</div><div class="line">  </div><div class="line">  <span class="comment">//quantizate the top 30% of each layer, change the "partition" until partition=0</span></div><div class="line">  <span class="keyword">int</span> partition=<span class="keyword">int</span>(count_*<span class="number">0.7</span>)<span class="number">-1</span>;</div><div class="line"></div><div class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; (count_); ++i) &#123;</div><div class="line">  </div><div class="line">    <span class="keyword">if</span>(<span class="built_in">std</span>::<span class="built_in">abs</span>(data_vec[i])&gt;=data_copy[partition])</div><div class="line">      &#123;</div><div class="line">        data_vec[i] = weightCluster_zero(data_vec[i],n1);</div><div class="line"> </div><div class="line">        mask_vec[i]=<span class="number">0</span>;</div><div class="line">      &#125;</div><div class="line">  &#125;</div></pre></td></tr></table></figure><h3 id="参数更新"><a href="#参数更新" class="headerlink" title="参数更新"></a>参数更新</h3><p>在re-training中，我们只对未量化的那些参数进行更新。待更新的参数，<code>mask</code>中的值都是$1$，这样和<code>diff</code>相乘仍然不变；不更新的参数，<code>mask</code>中的值都是$0$，和<code>diff</code>乘起来，相当于强制把梯度变成了$0$。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">// sgd_solver.cpp</div><div class="line">caffe_gpu_mul(net_params[param_id]-&gt;count(),net_params[param_id]-&gt;gpu_mask(),net_params[param_id]-&gt;mutable_gpu_diff(),net_params[param_id]-&gt;mutable_gpu_diff());</div></pre></td></tr></table></figure><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>论文中还有一些其他的小细节，这里不再多说。本文的作者还维护了一个关于模型量化压缩相关的<a href="https://github.com/Zhouaojun/Efficient-Deep-Learning" target="_blank" rel="external">repo</a>，也可以作为参考。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;卷积神经网络虽然已经在很多任务上取得了很棒的效果，但是模型大小和运算量限制了它们在移动设备和嵌入式设备上的使用。模型量化压缩等问题自然引起了大家的关注。&lt;a href=&quot;https://arxiv.org/abs/1702.03044&quot;&gt;Incremental Network Quantization&lt;/a&gt;这篇文章关注的是如何使用更少的比特数进行模型参数量化以达到压缩模型，减少模型大小同时使得模型精度无损。如下图所示，使用5bit位数，INQ在多个模型上都取得了不逊于原始FP32模型的精度。实验结果还是很有说服力的。作者将其开源在了GitHub上，见&lt;a href=&quot;https://github.com/Zhouaojun/Incremental-Network-Quantization&quot;&gt;Incremental-Network-Quantization&lt;/a&gt;。&lt;br&gt;&lt;img src=&quot;/img/paper-inq-result.png&quot; alt=&quot;实验结果&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="deep learning" scheme="https://xmfbit.github.io/tags/deep-learning/"/>
    
      <category term="paper" scheme="https://xmfbit.github.io/tags/paper/"/>
    
      <category term="quantization" scheme="https://xmfbit.github.io/tags/quantization/"/>
    
  </entry>
  
  <entry>
    <title>Caffe 中的 SyncedMem介绍</title>
    <link href="https://xmfbit.github.io/2018/01/12/caffe-syncedmem/"/>
    <id>https://xmfbit.github.io/2018/01/12/caffe-syncedmem/</id>
    <published>2018-01-12T06:05:59.000Z</published>
    <updated>2018-03-15T06:54:37.450Z</updated>
    
    <content type="html"><![CDATA[<p><code>Blob</code>是Caffe中的基本数据结构，类似于TensorFlow和PyTorch中的Tensor。图像读入后作为<code>Blob</code>，开始在各个<code>Layer</code>之间传递，最终得到输出。下面这张图展示了<code>Blob</code>和<code>Layer</code>之间的关系：<br> <img src="/img/caffe_syncedmem_blob_flow.jpg" width="300" height="200" alt="blob的流动" align="center"></p><p>Caffe中的<code>Blob</code>在实现的时候，使用了<code>SyncedMem</code>管理内存，并在内存（Host）和显存（device）之间同步。这篇博客对Caffe中<code>SyncedMem</code>的实现做一总结。<br><a id="more"></a></p><h2 id="SyncedMem的作用"><a href="#SyncedMem的作用" class="headerlink" title="SyncedMem的作用"></a>SyncedMem的作用</h2><p><code>Blob</code>是一个多维的数组，可以位于内存，也可以位于显存（当使用GPU时）。一方面，我们需要对底层的内存进行管理，包括何何时开辟内存空间。另一方面，我们的训练数据常常是首先由硬盘读取到内存中，而训练又经常使用GPU，最终结果的保存或可视化又要求数据重新传回内存，所以涉及到Host和Device内存的同步问题。</p><h2 id="同步的实现思路"><a href="#同步的实现思路" class="headerlink" title="同步的实现思路"></a>同步的实现思路</h2><p>在<code>SyncedMem</code>的实现代码中，作者使用一个枚举量<code>head_</code>来标记当前的状态。如下所示：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// in SyncedMem</span></div><div class="line"><span class="keyword">enum</span> SyncedHead &#123; UNINITIALIZED, HEAD_AT_CPU, HEAD_AT_GPU, SYNCED &#125;;</div><div class="line"><span class="comment">// 使用过Git吗？ 在Git中那个标志着repo最新版本状态的变量就叫 HEAD</span></div><div class="line"><span class="comment">// 这里也是一样，标志着最新的数据位于哪里</span></div><div class="line">SyncedHead head_;</div></pre></td></tr></table></figure><p>这样，利用<code>head_</code>变量，就可以构建一个状态转移图，在不同状态切换时进行必要的同步操作等。<br><img src="/img/caffe_syncedmem_transfer.png" alt="状态转换图"></p><h2 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h2><p><code>SyncedMem</code>的类声明如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * @brief Manages memory allocation and synchronization between the host (CPU)</div><div class="line"> *        and device (GPU).</div><div class="line"> *</div><div class="line"> * TODO(dox): more thorough description.</div><div class="line"> */</div><div class="line"><span class="keyword">class</span> SyncedMemory &#123;</div><div class="line"> <span class="keyword">public</span>:</div><div class="line">  SyncedMemory();</div><div class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">SyncedMemory</span><span class="params">(<span class="keyword">size_t</span> size)</span></span>;</div><div class="line">  ~SyncedMemory();</div><div class="line">  <span class="comment">// 获取CPU data指针</span></div><div class="line">  <span class="function"><span class="keyword">const</span> <span class="keyword">void</span>* <span class="title">cpu_data</span><span class="params">()</span></span>;</div><div class="line">  <span class="comment">// 设置CPU data指针</span></div><div class="line">  <span class="function"><span class="keyword">void</span> <span class="title">set_cpu_data</span><span class="params">(<span class="keyword">void</span>* data)</span></span>;</div><div class="line">  <span class="comment">// 获取GPU data指针</span></div><div class="line">  <span class="function"><span class="keyword">const</span> <span class="keyword">void</span>* <span class="title">gpu_data</span><span class="params">()</span></span>;</div><div class="line">  <span class="comment">// 设置GPU data指针</span></div><div class="line">  <span class="function"><span class="keyword">void</span> <span class="title">set_gpu_data</span><span class="params">(<span class="keyword">void</span>* data)</span></span>;</div><div class="line">  <span class="comment">// 获取CPU data指针，并在后续将改变指针所指向内存的值</span></div><div class="line">  <span class="function"><span class="keyword">void</span>* <span class="title">mutable_cpu_data</span><span class="params">()</span></span>;</div><div class="line">  <span class="comment">// 获取GPU data指针，并在后续将改变指针所指向内存的值</span></div><div class="line">  <span class="function"><span class="keyword">void</span>* <span class="title">mutable_gpu_data</span><span class="params">()</span></span>;</div><div class="line">  <span class="comment">// CPU 和 GPU的同步状态：未初始化，在CPU（未同步），在GPU（未同步），已同步</span></div><div class="line">  <span class="keyword">enum</span> SyncedHead &#123; UNINITIALIZED, HEAD_AT_CPU, HEAD_AT_GPU, SYNCED &#125;;</div><div class="line">  <span class="function">SyncedHead <span class="title">head</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> head_; &#125;</div><div class="line">  <span class="comment">// 内存大小</span></div><div class="line">  <span class="keyword">size_t</span> size() &#123; <span class="keyword">return</span> size_; &#125;</div><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> CPU_ONLY</span></div><div class="line">  <span class="function"><span class="keyword">void</span> <span class="title">async_gpu_push</span><span class="params">(<span class="keyword">const</span> cudaStream_t&amp; stream)</span></span>;</div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></div><div class="line"></div><div class="line"> <span class="keyword">private</span>:</div><div class="line">  <span class="function"><span class="keyword">void</span> <span class="title">check_device</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">void</span> <span class="title">to_cpu</span><span class="params">()</span></span>;</div><div class="line">  <span class="function"><span class="keyword">void</span> <span class="title">to_gpu</span><span class="params">()</span></span>;</div><div class="line">  <span class="keyword">void</span>* cpu_ptr_;</div><div class="line">  <span class="keyword">void</span>* gpu_ptr_;</div><div class="line">  <span class="keyword">size_t</span> size_;</div><div class="line">  SyncedHead head_;</div><div class="line">  <span class="keyword">bool</span> own_cpu_data_;</div><div class="line">  <span class="keyword">bool</span> cpu_malloc_use_cuda_;</div><div class="line">  <span class="keyword">bool</span> own_gpu_data_;</div><div class="line">  <span class="comment">// GPU设备编号</span></div><div class="line">  <span class="keyword">int</span> device_;</div><div class="line"></div><div class="line">  DISABLE_COPY_AND_ASSIGN(SyncedMemory);</div><div class="line">&#125;;  <span class="comment">// class SyncedMemory</span></div></pre></td></tr></table></figure><p>我们以<code>to_cpu()</code>为例，看一下如何在不同状态之间切换。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">inline</span> <span class="keyword">void</span> SyncedMemory::to_gpu() &#123;</div><div class="line">  <span class="comment">// 检查设备状态（使用条件编译，只在DEBUG中使能）</span></div><div class="line">  check_device();</div><div class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> CPU_ONLY</span></div><div class="line">  <span class="keyword">switch</span> (head_) &#123;</div><div class="line">  <span class="keyword">case</span> UNINITIALIZED:</div><div class="line">    <span class="comment">// 还没有初始化呢~所以内存啥的还没开</span></div><div class="line">    <span class="comment">// 先在GPU上开块显存吧~</span></div><div class="line">    CUDA_CHECK(cudaMalloc(&amp;gpu_ptr_, size_));</div><div class="line">    caffe_gpu_memset(size_, <span class="number">0</span>, gpu_ptr_);</div><div class="line">    <span class="comment">// 接着，改变状态标志</span></div><div class="line">    head_ = HEAD_AT_GPU;</div><div class="line">    own_gpu_data_ = <span class="literal">true</span>;</div><div class="line">    <span class="keyword">break</span>;</div><div class="line">  <span class="keyword">case</span> HEAD_AT_CPU:</div><div class="line">    <span class="comment">// 数据在CPU上~如果需要，先在显存上开内存</span></div><div class="line">    <span class="keyword">if</span> (gpu_ptr_ == <span class="literal">NULL</span>) &#123;</div><div class="line">      CUDA_CHECK(cudaMalloc(&amp;gpu_ptr_, size_));</div><div class="line">      own_gpu_data_ = <span class="literal">true</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// 数据拷贝</span></div><div class="line">    caffe_gpu_memcpy(size_, cpu_ptr_, gpu_ptr_);</div><div class="line">    <span class="comment">// 改变状态变量</span></div><div class="line">    head_ = SYNCED;</div><div class="line">    <span class="keyword">break</span>;</div><div class="line">  <span class="comment">// 已经在GPU或者已经同步了，什么都不做</span></div><div class="line">  <span class="keyword">case</span> HEAD_AT_GPU:</div><div class="line">  <span class="keyword">case</span> SYNCED:</div><div class="line">    <span class="keyword">break</span>;</div><div class="line">  &#125;</div><div class="line"><span class="meta">#<span class="meta-keyword">else</span></span></div><div class="line">  <span class="comment">// NO_GPU 是一个宏，打印FATAL ERROR日志信息</span></div><div class="line">  <span class="comment">// 编译选项没有开GPU支持，只能说 无可奉告</span></div><div class="line">  NO_GPU;</div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></div><div class="line">&#125;</div></pre></td></tr></table></figure><p>注意到，除了<code>head_</code>以外，<code>SyncedMemory</code>中还有<code>own_gpu_data_</code>（同样，也有<code>own_cpu_data_</code>）的成员。这个变量是用来标志当前CPU或GPU上有没有分配内存，从而当我们使用<code>set_c/gpu_data</code>或析构函数被调用的时候，能够正确释放内存/显存的。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;Blob&lt;/code&gt;是Caffe中的基本数据结构，类似于TensorFlow和PyTorch中的Tensor。图像读入后作为&lt;code&gt;Blob&lt;/code&gt;，开始在各个&lt;code&gt;Layer&lt;/code&gt;之间传递，最终得到输出。下面这张图展示了&lt;code&gt;Blob&lt;/code&gt;和&lt;code&gt;Layer&lt;/code&gt;之间的关系：&lt;br&gt; &lt;img src=&quot;/img/caffe_syncedmem_blob_flow.jpg&quot; width = &quot;300&quot; height = &quot;200&quot; alt=&quot;blob的流动&quot; align=center /&gt;&lt;/p&gt;
&lt;p&gt;Caffe中的&lt;code&gt;Blob&lt;/code&gt;在实现的时候，使用了&lt;code&gt;SyncedMem&lt;/code&gt;管理内存，并在内存（Host）和显存（device）之间同步。这篇博客对Caffe中&lt;code&gt;SyncedMem&lt;/code&gt;的实现做一总结。&lt;br&gt;
    
    </summary>
    
    
      <category term="caffe" scheme="https://xmfbit.github.io/tags/caffe/"/>
    
  </entry>
  
  <entry>
    <title>Caffe中的BatchNorm实现</title>
    <link href="https://xmfbit.github.io/2018/01/08/caffe-batch-norm/"/>
    <id>https://xmfbit.github.io/2018/01/08/caffe-batch-norm/</id>
    <published>2018-01-08T12:12:44.000Z</published>
    <updated>2018-03-15T06:54:37.449Z</updated>
    
    <content type="html"><![CDATA[<p>这篇博客总结了Caffe中BN的实现。<br><a id="more"></a></p><h2 id="BN简介"><a href="#BN简介" class="headerlink" title="BN简介"></a>BN简介</h2><p>由于BN技术已经有很广泛的应用，所以这里只对BN做一个简单的介绍。</p><p>BN是Batch Normalization的简称，来源于Google研究人员的论文：<a href="https://arxiv.org/pdf/1502.03167.pdf" target="_blank" rel="external">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>。对于网络的输入层，我们可以采用减去均值除以方差的方法进行归一化，对于网络中间层，BN可以实现类似的功能。</p><p>在BN层中，训练时，会对输入blob各个channel的均值和方差做一统计。在做inference的时候，我们就可以利用均值和方法，对输入$x$做如下的归一化操作。其中，$\epsilon$是为了防止除数是$0$，$i$是channel的index。</p><script type="math/tex; mode=display">\hat{x_i} = \frac{x_i-\mu_i}{\sqrt{Var(x_i)+\epsilon}}</script><p>不过如果只是做如上的操作，会影响模型的表达能力。例如，Identity Map($y = x$)就不能表示了。所以，作者提出还需要在后面添加一个线性变换，如下所示。其中，$\gamma$和$\beta$都是待学习的参数，使用梯度下降进行更新。BN的最终输出就是$y$。</p><script type="math/tex; mode=display">y_i = \gamma \hat{x_i} + \beta</script><p>如下图所示，展示了BN变换的过程。<br><img src="/img/caffe_bn_what_is_bn.jpg" alt="BN变换"></p><p>上面，我们讲的还是inference时候BN变换是什么样子的。那么，训练时候，BN是如何估计样本均值和方差的呢？下面，结合Caffe的代码进行梳理。</p><h2 id="BN-in-Caffe"><a href="#BN-in-Caffe" class="headerlink" title="BN in Caffe"></a>BN in Caffe</h2><p>在BVLC的Caffe实现中，BN层需要和Scale层配合使用。在这里，BN层专门用来做“Normalization”操作（确实是人如其名了），而后续的线性变换层，交给Scale层去做。</p><p>下面的这段代码取自He Kaiming的Residual Net50的<a href="https://github.com/KaimingHe/deep-residual-networks/blob/master/prototxt/ResNet-50-deploy.prototxt#L21" target="_blank" rel="external">模型定义文件</a>。在这里，设置<code>batch_norm_param</code>中<code>use_global_stats</code>为<code>true</code>，是指在inference阶段，我们只使用已经得到的均值和方差统计量，进行归一化处理，而不再更新这两个统计量。后面Scale层设置的<code>bias_term: true</code>是不可省略的。这个选项将其配置为线性变换层。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">bottom: &quot;conv1&quot;</div><div class="line">top: &quot;conv1&quot;</div><div class="line">name: &quot;bn_conv1&quot;</div><div class="line">type: &quot;BatchNorm&quot;</div><div class="line">batch_norm_param &#123;</div><div class="line">use_global_stats: true</div><div class="line">&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">bottom: &quot;conv1&quot;</div><div class="line">top: &quot;conv1&quot;</div><div class="line">name: &quot;scale_conv1&quot;</div><div class="line">type: &quot;Scale&quot;</div><div class="line">scale_param &#123;</div><div class="line">bias_term: true</div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>这就是Caffe中BN层的固定搭配方法。这里只是简单提到，具体参数的意义待我们深入代码可以分析。</p><h2 id="BatchNorm-层的实现"><a href="#BatchNorm-层的实现" class="headerlink" title="BatchNorm 层的实现"></a>BatchNorm 层的实现</h2><p>上面说过，Caffe中的BN层与原始论文稍有不同，只是做了输入的归一化，而后续的线性变换是交由后续的Scale层实现的。</p><h3 id="proto定义的相关参数"><a href="#proto定义的相关参数" class="headerlink" title="proto定义的相关参数"></a>proto定义的相关参数</h3><p>我们首先看一下<code>caffe.proto</code>中关于BN层参数的描述。保留了原始的英文注释，并添加了中文解释。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">message BatchNormParameter &#123;</div><div class="line">  // If false, normalization is performed over the current mini-batch</div><div class="line">  // and global statistics are accumulated (but not yet used) by a moving</div><div class="line">  // average.</div><div class="line">  // If true, those accumulated mean and variance values are used for the</div><div class="line">  // normalization.</div><div class="line">  // By default, it is set to false when the network is in the training</div><div class="line">  // phase and true when the network is in the testing phase.</div><div class="line">  // 设置为False的话，更新全局统计量，对当前的mini-batch进行规范化时，不使用全局统计量，而是</div><div class="line">  // 当前batch的均值和方差。</div><div class="line">  // 设置为True，使用全局统计量做规范化。</div><div class="line">  // 后面在BN的实现代码我们会看到，这个变量默认随着当前网络在train或test phase而变化。</div><div class="line">  // 当train时为false，当test时为true。</div><div class="line">  optional bool use_global_stats = 1;</div><div class="line">  </div><div class="line">  // What fraction of the moving average remains each iteration?</div><div class="line">  // Smaller values make the moving average decay faster, giving more</div><div class="line">  // weight to the recent values.</div><div class="line">  // Each iteration updates the moving average @f$S_&#123;t-1&#125;@f$ with the</div><div class="line">  // current mean @f$ Y_t @f$ by</div><div class="line">  // @f$ S_t = (1-\beta)Y_t + \beta \cdot S_&#123;t-1&#125; @f$, where @f$ \beta @f$</div><div class="line">  // is the moving_average_fraction parameter.</div><div class="line">  // BN在统计全局均值和方差信息时，使用的是滑动平均法，也就是</div><div class="line">  // St = (1-beta)*Yt + beta*S_&#123;t-1&#125;</div><div class="line">  // 其中St为当前估计出来的全局统计量（均值或方差），Yt为当前batch的均值或方差</div><div class="line">  // beta是滑动因子。其实这是一种很常见的平滑滤波的方法。</div><div class="line">  optional float moving_average_fraction = 2 [default = .999];</div><div class="line">  </div><div class="line">  // Small value to add to the variance estimate so that we don&apos;t divide by</div><div class="line">  // zero.</div><div class="line">  // 防止除数为0加上去的eps</div><div class="line">  optional float eps = 3 [default = 1e-5];</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><p>OK。现在可以进入BN的代码实现了。阅读大部分代码都没有什么难度，下面主要结合代码讲解<code>use_global_stats</code>变量的作用和均值（方差同理）的计算。由于均值和方差的计算原理相近，所以下面只会详细介绍均值的计算。</p><h3 id="SetUp"><a href="#SetUp" class="headerlink" title="SetUp"></a>SetUp</h3><p>BN层的SetUp代码如下。首先，会根据当前处于train还是test决定是否使用全局的统计量。如果prototxt文件中设置了<code>use_global_stats</code>标志，则会使用用户给定的配置。所以一般在使用BN时，无需对<code>use_global_stats</code>进行配置。</p><p>这里有一个地方容易迷惑。BN中要对样本的均值和方差进行统计，即我们需要两个blob来存储。但是从下面的代码可以看到，BN一共有3个blob作为参数。这里做一解释，主要参考了wiki的<a href="https://wiki2.org/en/Moving_average" target="_blank" rel="external">moving average条目</a>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line"><span class="keyword">void</span> BatchNormLayer&lt;Dtype&gt;::LayerSetUp(<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div><div class="line">      <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</div><div class="line">  BatchNormParameter param = <span class="keyword">this</span>-&gt;layer_param_.batch_norm_param();</div><div class="line">  moving_average_fraction_ = param.moving_average_fraction();</div><div class="line">  <span class="comment">// 默认根据当前是否处在TEST模式而决定是否使用全局mean和var</span></div><div class="line">  use_global_stats_ = <span class="keyword">this</span>-&gt;phase_ == TEST;</div><div class="line">  <span class="keyword">if</span> (param.has_use_global_stats())</div><div class="line">    use_global_stats_ = param.use_global_stats();</div><div class="line">  <span class="comment">// 得到channels数量</span></div><div class="line">  <span class="comment">// 为了防止越界，首先检查输入是否为1D</span></div><div class="line">  <span class="keyword">if</span> (bottom[<span class="number">0</span>]-&gt;num_axes() == <span class="number">1</span>)</div><div class="line">    channels_ = <span class="number">1</span>;</div><div class="line">  <span class="keyword">else</span></div><div class="line">    channels_ = bottom[<span class="number">0</span>]-&gt;shape(<span class="number">1</span>);</div><div class="line">  eps_ = param.eps();</div><div class="line">  <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;blobs_.size() &gt; <span class="number">0</span>) &#123;</div><div class="line">    LOG(INFO) &lt;&lt; <span class="string">"Skipping parameter initialization"</span>;</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    <span class="comment">// 参数共3个</span></div><div class="line">    <span class="keyword">this</span>-&gt;blobs_.resize(<span class="number">3</span>);</div><div class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; sz;</div><div class="line">    sz.push_back(channels_);</div><div class="line">    <span class="comment">// mean 和var都是1D的长度为channels的向量</span></div><div class="line">    <span class="comment">// 因为在规范化过程中，要逐channel进行，即：</span></div><div class="line">    <span class="comment">// for c in range(channels):</span></div><div class="line">    <span class="comment">//     x_hat[c] = (x[c] - mean[c]) / std[c]</span></div><div class="line">    <span class="keyword">this</span>-&gt;blobs_[<span class="number">0</span>].reset(<span class="keyword">new</span> Blob&lt;Dtype&gt;(sz));</div><div class="line">    <span class="keyword">this</span>-&gt;blobs_[<span class="number">1</span>].reset(<span class="keyword">new</span> Blob&lt;Dtype&gt;(sz));</div><div class="line">    <span class="comment">// 这里的解释见下</span></div><div class="line">    sz[<span class="number">0</span>] = <span class="number">1</span>;</div><div class="line">    <span class="keyword">this</span>-&gt;blobs_[<span class="number">2</span>].reset(<span class="keyword">new</span> Blob&lt;Dtype&gt;(sz));</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">3</span>; ++i) &#123;</div><div class="line">      caffe_set(<span class="keyword">this</span>-&gt;blobs_[i]-&gt;count(), Dtype(<span class="number">0</span>),</div><div class="line">                <span class="keyword">this</span>-&gt;blobs_[i]-&gt;mutable_cpu_data());</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="comment">// Mask statistics from optimization by setting local learning rates</span></div><div class="line">  <span class="comment">// for mean, variance, and the bias correction to zero.</span></div><div class="line">  <span class="comment">// mean 和 std在训练的时候是不需要梯度下降来更新的，这里强制把其learning rate</span></div><div class="line">  <span class="comment">// 设置为0</span></div><div class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>-&gt;blobs_.size(); ++i) &#123;</div><div class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;layer_param_.param_size() == i) &#123;</div><div class="line">      ParamSpec* fixed_param_spec = <span class="keyword">this</span>-&gt;layer_param_.add_param();</div><div class="line">      fixed_param_spec-&gt;set_lr_mult(<span class="number">0.f</span>);</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      CHECK_EQ(<span class="keyword">this</span>-&gt;layer_param_.param(i).lr_mult(), <span class="number">0.f</span>)</div><div class="line">          &lt;&lt; <span class="string">"Cannot configure batch normalization statistics as layer "</span></div><div class="line">          &lt;&lt; <span class="string">"parameters."</span>;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>在求取某个流数据（stream）的平均值的时候，常用的一种方法是滑动平均法，也就是使用系数$\alpha$来做平滑滤波，如下所示：</p><script type="math/tex; mode=display">S_t = \alpha Y_t + (1-\alpha) S_{t-1}</script><p>上面的式子等价于：</p><script type="math/tex; mode=display">S_t = \frac{\text{WeightedSum}_n}{\text{WeightedCount}_n}</script><p>其中，<script type="math/tex">\text{WeightedSum}_n = Y_t + (1-\alpha) \text{WeightedSum}_{n-1}</script></p><script type="math/tex; mode=display">\text{WeightedCount}_n = 1 + (1-\alpha) \text{WeightedCount}_{n-1}</script><p>而Caffe中BN的实现中，<code>blobs_[0]</code>和<code>blobs_[1]</code>中存储的实际是$\text{WeightedSum}_n$，而<code>blos_[2]</code>中存储的是$\text{WeightedCount}_n$。所以，真正的mean和var是两者相除的结果。即：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mu = blobs_[0] / blobs_[2]</div><div class="line">var = blobs_[1] / blobs_[2]</div></pre></td></tr></table></figure></p><h3 id="Forward"><a href="#Forward" class="headerlink" title="Forward"></a>Forward</h3><p>下面是Forward CPU的代码。主要应该注意当前batch的mean和var的求法。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line"><span class="keyword">void</span> BatchNormLayer&lt;Dtype&gt;::Forward_cpu(<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div><div class="line">    <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</div><div class="line">  <span class="keyword">const</span> Dtype* bottom_data = bottom[<span class="number">0</span>]-&gt;cpu_data();</div><div class="line">  Dtype* top_data = top[<span class="number">0</span>]-&gt;mutable_cpu_data();</div><div class="line">  <span class="keyword">int</span> num = bottom[<span class="number">0</span>]-&gt;shape(<span class="number">0</span>);</div><div class="line">  <span class="keyword">int</span> spatial_dim = bottom[<span class="number">0</span>]-&gt;count()/(bottom[<span class="number">0</span>]-&gt;shape(<span class="number">0</span>)*channels_);</div><div class="line"></div><div class="line">  <span class="comment">// 如果不是就地操作，首先将bottom的数据复制到top</span></div><div class="line">  <span class="keyword">if</span> (bottom[<span class="number">0</span>] != top[<span class="number">0</span>]) &#123;</div><div class="line">    caffe_copy(bottom[<span class="number">0</span>]-&gt;count(), bottom_data, top_data);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// 如果使用全局统计量，我们需要先计算出真正的mean和var</span></div><div class="line">  <span class="keyword">if</span> (use_global_stats_) &#123;</div><div class="line">    <span class="comment">// use the stored mean/variance estimates.</span></div><div class="line">    <span class="keyword">const</span> Dtype scale_factor = <span class="keyword">this</span>-&gt;blobs_[<span class="number">2</span>]-&gt;cpu_data()[<span class="number">0</span>] == <span class="number">0</span> ?</div><div class="line">        <span class="number">0</span> : <span class="number">1</span> / <span class="keyword">this</span>-&gt;blobs_[<span class="number">2</span>]-&gt;cpu_data()[<span class="number">0</span>];</div><div class="line">    <span class="comment">// mean = blobs[0] / blobs[2]</span></div><div class="line">    caffe_cpu_scale(variance_.count(), scale_factor,</div><div class="line">        <span class="keyword">this</span>-&gt;blobs_[<span class="number">0</span>]-&gt;cpu_data(), mean_.mutable_cpu_data());</div><div class="line">    <span class="comment">// var = blobs[1] / blobs[2]</span></div><div class="line">    caffe_cpu_scale(variance_.count(), scale_factor,</div><div class="line">        <span class="keyword">this</span>-&gt;blobs_[<span class="number">1</span>]-&gt;cpu_data(), variance_.mutable_cpu_data());</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    <span class="comment">// 不使用全局统计量时，我们要根据当前batch的mean和var做规范化</span></div><div class="line">    <span class="comment">// compute mean</span></div><div class="line">    <span class="comment">// spatial_sum_multiplier_是全1向量</span></div><div class="line">    <span class="comment">// batch_sum_multiplier_也是全1向量</span></div><div class="line">    <span class="comment">// gemv做矩阵与向量相乘 y = alpha*A*x + beta*y。</span></div><div class="line">    <span class="comment">// 下面式子是将bottom_data这个矩阵与一个全1向量相乘，</span></div><div class="line">    <span class="comment">// 相当于是在统计行和。</span></div><div class="line">    <span class="comment">// 注意第二个参数channels_ * num指矩阵的行数，第三个参数是矩阵的列数</span></div><div class="line">    <span class="comment">// 所以这是在计算每个channel的feature map的和</span></div><div class="line">    <span class="comment">// 结果out[n][c]是指输入第n个sample的第c个channel的和</span></div><div class="line">    <span class="comment">// 同时，传入了 1. / (num * spatial_dim) 作为因子乘到结果上面，作用见下面</span></div><div class="line">    caffe_cpu_gemv&lt;Dtype&gt;(CblasNoTrans, channels_ * num, spatial_dim,</div><div class="line">        <span class="number">1.</span> / (num * spatial_dim), bottom_data,</div><div class="line">        spatial_sum_multiplier_.cpu_data(), <span class="number">0.</span>,</div><div class="line">        num_by_chans_.mutable_cpu_data());</div><div class="line">    <span class="comment">// 道理和上面相同，注意下面通过传入CblasTrans，指定了矩阵要转置。所以是在求列和</span></div><div class="line">    <span class="comment">// 这样，就求出了各个channel的和。</span></div><div class="line">    <span class="comment">// 上面不是已经除了 num * spatial_dim 吗？这就是求和元素的总数量</span></div><div class="line">    <span class="comment">// 到此，我们就完成了对当前batch的平均值的求解</span></div><div class="line">    caffe_cpu_gemv&lt;Dtype&gt;(CblasTrans, num, channels_, <span class="number">1.</span>,</div><div class="line">        num_by_chans_.cpu_data(), batch_sum_multiplier_.cpu_data(), <span class="number">0.</span>,</div><div class="line">        mean_.mutable_cpu_data());</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// subtract mean</span></div><div class="line">  <span class="comment">// gemm是在做矩阵与矩阵相乘 C = alpha*A*B + beta*C</span></div><div class="line">  <span class="comment">// 下面这个是在做broadcasting subtraction</span></div><div class="line">  caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasNoTrans, num, channels_, <span class="number">1</span>, <span class="number">1</span>,</div><div class="line">      batch_sum_multiplier_.cpu_data(), mean_.cpu_data(), <span class="number">0.</span>,</div><div class="line">      num_by_chans_.mutable_cpu_data());</div><div class="line">  caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasNoTrans, channels_ * num,</div><div class="line">      spatial_dim, <span class="number">1</span>, <span class="number">-1</span>, num_by_chans_.cpu_data(),</div><div class="line">      spatial_sum_multiplier_.cpu_data(), <span class="number">1.</span>, top_data);</div><div class="line"></div><div class="line">  <span class="comment">// 计算当前的var</span></div><div class="line">  <span class="keyword">if</span> (!use_global_stats_) &#123;</div><div class="line">    <span class="comment">// compute variance using var(X) = E((X-EX)^2)</span></div><div class="line">    caffe_sqr&lt;Dtype&gt;(top[<span class="number">0</span>]-&gt;count(), top_data,</div><div class="line">                     temp_.mutable_cpu_data());  <span class="comment">// (X-EX)^2</span></div><div class="line">    caffe_cpu_gemv&lt;Dtype&gt;(CblasNoTrans, channels_ * num, spatial_dim,</div><div class="line">        <span class="number">1.</span> / (num * spatial_dim), temp_.cpu_data(),</div><div class="line">        spatial_sum_multiplier_.cpu_data(), <span class="number">0.</span>,</div><div class="line">        num_by_chans_.mutable_cpu_data());</div><div class="line">    caffe_cpu_gemv&lt;Dtype&gt;(CblasTrans, num, channels_, <span class="number">1.</span>,</div><div class="line">        num_by_chans_.cpu_data(), batch_sum_multiplier_.cpu_data(), <span class="number">0.</span>,</div><div class="line">        variance_.mutable_cpu_data());  <span class="comment">// E((X_EX)^2)</span></div><div class="line"></div><div class="line">    <span class="comment">// compute and save moving average</span></div><div class="line">    <span class="comment">// 做滑动平均，更新全局统计量，这里可以参见上面的式子</span></div><div class="line">    <span class="keyword">this</span>-&gt;blobs_[<span class="number">2</span>]-&gt;mutable_cpu_data()[<span class="number">0</span>] *= moving_average_fraction_;</div><div class="line">    <span class="keyword">this</span>-&gt;blobs_[<span class="number">2</span>]-&gt;mutable_cpu_data()[<span class="number">0</span>] += <span class="number">1</span>;</div><div class="line">    caffe_cpu_axpby(mean_.count(), Dtype(<span class="number">1</span>), mean_.cpu_data(),</div><div class="line">        moving_average_fraction_, <span class="keyword">this</span>-&gt;blobs_[<span class="number">0</span>]-&gt;mutable_cpu_data());</div><div class="line">    <span class="keyword">int</span> m = bottom[<span class="number">0</span>]-&gt;count()/channels_;</div><div class="line">    Dtype bias_correction_factor = m &gt; <span class="number">1</span> ? Dtype(m)/(m<span class="number">-1</span>) : <span class="number">1</span>;</div><div class="line">    caffe_cpu_axpby(variance_.count(), bias_correction_factor,</div><div class="line">        variance_.cpu_data(), moving_average_fraction_,</div><div class="line">        <span class="keyword">this</span>-&gt;blobs_[<span class="number">1</span>]-&gt;mutable_cpu_data());</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// normalize variance</span></div><div class="line">  caffe_add_scalar(variance_.count(), eps_, variance_.mutable_cpu_data());</div><div class="line">  caffe_sqrt(variance_.count(), variance_.cpu_data(),</div><div class="line">             variance_.mutable_cpu_data());</div><div class="line"></div><div class="line">  <span class="comment">// replicate variance to input size</span></div><div class="line">  <span class="comment">// 同样是在做broadcasting</span></div><div class="line">  caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasNoTrans, num, channels_, <span class="number">1</span>, <span class="number">1</span>,</div><div class="line">      batch_sum_multiplier_.cpu_data(), variance_.cpu_data(), <span class="number">0.</span>,</div><div class="line">      num_by_chans_.mutable_cpu_data());</div><div class="line">  caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasNoTrans, channels_ * num,</div><div class="line">      spatial_dim, <span class="number">1</span>, <span class="number">1.</span>, num_by_chans_.cpu_data(),</div><div class="line">      spatial_sum_multiplier_.cpu_data(), <span class="number">0.</span>, temp_.mutable_cpu_data());</div><div class="line">  caffe_div(temp_.count(), top_data, temp_.cpu_data(), top_data);</div><div class="line">  <span class="comment">// TODO(cdoersch): The caching is only needed because later in-place layers</span></div><div class="line">  <span class="comment">//                 might clobber the data.  Can we skip this if they won't?</span></div><div class="line">  caffe_copy(x_norm_.count(), top_data,</div><div class="line">      x_norm_.mutable_cpu_data());</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><p>由上面的计算过程不难得出，当经过很多轮迭代之后，<code>blobs_[2]</code>的值会趋于稳定。下面我们使用$m_t$来表示第$t$轮迭代后的<code>blobs_[2]</code>的值，也就是$\text{WeightedCount}_n$，使用$\alpha$表示<code>moving_average_fraction_</code>，那么我们有：</p><script type="math/tex; mode=display">m_t = 1 + \alpha m_{t-1}</script><p>可以求取$m_t$的通项后令$t=\infty$，可以得到，$m_{\infty}=\frac{1}{1-\alpha}$。</p><h3 id="Backward"><a href="#Backward" class="headerlink" title="Backward"></a>Backward</h3><p>在做BP的时候，我们需要分情况讨论。</p><ul><li>当<code>use_global_stats == true</code>的时候，BN所做的操作是一个线性变换<script type="math/tex; mode=display">BN(x) = \frac{x-\mu}{\sqrt{Var}}</script>所以<script type="math/tex; mode=display">\frac{\partial L}{\partial x} = \frac{1}{\sqrt{Var}}\frac{\partial L}{\partial y}</script></li></ul><p>对应的代码如下。其中，<code>temp_</code>是broadcasting之后的输入<code>x</code>的标准差（见上面<code>Forward</code>部分的代码最后），做逐元素的除法即可。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> (use_global_stats_) &#123;</div><div class="line">  caffe_div(temp_.count(), top_diff, temp_.cpu_data(), bottom_diff);</div><div class="line">  <span class="keyword">return</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><ul><li>当<code>use_global_stats == false</code>的时候，BN所做操作虽然也是上述线性变换。但是注意，现在式子里面的$\mu$和$Var(x)$都是当前batch计算出来的，也就是它们都是输入<code>x</code>的函数。所以就麻烦了不少。这里我并没有推导，而是看了<a href="https://kevinzakka.github.io/2016/09/14/batch_normalization/" target="_blank" rel="external">这篇博客</a>，里面有详细的推导过程，写的很易懂。我将最后的结果贴在下面，对计算过程感兴趣的可以去原文章查看。<br><img src="/img/caffe_bn_bp_of_bn.jpg" alt="BP的推导结果"></li></ul><p>我们使用$y$来代替上面的$\hat{x_i}$，并且上下同时除以$m$，就可以得到Caffe BN代码中所给的BP式子：</p><script type="math/tex; mode=display">\frac{\partial f}{\partial x_i} = \frac{\frac{\partial f}{\partial y}-E[\frac{\partial f}{\partial y}]-yE[\frac{\partial f}{\partial y}y]}{\sqrt{\sigma^2+\epsilon}}</script><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// if Y = (X-mean(X))/(sqrt(var(X)+eps)), then</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">// dE(Y)/dX =</span></div><div class="line"><span class="comment">//   (dE/dY - mean(dE/dY) - mean(dE/dY \cdot Y) \cdot Y)</span></div><div class="line"><span class="comment">//     ./ sqrt(var(X) + eps)</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">// where \cdot and ./ are hadamard product and elementwise division,</span></div><div class="line"><span class="comment">// respectively, dE/dY is the top diff, and mean/var/sum are all computed</span></div><div class="line"><span class="comment">// along all dimensions except the channels dimension.  In the above</span></div><div class="line"><span class="comment">// equation, the operations allow for expansion (i.e. broadcast) along all</span></div><div class="line"><span class="comment">// dimensions except the channels dimension where required.</span></div></pre></td></tr></table></figure><p>下面的代码部分就是实现上面这个式子的内容，注释很详细，要解决的一个比较棘手的问题就是broadcasting，这个有兴趣可以看一下。对Caffe中BN的介绍就到这里。下面介绍与BN经常成对出现的Scale层。</p><h2 id="Scale层的实现"><a href="#Scale层的实现" class="headerlink" title="Scale层的实现"></a>Scale层的实现</h2><p>Caffe中将后续的线性变换使用单独的Scale层实现。Caffe中的Scale可以根据需要配置成不同的模式：</p><ul><li>当输入blob为两个时，计算输入blob的逐元素乘的结果（维度不相同时，第二个blob可以做broadcasting）。</li><li>当输入blob为一个时，计算输入blob与一个可学习参数<code>gamma</code>的按元素相乘结果。</li><li>当设置<code>bias_term: true</code>时，添加一个偏置项。</li></ul><p>用于BN的线性变换的计算方法很直接，这里不再多说了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇博客总结了Caffe中BN的实现。&lt;br&gt;
    
    </summary>
    
    
      <category term="caffe" scheme="https://xmfbit.github.io/tags/caffe/"/>
    
  </entry>
  
  <entry>
    <title>shell编程</title>
    <link href="https://xmfbit.github.io/2017/11/10/shell-programming/"/>
    <id>https://xmfbit.github.io/2017/11/10/shell-programming/</id>
    <published>2017-11-10T05:06:30.000Z</published>
    <updated>2018-03-15T06:54:37.462Z</updated>
    
    <content type="html"><![CDATA[<p>介绍基本的shell编程方法，参考的教程是<a href="http://www.freeos.com/guides/lsst/" target="_blank" rel="external">Linux Shell Scripting Tutorial, A Beginner’s handbook</a>。<br><img src="/img/shell-programming-bash-logo.png" alt="Bash Logo"><br><a id="more"></a></p><h2 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h2><p>变量是代码的基本组成元素。可以认为shell中的变量类型都是字符串。</p><p>shell中的变量可以分为两类：系统变量和用户自定义变量。下面分别进行介绍。</p><p>在代码中使用变量值的时候，需要在前面加上<code>$</code>。<code>echo</code>命令可以在控制台打印相应输出。所以使用<code>echo $var</code>就可以输出变量<code>var</code>的值。</p><h3 id="系统变量"><a href="#系统变量" class="headerlink" title="系统变量"></a>系统变量</h3><p>系统变量是指Linux中自带的一些变量。例如<code>HOME</code>,<code>PATH</code>等。其中<code>PATH</code>又叫环境变量。更多的系统变量见下表：<br><img src="/img/shell-programming-system-variables.jpg" alt="系统变量列表"></p><h3 id="用户定义的变量"><a href="#用户定义的变量" class="headerlink" title="用户定义的变量"></a>用户定义的变量</h3><p>用户自定义变量是用户命名并赋值的变量。使用下面的方法定义：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 注意不要在等号两边插入空格</span></div><div class="line">name=value</div><div class="line"><span class="comment"># 如 n=10</span></div></pre></td></tr></table></figure><h3 id="局部变量和全局变量"><a href="#局部变量和全局变量" class="headerlink" title="局部变量和全局变量"></a>局部变量和全局变量</h3><p>局部变量是指在当前代码块内可见的变量，使用<code>local</code>声明。例如下面的代码，将依次输出：111, 222, 111.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#! /bin/sh</span></div><div class="line">num=111 <span class="comment"># 全局变量</span></div><div class="line"><span class="function"><span class="title">func1</span></span>()</div><div class="line">&#123;</div><div class="line">  <span class="built_in">local</span> num=222 <span class="comment"># 局部变量</span></div><div class="line">  <span class="built_in">echo</span> <span class="variable">$num</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="built_in">echo</span> <span class="string">"before---<span class="variable">$num</span>"</span></div><div class="line">func1</div><div class="line"><span class="built_in">echo</span> <span class="string">"after---<span class="variable">$num</span>"</span></div></pre></td></tr></table></figure></p><h3 id="变量之间的运算"><a href="#变量之间的运算" class="headerlink" title="变量之间的运算"></a>变量之间的运算</h3><p>使用<code>expr</code>可以进行变量之间的运算，如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 注意要在操作符两边空余空格</span></div><div class="line">expr 1 + 3</div><div class="line"><span class="comment"># 由于*是特殊字符，所以乘法要使用转义</span></div><div class="line">expr 10 \* 2</div></pre></td></tr></table></figure><h3 id="和””"><a href="#和””" class="headerlink" title="``和””"></a>``和””</h3><p>使用``（也就是TAB键上面的那个）包起来的部分，是可执行的命令。而使用””（引号）包起来的部分，是字符串。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">a=`expr 10 \* 3`</div><div class="line"><span class="comment"># output: 3</span></div><div class="line"><span class="built_in">echo</span> <span class="variable">$a</span></div><div class="line"><span class="comment"># output: a</span></div><div class="line"><span class="built_in">echo</span> a</div><div class="line"><span class="comment"># output: expr 10 \* 3</span></div><div class="line">a=<span class="string">"expr 10 \* 3"</span></div><div class="line"><span class="built_in">echo</span> <span class="variable">$a</span></div></pre></td></tr></table></figure><p>另外，使用””（双引号）括起来的字符串会发生变量替换，而用’’（单引号）括起来的字符串则不会。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">a=1</div><div class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$a</span>"</span>  <span class="comment"># 输出 1</span></div><div class="line"><span class="built_in">echo</span> <span class="string">'$a'</span>  <span class="comment"># 输出 $a</span></div></pre></td></tr></table></figure><h3 id="读取输入"><a href="#读取输入" class="headerlink" title="读取输入"></a>读取输入</h3><p>使用<code>read var1, var2, ...</code>的方式从键盘的输入读取变量的值。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># input a=1</span></div><div class="line"><span class="built_in">read</span> a</div><div class="line"><span class="comment"># ouptut: 2</span></div><div class="line"><span class="built_in">echo</span> `expr <span class="variable">$a</span> + 1`</div></pre></td></tr></table></figure><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="命令的返回值"><a href="#命令的返回值" class="headerlink" title="命令的返回值"></a>命令的返回值</h3><p>当bash命令成功执行后，返回给系统的返回值为<code>0</code>；否则为非零。可以据此判断上步操作的状态。使用<code>$?</code>可以取出上一步执行的返回值。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 将echo 错输为ecoh</span></div><div class="line">ecoh <span class="string">"hello"</span></div><div class="line"><span class="comment"># output: 非零(127)</span></div><div class="line"><span class="built_in">echo</span> $?</div><div class="line"><span class="comment"># output: 0</span></div><div class="line"><span class="built_in">echo</span> $?</div></pre></td></tr></table></figure><h3 id="通配符"><a href="#通配符" class="headerlink" title="通配符"></a>通配符</h3><p>通配符是指<code>*</code>,<code>?</code>和<code>[...]</code>这三类。</p><p><code>*</code>可以匹配任意多的字符，<code>?</code>用来匹配一个字符。<code>[...]</code>用来匹配括号内的字符。见下表。<br><img src="/img/shell-programming-wild-cards.jpg" alt="通配符"></p><p><code>[...]</code>表示法还有如下变形：</p><ul><li>使用<code>-</code>用来指示范围。如<code>[a-z]</code>，表示<code>a</code>到<code>z</code>间任意一个字符。</li><li>使用<code>^</code>或<code>!</code>表示取反。如<code>[!a-p]</code>表示除了<code>a</code>到<code>p</code>间字符的其他字符。</li></ul><h3 id="输入输出重定向"><a href="#输入输出重定向" class="headerlink" title="输入输出重定向"></a>输入输出重定向</h3><p>重定向是指改变命令的输出位置。使用<code>&gt;</code>进行输出重定向。使用<code>&lt;</code>进行输入重定向。例如，<code>ls -l &gt; a.txt</code>，将本目录下的文件信息输出到文本文件<code>a.txt</code>中，而不再输出到终端。</p><p>此外，<code>&gt;&gt;</code>同样是输出重定向。但是它会在文件末尾追加写入，不会覆盖文件的原有内容。</p><p>搭配使用<code>&lt;</code>和<code>&gt;</code>可以做文件处理。例如，<code>tr group1 group2</code>命令可以将<code>group1</code>中的字符变换为<code>group2</code>中对应位置的字符。使用如下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tr <span class="string">"[a-z]"</span> <span class="string">"A-Z"</span> &lt; ori.txt &gt; out.txt</div></pre></td></tr></table></figure><p>可以将<code>ori.txt</code>中的小写字母转换为大写字母输出到<code>out.txt</code>中。</p><h3 id="管道（pipeline）"><a href="#管道（pipeline）" class="headerlink" title="管道（pipeline）"></a>管道（pipeline）</h3><p>管道<code>|</code>可以将第一个程序的输出作为第二个程序的输入。例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cat ori.txt | tr <span class="string">"[a-z]"</span> <span class="string">"A-Z"</span></div></pre></td></tr></table></figure><p>会将<code>ori.txt</code>中的小写字母转换为大写，并在终端输出。</p><h3 id="过滤器（Filter）"><a href="#过滤器（Filter）" class="headerlink" title="过滤器（Filter）"></a>过滤器（Filter）</h3><p>Filter是指那些输入和输出都是控制台的命令。通过Filter和输入输出重定向，可以很方便地对文件内容进行整理。例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sort &lt; names.txt | uniq &gt; u_names.txt</div></pre></td></tr></table></figure><p><code>uniq</code>命令可以实现去重，但是需要首先对输入数据进行排序。上面的Filter可以将输入文件<code>names.txt</code>中的行文本去重后输出到<code>u_names.txt</code>中去。</p><h2 id="控制流"><a href="#控制流" class="headerlink" title="控制流"></a>控制流</h2><h3 id="if-条件控制"><a href="#if-条件控制" class="headerlink" title="if 条件控制"></a>if 条件控制</h3><p>在bash中使用<code>if</code>条件控制的语法和MATLAB等很像，要在末尾加上类似<code>end</code>的指示符，如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> condition</div><div class="line"><span class="keyword">then</span> </div><div class="line">XXX</div><div class="line"><span class="keyword">fi</span></div></pre></td></tr></table></figure><p>或者加上<code>else</code>，使用如下的形式：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> condition</div><div class="line"><span class="keyword">then</span></div><div class="line">    <span class="keyword">do</span> something</div><div class="line"><span class="keyword">elif</span> condition</div><div class="line"><span class="keyword">then</span></div><div class="line">    <span class="keyword">do</span> something</div><div class="line"><span class="keyword">else</span></div><div class="line">    <span class="keyword">do</span> something</div><div class="line"><span class="keyword">fi</span></div></pre></td></tr></table></figure></p><p>那么，如何做逻辑运算呢？需要借助<code>test</code>关键字。</p><p>对于整数来说，我们可以使用<code>if test op1 oprator op2</code>的方式，判断操作数<code>op1</code>和<code>op2</code>的大小关系。其中，<code>operator</code>可以是<code>-gt</code>，<code>-eq</code>等。</p><p>或者另一种写法：<code>if [ op1 operator op2 ]</code>，但是注意后者<code>[]</code>与操作数之间有空格。<br>如下表所示（点击可放大）：</p><p><img src="/img/shell-programming-if-operators.jpg" alt="比较整数的逻辑运算"></p><p>对于字符串，支持的逻辑判断如下：<br><img src="/img/bash-programming-comparing-string.jpg" alt="比较字符串的逻辑运算"></p><p>举个例子，我们想判断输入的值是否为1或2，可以使用如下的脚本。注意<code>[]</code>的两边一定要加空格。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#! /bin/bash</span></div><div class="line">a=1</div><div class="line"><span class="keyword">if</span> [ <span class="variable">$1</span>=<span class="variable">$a</span> ]</div><div class="line"><span class="keyword">then</span></div><div class="line">    <span class="built_in">echo</span> <span class="string">"you input 1"</span></div><div class="line"><span class="keyword">elif</span> [ <span class="variable">$1</span>=2 ]</div><div class="line"><span class="keyword">then</span></div><div class="line">    <span class="built_in">echo</span> <span class="string">"you input 2"</span></div><div class="line"><span class="keyword">else</span></div><div class="line">    <span class="built_in">echo</span> <span class="string">"you input <span class="variable">$1</span>"</span></div><div class="line"><span class="keyword">fi</span></div></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;介绍基本的shell编程方法，参考的教程是&lt;a href=&quot;http://www.freeos.com/guides/lsst/&quot;&gt;Linux Shell Scripting Tutorial, A Beginner’s handbook&lt;/a&gt;。&lt;br&gt;&lt;img src=&quot;/img/shell-programming-bash-logo.png&quot; alt=&quot;Bash Logo&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="linux" scheme="https://xmfbit.github.io/tags/linux/"/>
    
      <category term="shell" scheme="https://xmfbit.github.io/tags/shell/"/>
    
  </entry>
  
</feed>
