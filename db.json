{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/img/corner_type_1.png","path":"img/corner_type_1.png","modified":0,"renderable":0},{"_id":"source/img/line_fit_demo.png","path":"img/line_fit_demo.png","modified":0,"renderable":0},{"_id":"source/img/ransac_step.png","path":"img/ransac_step.png","modified":0,"renderable":0},{"_id":"source/img/rotation.png","path":"img/rotation.png","modified":0,"renderable":0},{"_id":"source/img/sift_dominant_orientation.png","path":"img/sift_dominant_orientation.png","modified":0,"renderable":0},{"_id":"source/img/svd_ranking.png","path":"img/svd_ranking.png","modified":0,"renderable":0},{"_id":"source/img/canny_linking.png","path":"img/canny_linking.png","modified":0,"renderable":0},{"_id":"source/img/canny_nms.png","path":"img/canny_nms.png","modified":0,"renderable":0},{"_id":"source/img/corner_window_fun.png","path":"img/corner_window_fun.png","modified":0,"renderable":0},{"_id":"source/img/edge_deriative.png","path":"img/edge_deriative.png","modified":0,"renderable":0},{"_id":"source/img/harris_non_scale_constant.png","path":"img/harris_non_scale_constant.png","modified":0,"renderable":0},{"_id":"source/img/patch_average_intensity_scale_constant.png","path":"img/patch_average_intensity_scale_constant.png","modified":0,"renderable":0},{"_id":"source/img/sift_detection_maximum.png","path":"img/sift_detection_maximum.png","modified":0,"renderable":0},{"_id":"source/img/svd_superman.png","path":"img/svd_superman.png","modified":0,"renderable":0},{"_id":"source/img/corner_judge.png","path":"img/corner_judge.png","modified":0,"renderable":0},{"_id":"source/img/corner_judge_2.png","path":"img/corner_judge_2.png","modified":0,"renderable":0},{"_id":"source/img/fun_noise.png","path":"img/fun_noise.png","modified":0,"renderable":0},{"_id":"source/img/original_superman.png","path":"img/original_superman.png","modified":0,"renderable":0},{"_id":"source/img/ransac_k.png","path":"img/ransac_k.png","modified":0,"renderable":0},{"_id":"source/img/what_is_corner.png","path":"img/what_is_corner.png","modified":0,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"source/avatar/liumengli.jpg","path":"avatar/liumengli.jpg","modified":0,"renderable":0},{"_id":"source/img/svd_flower.png","path":"img/svd_flower.png","modified":0,"renderable":0},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"source/img/dog_x.png","path":"img/dog_x.png","modified":0,"renderable":0},{"_id":"source/img/ransac_line_fit.png","path":"img/ransac_line_fit.png","modified":0,"renderable":0},{"_id":"source/img/sift_dog.png","path":"img/sift_dog.png","modified":0,"renderable":0},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"source/img/sift_experiment_1.png","path":"img/sift_experiment_1.png","modified":0,"renderable":0},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"source/img/convolution.png","path":"img/convolution.png","modified":0,"renderable":0},{"_id":"source/img/dog_different_size.png","path":"img/dog_different_size.png","modified":0,"renderable":0},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"source/img/sift_experiment_2.png","path":"img/sift_experiment_2.png","modified":0,"renderable":0},{"_id":"source/img/projective_geometry_property_1.png","path":"img/projective_geometry_property_1.png","modified":0,"renderable":0},{"_id":"source/img/projective_geometry_property_2.png","path":"img/projective_geometry_property_2.png","modified":0,"renderable":0},{"_id":"source/img/camera_geometry_application.png","path":"img/camera_geometry_application.png","modified":0,"renderable":0},{"_id":"source/img/image_matching_hard.png","path":"img/image_matching_hard.png","modified":0,"renderable":0},{"_id":"source/img/pinhole_camera_model.png","path":"img/pinhole_camera_model.png","modified":1,"renderable":0},{"_id":"source/img/qicizuobiao.png","path":"img/qicizuobiao.png","modified":1,"renderable":0},{"_id":"source/img/qicizuobiao_transform.png","path":"img/qicizuobiao_transform.png","modified":1,"renderable":0},{"_id":"source/img/case_1_m.png","path":"img/case_1_m.png","modified":1,"renderable":0},{"_id":"source/img/case_2_m.png","path":"img/case_2_m.png","modified":1,"renderable":0},{"_id":"source/img/case_3_m.png","path":"img/case_3_m.png","modified":1,"renderable":0},{"_id":"source/img/camera_skew.png","path":"img/camera_skew.png","modified":1,"renderable":0},{"_id":"source/img/case_4_m.png","path":"img/case_4_m.png","modified":1,"renderable":0},{"_id":"source/img/camera_translation_rotation.png","path":"img/camera_translation_rotation.png","modified":1,"renderable":0},{"_id":"source/img/case_m_5.png","path":"img/case_m_5.png","modified":1,"renderable":0},{"_id":"source/img/rotation_matrix.png","path":"img/rotation_matrix.png","modified":1,"renderable":0},{"_id":"source/img/case_6_m.png","path":"img/case_6_m.png","modified":1,"renderable":0},{"_id":"source/img/generic_projection_matrix.png","path":"img/generic_projection_matrix.png","modified":1,"renderable":0},{"_id":"source/img/camera_model_things_to_remember.png","path":"img/camera_model_things_to_remember.png","modified":1,"renderable":0}],"Cache":[{"_id":"source/_posts/cs131-camera.md","hash":"af3c8e87c597363aec850f36208b2d030dedc1a6","modified":1486048579000},{"_id":"source/_posts/cs131-edge-detection.md","hash":"525406fad7c7724f2b77d3a93a06666d7515c660","modified":1485961829000},{"_id":"source/_posts/cs131-filter-svd.md","hash":"f198c7a4f9830de141998b1a5998b725d4717c68","modified":1485961829000},{"_id":"source/_posts/cs131-finding-features.md","hash":"215e59ff8da3260e43a3d2c66ec37b8ec0e5585f","modified":1485961829000},{"_id":"source/_posts/cs131-linear-alg.md","hash":"ecf87dbb1365994c3bd232cb6319f13acd6edc87","modified":1485961829000},{"_id":"source/_posts/cs131-sift.md","hash":"35aa2f506065e9c42c73ffce8dd9cdd00fbad6ec","modified":1485961829000},{"_id":"source/_posts/gsl-with-vs.md","hash":"4e8d8fa9f9d76739a9bee8c966f63f2003f99151","modified":1485961829000},{"_id":"source/_posts/hello-world.md","hash":"83ed29662f5775bed6a8b1af300aca1b91240d92","modified":1485961829000},{"_id":"source/_posts/use-doxygen.md","hash":"7dfd60c0492ea6a9e4b7d5133617adf423e575b6","modified":1485961829000},{"_id":"source/_posts/python-reg-exp.md","hash":"cbc1287d80f3e8daed0b1ccd21dffde2f019f3f0","modified":1485961829000},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1485961829000},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1485961829000},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1485961829000},{"_id":"themes/next/.gitignore","hash":"5f09fca02e030b7676c1d312cd88ce8fbccf381c","modified":1485961829000},{"_id":"themes/next/.javascript_ignore","hash":"f9ea3c5395f8feb225a24e2c32baa79afda30c16","modified":1485961829000},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1485961829000},{"_id":"themes/next/README.en.md","hash":"3b0c7998cf17f9cf9e1a5bfcd65679a43a00c817","modified":1485961829000},{"_id":"themes/next/README.md","hash":"500b5606eb6a09c979d16128f8b00f4bf9bc95ac","modified":1485961829000},{"_id":"themes/next/bower.json","hash":"5abc236d9cc2512f5457ed57c1fba76669eb7399","modified":1485961829000},{"_id":"themes/next/gulpfile.coffee","hash":"61ef0606a8134894d7ac796bc8d0fa4ba6a94483","modified":1485961829000},{"_id":"themes/next/_config.yml","hash":"263059170206812bae848d87c7baa1666cdf9cc2","modified":1485961829000},{"_id":"themes/next/package.json","hash":"877cb98025e59015532c4c9a04a33e2af4ad56f9","modified":1485961829000},{"_id":"source/about/index.md","hash":"7eb7acffb61b7be9cbb41f0b72f409ec4e4be17e","modified":1485961829000},{"_id":"source/tags/index.md","hash":"62ca8832e828cf0af53b2774fe0b4c65af4feed6","modified":1485961829000},{"_id":"source/img/corner_type_1.png","hash":"4c431c0faf73514d013771932114831969ab3038","modified":1485961829000},{"_id":"source/img/line_fit_demo.png","hash":"0916a1148ce54c4b0f9bfc2dde33bd35782bf724","modified":1485961829000},{"_id":"source/img/ransac_step.png","hash":"eb9e2d50c4920cfd4516c9e7df2c981d8544b118","modified":1485961829000},{"_id":"source/img/rotation.png","hash":"11557a269f79012091059c15602438a69a211721","modified":1485961829000},{"_id":"source/img/sift_dominant_orientation.png","hash":"9a5a1538b25d9b7edcc18e23ad8a41fdaea341c8","modified":1485961829000},{"_id":"source/img/svd_ranking.png","hash":"6cae2c6139567934a59a8e93d9672633d1016e1a","modified":1485961829000},{"_id":"source/img/canny_linking.png","hash":"8545dcacf874990d7d1b1ae074abbf4eb694f382","modified":1485961829000},{"_id":"source/img/canny_nms.png","hash":"363582d281cb85ba31ebf20dff0b1e7e7c2588cb","modified":1485961829000},{"_id":"source/img/corner_window_fun.png","hash":"81b549c79bbe2bec390aab961ea503d9e80980a5","modified":1485961829000},{"_id":"source/img/edge_deriative.png","hash":"a26ae2c627cdf6b95419c89d52689ad06fdb7d0d","modified":1485961829000},{"_id":"source/img/harris_non_scale_constant.png","hash":"e36afe38ba3f1e428c435b00c12d030c43edb108","modified":1485961829000},{"_id":"source/img/patch_average_intensity_scale_constant.png","hash":"bd0609e8de60de54e12c47ef7416c972f3582a0b","modified":1485961829000},{"_id":"source/img/sift_detection_maximum.png","hash":"eaa0c3e9bda32792b35008184e794bd3e8966cf4","modified":1485961829000},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"5ab257af816986cd0e53f9527a92d5934ac70ae9","modified":1485961829000},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"c2024ded82143807c28a299c5fe6b927ef3525ff","modified":1485961829000},{"_id":"themes/next/languages/de.yml","hash":"1fdea1f84b7f691f5b4dd4d2b43eeb27b10fa0c8","modified":1485961829000},{"_id":"source/img/svd_superman.png","hash":"a4c3b97c4acfac14b978a6a00d163e2436227eda","modified":1485961829000},{"_id":"themes/next/languages/fr-FR.yml","hash":"9fca01ef917d33ae2ae6bc04561ec6799dff5351","modified":1485961829000},{"_id":"themes/next/languages/default.yml","hash":"767470a80dc257e23e14c3a78e8c52a46c9d6209","modified":1485961829000},{"_id":"themes/next/languages/id.yml","hash":"34396bef27c4ab9e9a3c5d3e3aa94b0e3b3a7b0d","modified":1485961829000},{"_id":"themes/next/languages/en.yml","hash":"40057d6608e825d06e0864bac4dcd27ed88ada87","modified":1485961829000},{"_id":"themes/next/languages/ko.yml","hash":"b6bc5d6b0c000deb44099b42d3aebb8c49dbfca9","modified":1485961829000},{"_id":"themes/next/languages/ja.yml","hash":"49f12149edcc1892b26a6207328cda64da20116d","modified":1485961829000},{"_id":"themes/next/languages/pt-BR.yml","hash":"7742ba4c0d682cbe1d38305332ebc928abd754b5","modified":1485961829000},{"_id":"themes/next/languages/ru.yml","hash":"257d11e626cbe4b9b78785a764190b9278f95c28","modified":1485961829000},{"_id":"themes/next/languages/zh-hk.yml","hash":"34c84c6d04447a25bd5eac576922a13947c000e2","modified":1485961829000},{"_id":"themes/next/languages/zh-Hans.yml","hash":"f6c9fafa0f5f0050cd07ca2cf5e38fbae3e28145","modified":1485961829000},{"_id":"themes/next/languages/pt.yml","hash":"6b660b117314cad93f08757601df3adb04c68beb","modified":1485961829000},{"_id":"themes/next/layout/_layout.swig","hash":"7a1e4443c3ba1e08c20e64ddbf0b8255d034dab0","modified":1485961829000},{"_id":"themes/next/languages/zh-tw.yml","hash":"c97a5c41149de9b17f33439b0ecf0eff6fdae50e","modified":1485961829000},{"_id":"themes/next/layout/archive.swig","hash":"b5b59d70fc1563f482fa07afd435752774ad5981","modified":1485961829000},{"_id":"themes/next/layout/index.swig","hash":"427d0b95b854e311ae363088ab39a393bf8fdc8b","modified":1485961829000},{"_id":"themes/next/layout/category.swig","hash":"6422d196ceaff4220d54b8af770e7e957f3364ad","modified":1485961829000},{"_id":"themes/next/layout/schedule.swig","hash":"1f1cdc268f4ef773fd3ae693bbdf7d0b2f45c3a3","modified":1485961829000},{"_id":"themes/next/layout/post.swig","hash":"e2e512142961ddfe77eba29eaa88f4a2ee43ae18","modified":1485961829000},{"_id":"themes/next/layout/page.swig","hash":"3727fab9dadb967e9c2204edca787dc72264674a","modified":1485961829000},{"_id":"themes/next/scripts/merge-configs.js","hash":"0c56be2e85c694247cfa327ea6d627b99ca265e8","modified":1485961829000},{"_id":"themes/next/layout/tag.swig","hash":"07cf49c49c39a14dfbe9ce8e7d7eea3d4d0a4911","modified":1485961829000},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1485961830000},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1485961830000},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1485961830000},{"_id":"source/img/corner_judge.png","hash":"4020cd84f4ea052bcc10ce09f25bd1bad8f5c293","modified":1485961829000},{"_id":"source/img/corner_judge_2.png","hash":"d6daba0908de0a3686bc925c31f7c34adb4068f2","modified":1485961829000},{"_id":"source/img/fun_noise.png","hash":"b1e7adbf4ffd2801b0685be5213579bf0f7d16e3","modified":1485961829000},{"_id":"source/img/original_superman.png","hash":"310f3412935a64309e53d8e1d8403dd1c52206c8","modified":1485961829000},{"_id":"source/img/ransac_k.png","hash":"abe2b6c3ff381e1c113c96b4839e579a59da8da0","modified":1485961829000},{"_id":"source/img/what_is_corner.png","hash":"18bd784f1845b9252f72cb54e0128157db10a940","modified":1485961829000},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1485961829000},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1485961829000},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1485961829000},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1485961829000},{"_id":"themes/next/layout/_scripts/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1485961829000},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1485961829000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"4512867d80d9eddfc3a0f5fea3c456f33aa9d522","modified":1485961829000},{"_id":"themes/next/layout/_macro/post.swig","hash":"e6016def9b512188f4c2725399c9adc7bc41cdae","modified":1485961829000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"5864f5567ba5efeabcf6ea355013c0b603ee07f2","modified":1485961829000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"43d8830bb19da4fc7a5773866be19fa066b62645","modified":1485961829000},{"_id":"themes/next/layout/_macro/reward.swig","hash":"37e5b7c42ec17b9b6b786c5512bcc481a21c974e","modified":1485961829000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"31e3b17af134d05fe293f8a48ebea5f9eb2ec21e","modified":1485961829000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"7172c6053118b7c291a56a7860128a652ae66b83","modified":1485961829000},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"14e785adeb0e671ba0ff9a553e6f0d8def6c670c","modified":1485961829000},{"_id":"themes/next/layout/_partials/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1485961829000},{"_id":"themes/next/layout/_partials/head.swig","hash":"ca56f92e2fa82b03853869f5073ee1a5626a4796","modified":1485961829000},{"_id":"themes/next/layout/_partials/header.swig","hash":"adab5c3f7b173f1b45454787f39dde07aea03483","modified":1485961829000},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"39d613e5a9f8389d4ea52d6082502af8e833b9f2","modified":1485961829000},{"_id":"themes/next/layout/_partials/search.swig","hash":"1431719d1dbba3f5ee385eebc46376d1a960b2d5","modified":1485961829000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1485961829000},{"_id":"themes/next/scripts/tags/button.js","hash":"62e6dbeb53d07627a048132c79630b45d9a8f2cc","modified":1485961829000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1485961829000},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1485961829000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1485961829000},{"_id":"themes/next/scripts/tags/note.js","hash":"6752925eedbdb939d8ec4d11bdfb75199f18dd70","modified":1485961829000},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1485961829000},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1485961829000},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"90035272fa31a3f65b3c0e2cb8a633876ef457dc","modified":1485961829000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1485961829000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1485961829000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1485961829000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1485961829000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1485961829000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1485961829000},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1485961829000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1485961829000},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1485961829000},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1485961829000},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1485961829000},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1485961829000},{"_id":"source/avatar/liumengli.jpg","hash":"4069caff1851227a11b74759a75bec586c568cd3","modified":1485961829000},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1485961829000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1485961829000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1485961829000},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1485961829000},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1485961829000},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1485961829000},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1485961829000},{"_id":"source/img/svd_flower.png","hash":"e1924f7eaf2a920c769fd63ba27baf210adf59c7","modified":1485961829000},{"_id":"themes/next/layout/_components/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1485961829000},{"_id":"themes/next/layout/_components/algolia-search/dom.swig","hash":"636f1181dd5887a70b4a08ca8f655d4e46635792","modified":1485961829000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1485961829000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1485961829000},{"_id":"themes/next/layout/_scripts/third-party/analytics.swig","hash":"394d9fff7951287cc90f52acc2d4cbfd1bae079d","modified":1485961829000},{"_id":"themes/next/layout/_scripts/third-party/comments.swig","hash":"4abc01bc870e1d7a783cdbd26166edc782a6a4f4","modified":1485961829000},{"_id":"themes/next/layout/_scripts/third-party/lean-analytics.swig","hash":"92dc60821307fc9769bea9b2d60adaeb798342af","modified":1485961829000},{"_id":"themes/next/layout/_scripts/third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1485961829000},{"_id":"themes/next/layout/_scripts/third-party/localsearch.swig","hash":"b460e27db3dcd4ab40b17d8926a5c4e624f293a9","modified":1485961829000},{"_id":"themes/next/layout/_scripts/third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1485961829000},{"_id":"themes/next/layout/_scripts/third-party/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1485961829000},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1485961829000},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1485961829000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"ff5523d5dacaa77a55a24e50e6e6530c3b98bfad","modified":1485961829000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1485961829000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1485961829000},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1485961829000},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1485961829000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"63315fcf210799f894208c9f512737096df84962","modified":1485961829000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1485961829000},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1485961829000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"c8d35a6b9e3bff6d8fdb66de853065af9d37562d","modified":1485961829000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"fc185c6cec79593775d1c2440dbe2a71cfbe2e99","modified":1485961829000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"c459aa6d607d8bcb747544e74f6ad0b8374aa3b1","modified":1485961829000},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"715d5b40dc52f319fe4bff0325beb874774d9bd9","modified":1485961829000},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"78a83c38f69a8747bb74e420e6c9eeef1ea76525","modified":1485961829000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1485961829000},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1485961829000},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1485961830000},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"c1072942459fa0880e8a33a1bd929176b62b4171","modified":1485961830000},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1485961830000},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1485961830000},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1485961830000},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1485961830000},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1485961830000},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1485961830000},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1485961830000},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1485961830000},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1485961830000},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1485961830000},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1485961830000},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1485961830000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1485961830000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1485961830000},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1485961830000},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1485961830000},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1485961830000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1485961830000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1485961830000},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1485961829000},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"96b29f69b8b916b22f62c9959a117b5a968200a5","modified":1485961829000},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"39bf93769d9080fa01a9a875183b43198f79bc19","modified":1485961829000},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1485961829000},{"_id":"themes/next/source/js/src/post-details.js","hash":"2038f54e289b6da5def09689e69f623187147be5","modified":1485961829000},{"_id":"themes/next/source/js/src/motion.js","hash":"269414e84df544a4ccb88519f6abae4943db3c67","modified":1485961829000},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1485961829000},{"_id":"themes/next/source/js/src/utils.js","hash":"384e17ff857f073060f5bf8c6e4f4b7353236331","modified":1485961829000},{"_id":"source/img/dog_x.png","hash":"5672ad3c046997781703816e4d58d3961fe26eeb","modified":1485961829000},{"_id":"source/img/ransac_line_fit.png","hash":"f3711368fa15222a40f134c267842999574277e2","modified":1485961829000},{"_id":"source/img/sift_dog.png","hash":"60371c0dbb5dfae010c84c59227dac9d878d3530","modified":1485961829000},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1485961830000},{"_id":"source/img/sift_experiment_1.png","hash":"87873fe348c7cb572b8d499730cf2ebc86a1e4ef","modified":1485961829000},{"_id":"themes/next/layout/_scripts/third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1485961829000},{"_id":"themes/next/layout/_scripts/third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1485961829000},{"_id":"themes/next/layout/_scripts/third-party/analytics/busuanzi-counter.swig","hash":"4fcbf57c4918528ab51d3d042cff92cf5aefb599","modified":1485961829000},{"_id":"themes/next/layout/_scripts/third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1485961829000},{"_id":"themes/next/layout/_scripts/third-party/analytics/facebook-sdk.swig","hash":"394d008e5e94575280407ad8a1607a028026cbc3","modified":1485961829000},{"_id":"themes/next/layout/_scripts/third-party/analytics/google-analytics.swig","hash":"30a23fa7e816496fdec0e932aa42e2d13098a9c2","modified":1485961829000},{"_id":"themes/next/layout/_scripts/third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1485961829000},{"_id":"themes/next/layout/_scripts/third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1485961829000},{"_id":"themes/next/layout/_scripts/third-party/comments/disqus.swig","hash":"fb1d04ede838b52ca7541973f86c3810f1ad396e","modified":1485961829000},{"_id":"themes/next/layout/_scripts/third-party/comments/gentie.swig","hash":"03592d1d731592103a41ebb87437fe4b0a4c78ca","modified":1485961829000},{"_id":"themes/next/layout/_scripts/third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1485961829000},{"_id":"themes/next/layout/_scripts/third-party/comments/youyan.swig","hash":"ea8078fa9e10be2bb042749d8b6a97adc38f914c","modified":1485961829000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"5304f99581da3a31de3ecec959b7adf9002fde83","modified":1485961829000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1485961829000},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"54c90cf7bdbf5c596179d8dae6e671bad1292662","modified":1485961829000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1485961829000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"013619c472c7e4b08311c464fcbe9fcf5edde603","modified":1485961829000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"b49efc66bd055a2d0be7deabfcb02ee72a9a28c8","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"0dfb4b3ba3180d7285e66f270e1d3fa0f132c3d2","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"10994990d6e0b4d965a728a22cf7f6ee29cae9f6","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"fda14bc35be2e1b332809b55b3d07155a833dbf4","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"82bbaa6322764779a1ac2e2c8390ce901c7972e2","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"ff9f163bb05c0709577040a875924d36c9ab99d6","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"dcf9fe43b2ef78b923118ba39efedb38760e76b1","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"1408209dfb9a22a0982a30bdbd14842c2b53f264","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"9b63bd8effc7cf4b96acdea4d73add7df934a222","modified":1485961829000},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1485961829000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1485961829000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1485961829000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1485961829000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1485961830000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1485961830000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1485961830000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1485961830000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1485961829000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"4eda182cbcc046dbf449aef97c02c230cf80a494","modified":1485961830000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"fb5b49426dee7f1508500e698d1b3c6b04c8fcce","modified":1485961830000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1485961830000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1485961830000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1485961830000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1485961830000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1485961830000},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"9ccee9189c910b8a264802d7b2ec305d12dedcd0","modified":1485961829000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"965ce8f688fedbeed504efd498bc9c1622d12362","modified":1485961830000},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"1b22f17fdc38070de50e6d1ab3a32da71aa2d819","modified":1485961830000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"6d7e6a5fc802b13694d8820fc0138037c0977d2e","modified":1485961830000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"97e438cc545714309882fbceadbf344fcaddcec5","modified":1485961830000},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1485961830000},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"8994ffcce84deac0471532f270f97c44fea54dc0","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"c890ce7fe933abad7baf39764a01894924854e92","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"7778920dd105fa4de3a7ab206eeba30b1a7bac45","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"4b7f81e1006e7acee3d1c840ccba155239f830cc","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"fdfadbb4483043c7e0afd541ee9712389e633517","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"8fae54591877a73dff0b29b2be2e8935e3c63575","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"b25132fe6a7ad67059a2c3afc60feabb479bdd75","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"7f1aab694caf603809e33cff82beea84cd0128fd","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"e792c8dc41561c96d128e9b421187f1c3dc978a0","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"963105a531403d7aad6d9e5e23e3bfabb8ec065a","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"c6dab7661a6b8c678b21b7eb273cef7100f970f6","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"bfd806d0a9f21446a22df82ac02e37d0075cc3b5","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"74d0ba86f698165d13402670382a822c8736a556","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"b8969e1654eec89a0fd10d88b337fee9cb03cd44","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"3eb73cee103b810fa56901577ecb9c9bb1793cff","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"2e7ec9aaa3293941106b1bdd09055246aa3c3dc6","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"c44f6a553ec7ea5508f2054a13be33a62a15d3a9","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"7690b9596ec3a49befbe529a5a2649abec0faf76","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"2d3abbc85b979a648e0e579e45f16a6eba49d1e7","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"234facd038f144bd0fe09a31ed1357c5d74c517f","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"eba491ae624b4c843c8be4c94a044085dad4ba0f","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"b03f891883446f3a5548b7cc90d29c77e62f1053","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/third-party/gentie.styl","hash":"586a3ec0f1015e7207cd6a2474362e068c341744","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"637c6b32c58ecf40041be6e911471cd82671919b","modified":1485961829000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"42348219db93a85d2ee23cb06cebd4d8ab121726","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"8b8e8cbce98a9296c8fd77f512ae85d945f65d40","modified":1485961829000},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"8b8e8cbce98a9296c8fd77f512ae85d945f65d40","modified":1485961829000},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1485961830000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1485961830000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1485961830000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1485961830000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"61d8d967807ef12598d81582fa95b9f600c3ee01","modified":1485961830000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1485961830000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1485961830000},{"_id":"source/img/convolution.png","hash":"af8e2638d7e484d8267a49ed11d3f3239fa19107","modified":1485961829000},{"_id":"source/img/dog_different_size.png","hash":"c8d097879dcfffa7cf6138b01b22d4792d56522c","modified":1485961829000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1485961829000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"c0522272bbaef2acb3d341912754d6ea2d0ecfc0","modified":1485961830000},{"_id":"source/img/sift_experiment_2.png","hash":"c1e482a1e85026664f33ce2dd7e72e3e3a58c0fc","modified":1485961829000},{"_id":"source/img/projective_geometry_property_1.png","hash":"ee1d6866a25eb2822cd8adb7b8666ae653a8bf45","modified":1486040559000},{"_id":"source/img/projective_geometry_property_2.png","hash":"1d0b53aa8901c0dc46673762820683b3afd4202b","modified":1486040972000},{"_id":"source/img/camera_geometry_application.png","hash":"cb34e60657f460f4cf120b740180740d721256e4","modified":1486039591000},{"_id":"source/img/image_matching_hard.png","hash":"4a09523ad90bb2d41a391edb8fd69bfed2cdf8e9","modified":1485961829000},{"_id":"source/img/camera_skew.png","hash":"c02198d706e8366ffd307fccc931f0400317642c","modified":1486046734000},{"_id":"source/img/case_1_m.png","hash":"6d4b596285b981d003a660d3ce03a95a74946576","modified":1486046024000},{"_id":"source/img/case_2_m.png","hash":"ced9ffe517ff6250f0f6a4e402897592233018ba","modified":1486046309000},{"_id":"source/img/case_3_m.png","hash":"b2d5bc2d469bbf0e4a4534c191feb4a30132e5cc","modified":1486046539000},{"_id":"source/img/case_4_m.png","hash":"85dee8dc61da967d28caa56a10d949f9de5b2e24","modified":1486046777000},{"_id":"source/img/case_m_5.png","hash":"dca097cea37695ed4b237671b017c2f04940de8e","modified":1486047510000},{"_id":"source/img/qicizuobiao.png","hash":"2bd2071a724832d96284a6d5a685991ab087f801","modified":1486044525000},{"_id":"source/img/case_6_m.png","hash":"bbd8245d6e3478b0287629f778aa8489489f3a37","modified":1486047717000},{"_id":"source/img/rotation_matrix.png","hash":"35aed3946385abfcd448fe99c796db440ea0ddb6","modified":1486047699000},{"_id":"source/img/qicizuobiao_transform.png","hash":"06b6ea9933a6d47c79b700f5c2d3c83e9cd4602f","modified":1486044575000},{"_id":"source/img/camera_translation_rotation.png","hash":"bd89b487aff4a1c8aa5faff2dd8280557b480478","modified":1486047056000},{"_id":"source/img/generic_projection_matrix.png","hash":"4bf8906146b76f3fc74891042de14982eece2346","modified":1486047830000},{"_id":"source/img/pinhole_camera_model.png","hash":"b72eab7554feea7be265c28d0b11efc3156dae40","modified":1486043465000},{"_id":"source/img/camera_model_things_to_remember.png","hash":"687a27be2aa5a335814315d19421f29fa79fee06","modified":1486048033000},{"_id":"public/search.xml","hash":"5f5e32b43349fafb860bdc41733014f1c416f145","modified":1486048600338},{"_id":"public/tags/index.html","hash":"d73402a233dc6074cad0073045c9c0e2b7af95e3","modified":1486048600487},{"_id":"public/archives/2014/index.html","hash":"a7baa808e8da43aefda2018e89a798ec59252e65","modified":1486048600489},{"_id":"public/archives/2014/07/index.html","hash":"722b686a057b75a2745b5d9b6c3c8f573d928938","modified":1486048600489},{"_id":"public/tags/gsl/index.html","hash":"878c14a656efd917195e8eecb7a32e1521ae2a09","modified":1486048600489},{"_id":"public/tags/doxygen/index.html","hash":"3fbabed4c30cf84f6bf74e1443335087ea48f21b","modified":1486048600490},{"_id":"public/tags/python/index.html","hash":"b747b55ed2fe39219cefdb304da965d5c6d9af2a","modified":1486048600490},{"_id":"public/about/index.html","hash":"6585ebc5e435c6b440e696260de795741b9b5661","modified":1486048600490},{"_id":"public/2017/01/25/cs131-finding-features/index.html","hash":"0c84e029ded94dfba0c658c86d5cdef4e4657954","modified":1486048600490},{"_id":"public/2017/01/24/cs131-edge-detection/index.html","hash":"f2b9632ea324569da7f2538be0f76c6c71d43439","modified":1486048600490},{"_id":"public/2017/01/23/cs131-filter-svd/index.html","hash":"9327635207ec87368ef4526078b92c8e2d4ba506","modified":1486048600490},{"_id":"public/2017/01/22/cs131-linear-alg/index.html","hash":"8b10387d1f30a426674c321b89d7b04e531aec95","modified":1486048600490},{"_id":"public/2016/12/16/gsl-with-vs/index.html","hash":"3c8e01d28383ceedf221610387ef70f0fce7be94","modified":1486048600490},{"_id":"public/2016/12/16/hello-world/index.html","hash":"11bf616987b8c17724565b34e009871cf1ca370e","modified":1486048600490},{"_id":"public/2016/12/16/use-doxygen/index.html","hash":"0de29adb9758bc9f6f2808d67d626c99312a49ca","modified":1486048600490},{"_id":"public/2014/07/17/python-reg-exp/index.html","hash":"5366caea86e592c154112a813bf8fcf09994bf6c","modified":1486048600490},{"_id":"public/archives/index.html","hash":"6da9fc4be7991a8632fd9c5dbf3eaf974fbc44cd","modified":1486048600490},{"_id":"public/archives/2016/index.html","hash":"3fc5559a4cd197755bb6edc281d4375f2c7349ea","modified":1486048600490},{"_id":"public/archives/2016/12/index.html","hash":"408942bc774bf01872b40f6569e4d8567517b356","modified":1486048600490},{"_id":"public/archives/2017/index.html","hash":"68090fb8b29486abac2cc27a15503345c165c571","modified":1486048600490},{"_id":"public/archives/2017/01/index.html","hash":"6f2b259e70afd94185dd457ae8ccad857ec6f20f","modified":1486048600490},{"_id":"public/index.html","hash":"ef74f5c41c95489c96fbc84e5c43449ca99624d8","modified":1486048600490},{"_id":"public/tags/公开课/index.html","hash":"f0805b0e01bc0a04ccef97d2db714be6dfe71bea","modified":1486048600490},{"_id":"public/tags/cs131/index.html","hash":"7c6c3386426956947909716713dad6561428c14d","modified":1486048600490},{"_id":"public/tags/tool/index.html","hash":"3884e9624d8ec389b92cf763fe2d1030104a5558","modified":1486048600490},{"_id":"public/archives/2017/02/index.html","hash":"20903f3a07a761b6a27cceb55545a12e44569a6d","modified":1486048600496},{"_id":"public/2017/02/02/cs131-camera/index.html","hash":"0a3a17ea0013941647aee6cab26d3e7d5e05310a","modified":1486048600496},{"_id":"public/2017/01/30/cs131-sift/index.html","hash":"e54f80ee33529f5bf245d9eea0843bf79466499b","modified":1486048600496},{"_id":"public/img/qicizuobiao.png","hash":"2bd2071a724832d96284a6d5a685991ab087f801","modified":1486048600500},{"_id":"public/img/case_1_m.png","hash":"6d4b596285b981d003a660d3ce03a95a74946576","modified":1486048600500},{"_id":"public/img/case_2_m.png","hash":"ced9ffe517ff6250f0f6a4e402897592233018ba","modified":1486048600501},{"_id":"public/img/camera_skew.png","hash":"c02198d706e8366ffd307fccc931f0400317642c","modified":1486048600501},{"_id":"public/img/case_3_m.png","hash":"b2d5bc2d469bbf0e4a4534c191feb4a30132e5cc","modified":1486048600501},{"_id":"public/img/case_4_m.png","hash":"85dee8dc61da967d28caa56a10d949f9de5b2e24","modified":1486048600501},{"_id":"public/img/case_m_5.png","hash":"dca097cea37695ed4b237671b017c2f04940de8e","modified":1486048600502},{"_id":"public/img/rotation_matrix.png","hash":"35aed3946385abfcd448fe99c796db440ea0ddb6","modified":1486048600505},{"_id":"public/img/case_6_m.png","hash":"bbd8245d6e3478b0287629f778aa8489489f3a37","modified":1486048600505},{"_id":"public/img/qicizuobiao_transform.png","hash":"06b6ea9933a6d47c79b700f5c2d3c83e9cd4602f","modified":1486048600505},{"_id":"public/img/camera_translation_rotation.png","hash":"bd89b487aff4a1c8aa5faff2dd8280557b480478","modified":1486048600513},{"_id":"public/img/generic_projection_matrix.png","hash":"4bf8906146b76f3fc74891042de14982eece2346","modified":1486048600513},{"_id":"public/img/pinhole_camera_model.png","hash":"b72eab7554feea7be265c28d0b11efc3156dae40","modified":1486048600516},{"_id":"public/img/camera_model_things_to_remember.png","hash":"687a27be2aa5a335814315d19421f29fa79fee06","modified":1486048600524},{"_id":"public/img/projective_geometry_property_1.png","hash":"ee1d6866a25eb2822cd8adb7b8666ae653a8bf45","modified":1486048600533},{"_id":"public/img/projective_geometry_property_2.png","hash":"1d0b53aa8901c0dc46673762820683b3afd4202b","modified":1486048600538},{"_id":"public/img/camera_geometry_application.png","hash":"cb34e60657f460f4cf120b740180740d721256e4","modified":1486048600541}],"Category":[],"Data":[],"Page":[{"title":"关于","date":"2016-12-17T12:49:51.000Z","_content":"\nHi, 你好，欢迎来到我的博客。目前，我是北京理工自动化学院组合导航与智能导航实验室的在读研究生，将于2017年4月进入中国科学院计算技术研究所计算机体系结构国家重点实验室工作。\n\n我的个人兴趣主要包括机器人，计算机视觉，嵌入式平台的深度学习框架及应用。我曾经在北京贝虎机器人和地平线机器人有过短暂的实习经历，亲身参与了基于深度学习的物体检测和车道线识别等任务。\n\n我的博客主要是关于个人在工作学习中的点滴心得，既是自己学习过程的整理，也希望能够帮助到有缘之人。本博客将会不定期更新。我是CV DL领域的新兵，如果我的博客中有问题或遗漏，欢迎与我沟通，帮我指正，请联系邮箱xmfbit # gmail.com.\n","source":"about/index.md","raw":"---\ntitle: 关于\ndate: 2016-12-17 20:49:51\n---\n\nHi, 你好，欢迎来到我的博客。目前，我是北京理工自动化学院组合导航与智能导航实验室的在读研究生，将于2017年4月进入中国科学院计算技术研究所计算机体系结构国家重点实验室工作。\n\n我的个人兴趣主要包括机器人，计算机视觉，嵌入式平台的深度学习框架及应用。我曾经在北京贝虎机器人和地平线机器人有过短暂的实习经历，亲身参与了基于深度学习的物体检测和车道线识别等任务。\n\n我的博客主要是关于个人在工作学习中的点滴心得，既是自己学习过程的整理，也希望能够帮助到有缘之人。本博客将会不定期更新。我是CV DL领域的新兵，如果我的博客中有问题或遗漏，欢迎与我沟通，帮我指正，请联系邮箱xmfbit # gmail.com.\n","updated":"2017-02-01T15:10:29.000Z","path":"about/index.html","comments":1,"layout":"page","_id":"ciyof8h2s0014cq1h655zbccm","content":"<p>Hi, 你好，欢迎来到我的博客。目前，我是北京理工自动化学院组合导航与智能导航实验室的在读研究生，将于2017年4月进入中国科学院计算技术研究所计算机体系结构国家重点实验室工作。</p>\n<p>我的个人兴趣主要包括机器人，计算机视觉，嵌入式平台的深度学习框架及应用。我曾经在北京贝虎机器人和地平线机器人有过短暂的实习经历，亲身参与了基于深度学习的物体检测和车道线识别等任务。</p>\n<p>我的博客主要是关于个人在工作学习中的点滴心得，既是自己学习过程的整理，也希望能够帮助到有缘之人。本博客将会不定期更新。我是CV DL领域的新兵，如果我的博客中有问题或遗漏，欢迎与我沟通，帮我指正，请联系邮箱xmfbit # gmail.com.</p>\n","excerpt":"","more":"<p>Hi, 你好，欢迎来到我的博客。目前，我是北京理工自动化学院组合导航与智能导航实验室的在读研究生，将于2017年4月进入中国科学院计算技术研究所计算机体系结构国家重点实验室工作。</p>\n<p>我的个人兴趣主要包括机器人，计算机视觉，嵌入式平台的深度学习框架及应用。我曾经在北京贝虎机器人和地平线机器人有过短暂的实习经历，亲身参与了基于深度学习的物体检测和车道线识别等任务。</p>\n<p>我的博客主要是关于个人在工作学习中的点滴心得，既是自己学习过程的整理，也希望能够帮助到有缘之人。本博客将会不定期更新。我是CV DL领域的新兵，如果我的博客中有问题或遗漏，欢迎与我沟通，帮我指正，请联系邮箱xmfbit # gmail.com.</p>\n"},{"title":"标签","date":"2016-12-17T12:10:38.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: 标签\ndate: 2016-12-17 20:10:38\ntype: tags\n---\n","updated":"2017-02-01T15:10:29.000Z","path":"tags/index.html","comments":1,"layout":"page","_id":"ciyof8h2u0015cq1h09si1fjc","content":"","excerpt":"","more":""}],"Post":[{"title":"CS131-立体视觉基础","date":"2017-02-02T12:38:55.000Z","_content":"\n数字图像是现实世界的物体通过光学成像设备在感光材料上的投影。在3D到2D的转换过程中，深度信息丢失。如何从单幅或者多幅图像中恢复出有用的3D信息，需要使用立体视觉的知识进行分析。如下图所示。这篇博客对课程讲义中立体视觉部分做一整理，首先介绍针孔相机模型，\n![立体视觉应用](/img/camera_geometry_application.png)\n\n## 针孔相机模型（Pinhole Camera）\n\n针孔相机是简化的相机模型。光线沿直线传播。物体反射的光线，通过针孔，在成像面形成倒立的影像。针孔与成像面的距离，称为焦距。一般而言，针孔越小，影像越清晰，但针孔太小，会导致衍射，反而令影像模糊。\n\n### 投影几何的重要性质\n\n在对针孔相机详细说明之前，首先介绍投影几何（Projective Geometry）的几条性质。\n\n在投影变换前后，长度和角度信息丢失，但直线仍然保持是直线。如下图所示。原来垂直和平行的台球桌面的边不再保持原有的角度和相对长度，但是仍然是直线。\n![性质1](/img/projective_geometry_property_1.png)\n\n另一方面，虽然3D世界中的平行线在投影变换后相交（我们将交点称为Vanishing point），但是3D世界中互相平行的线，在2D平面上的Vanishing point为同一点。而所有平行线的Vanishing point又在同一条直线上。如下图所示（竖直的绿色平行线在投影变换后仍然保持平行，实际上并不想交，但我们这里认为其交于无穷远的某点）。\n![性质2](/img/projective_geometry_property_2.png)\n\n### 针孔相机模型\n如下图所示，为针孔相机成像原理示意图。外部世界的一点$P$发出（或反射）的光线，经过小孔$O$，成像在在像平面$\\Pi^{'}$的点$P^{'}$处。通过简单的相似三角形知识，可以得到图上的关系式。\n![针孔相机模型示意图](/img/pinhole_camera_model.png)\n\n由上图可以知道，3D空间的一点$P$与成像平面上的对应点$P^{'}$坐标之间的数量关系为：\n$$\\left\\{\\begin{matrix}\nx^{'} = fx/z \\\\\ny^{'} = fy/z\n\\end{matrix}\\right.$$\n\n可是，由于变量$z$位于分母的位置，也就是说如果直接写成变换矩阵的话，这个矩阵是和变量$z$有关的，我们不想这样，而是想得到一个完全由相机本身确定的变换矩阵。所以，我们借鉴齐次矩阵的思想，将原来的点增加一个维度，转换为齐次坐标。如下图的两个例子所示。\n![齐次坐标](/img/qicizuobiao.png)\n\n这样，我们可以将3D和2D之间的变换写成下面的形式。当实际计算的时候，我们首先将3D点转换为4维向量（在末尾补1），然后左乘变换矩阵。最后将得到的结果化为末尾元素为1的形式，这样，前面两个元素就代表了变换后2D点的坐标。这样做，使得变换矩阵$M$完全由相机参数（即焦距$f$）决定。\n![](/img/qicizuobiao_transform.png)\n\n上面的式子只是理想情况下的相机模型，成立的假设条件较强，主要有以下几点假设：\n1. 内假设（和相机本身有关）\n    - 不同方向上焦距相同；\n    - 光学中心在相平面的坐标原点$(0, 0)$\n    - 没有倾斜（no skew）\n2. 外假设（和相机位姿有关，和相机本身参数无关）\n    - 相机没有旋转（坐标轴与世界坐标系方向重合）\n    - 相机没有平移（相机中心与世界坐标系中心重合）\n\n其中，no skew情形我也不知道中文应该如何翻译。这种情况如图所示，由于剪切变形，成像平面的坐标轴并不是严格正交，使得两个轴之间实际存在一个很小的夹角。\n![what is \"skew\"?](/img/camera_skew.png)\n\n下面，按照slide的顺序逐渐将上述假设移去，分析变换矩阵$M$应该如何修正。\n\n#### 理想情况\n理想情况以上假设全部满足，矩阵$M$如下所示。\n![case 1: M](/img/case_1_m.png)\n\n#### 光学中心不在像平面的坐标原点\n假设光学中心位于像平面内坐标为$(u_0, v_0)$的位置。则需要在理想情况计算的坐标基础上加上这个偏移量。所以，矩阵$M$被修正为：\n![case 2: M](/img/case_2_m.png)\n\n#### 像素非正方形\n由于透镜在$x$和$y$方向上的焦距不同，使得两个方向上的比例因子不同，不能再使用同一个$f$计算。修正如下：\n![case 3: M](/img/case_3_m.png)\n\n#### no skew\n这时候$x$方向上其实有$y$轴坐标的分量，所以修正如下：\n![case 4: M](/img/case_4_m.png)\n\n#### 相机的旋转和平移\n相机外部姿态很可能经过了旋转和平移，从而不与世界坐标系完全重合。如图所示。\n![相机旋转和平移](/img/camera_translation_rotation.png)\n\n所以我们需要先对世界坐标系内的3D点做一个齐次变换，将其变换为一个中间坐标系，这个中间坐标系和相机坐标系是重合的。也就是我们的变换矩阵应该是下面这个形式的，其中，$H$是表征旋转和平移的齐次矩阵，$H\\in \\mathbb{R}^{3\\times 4}$。\n$$P^{'} = MHP$$\n\n首先考虑较为简单的平移。所做的修正如下所示，也就是将原来的$\\mathbb{0}$矩阵变为了一个平移向量。\n![case 5: M](/img/case_m_5.png)\n\n进一步考虑旋转时，我们将旋转分解为绕三个坐标轴的三次旋转，单次旋转矩阵如下所示：\n![绕单轴的旋转矩阵](/img/rotation_matrix.png)\n\n将它们按照旋转顺序左乘起来，可以得到修正后的变换形式如下：\n![case 6: M](/img/case_6_m.png)\n\n#### 最终形式\n综上所示，变换矩阵的最终形式为：\n![最终的投影变换矩阵](/img/generic_projection_matrix.png)\n\n其中，内参数矩阵中有5个自由度，外参数矩阵中有6个自由度（3平移，3旋转）。\n\n上面的内容总结起来，如下图所示。\n![things to remember](/img/camera_model_things_to_remember.png)\n","source":"_posts/cs131-camera.md","raw":"---\ntitle: CS131-立体视觉基础\ndate: 2017-02-02 20:38:55\ntags:\n     - cs131\n     - 公开课\n---\n\n数字图像是现实世界的物体通过光学成像设备在感光材料上的投影。在3D到2D的转换过程中，深度信息丢失。如何从单幅或者多幅图像中恢复出有用的3D信息，需要使用立体视觉的知识进行分析。如下图所示。这篇博客对课程讲义中立体视觉部分做一整理，首先介绍针孔相机模型，\n![立体视觉应用](/img/camera_geometry_application.png)\n\n## 针孔相机模型（Pinhole Camera）\n\n针孔相机是简化的相机模型。光线沿直线传播。物体反射的光线，通过针孔，在成像面形成倒立的影像。针孔与成像面的距离，称为焦距。一般而言，针孔越小，影像越清晰，但针孔太小，会导致衍射，反而令影像模糊。\n\n### 投影几何的重要性质\n\n在对针孔相机详细说明之前，首先介绍投影几何（Projective Geometry）的几条性质。\n\n在投影变换前后，长度和角度信息丢失，但直线仍然保持是直线。如下图所示。原来垂直和平行的台球桌面的边不再保持原有的角度和相对长度，但是仍然是直线。\n![性质1](/img/projective_geometry_property_1.png)\n\n另一方面，虽然3D世界中的平行线在投影变换后相交（我们将交点称为Vanishing point），但是3D世界中互相平行的线，在2D平面上的Vanishing point为同一点。而所有平行线的Vanishing point又在同一条直线上。如下图所示（竖直的绿色平行线在投影变换后仍然保持平行，实际上并不想交，但我们这里认为其交于无穷远的某点）。\n![性质2](/img/projective_geometry_property_2.png)\n\n### 针孔相机模型\n如下图所示，为针孔相机成像原理示意图。外部世界的一点$P$发出（或反射）的光线，经过小孔$O$，成像在在像平面$\\Pi^{'}$的点$P^{'}$处。通过简单的相似三角形知识，可以得到图上的关系式。\n![针孔相机模型示意图](/img/pinhole_camera_model.png)\n\n由上图可以知道，3D空间的一点$P$与成像平面上的对应点$P^{'}$坐标之间的数量关系为：\n$$\\left\\{\\begin{matrix}\nx^{'} = fx/z \\\\\ny^{'} = fy/z\n\\end{matrix}\\right.$$\n\n可是，由于变量$z$位于分母的位置，也就是说如果直接写成变换矩阵的话，这个矩阵是和变量$z$有关的，我们不想这样，而是想得到一个完全由相机本身确定的变换矩阵。所以，我们借鉴齐次矩阵的思想，将原来的点增加一个维度，转换为齐次坐标。如下图的两个例子所示。\n![齐次坐标](/img/qicizuobiao.png)\n\n这样，我们可以将3D和2D之间的变换写成下面的形式。当实际计算的时候，我们首先将3D点转换为4维向量（在末尾补1），然后左乘变换矩阵。最后将得到的结果化为末尾元素为1的形式，这样，前面两个元素就代表了变换后2D点的坐标。这样做，使得变换矩阵$M$完全由相机参数（即焦距$f$）决定。\n![](/img/qicizuobiao_transform.png)\n\n上面的式子只是理想情况下的相机模型，成立的假设条件较强，主要有以下几点假设：\n1. 内假设（和相机本身有关）\n    - 不同方向上焦距相同；\n    - 光学中心在相平面的坐标原点$(0, 0)$\n    - 没有倾斜（no skew）\n2. 外假设（和相机位姿有关，和相机本身参数无关）\n    - 相机没有旋转（坐标轴与世界坐标系方向重合）\n    - 相机没有平移（相机中心与世界坐标系中心重合）\n\n其中，no skew情形我也不知道中文应该如何翻译。这种情况如图所示，由于剪切变形，成像平面的坐标轴并不是严格正交，使得两个轴之间实际存在一个很小的夹角。\n![what is \"skew\"?](/img/camera_skew.png)\n\n下面，按照slide的顺序逐渐将上述假设移去，分析变换矩阵$M$应该如何修正。\n\n#### 理想情况\n理想情况以上假设全部满足，矩阵$M$如下所示。\n![case 1: M](/img/case_1_m.png)\n\n#### 光学中心不在像平面的坐标原点\n假设光学中心位于像平面内坐标为$(u_0, v_0)$的位置。则需要在理想情况计算的坐标基础上加上这个偏移量。所以，矩阵$M$被修正为：\n![case 2: M](/img/case_2_m.png)\n\n#### 像素非正方形\n由于透镜在$x$和$y$方向上的焦距不同，使得两个方向上的比例因子不同，不能再使用同一个$f$计算。修正如下：\n![case 3: M](/img/case_3_m.png)\n\n#### no skew\n这时候$x$方向上其实有$y$轴坐标的分量，所以修正如下：\n![case 4: M](/img/case_4_m.png)\n\n#### 相机的旋转和平移\n相机外部姿态很可能经过了旋转和平移，从而不与世界坐标系完全重合。如图所示。\n![相机旋转和平移](/img/camera_translation_rotation.png)\n\n所以我们需要先对世界坐标系内的3D点做一个齐次变换，将其变换为一个中间坐标系，这个中间坐标系和相机坐标系是重合的。也就是我们的变换矩阵应该是下面这个形式的，其中，$H$是表征旋转和平移的齐次矩阵，$H\\in \\mathbb{R}^{3\\times 4}$。\n$$P^{'} = MHP$$\n\n首先考虑较为简单的平移。所做的修正如下所示，也就是将原来的$\\mathbb{0}$矩阵变为了一个平移向量。\n![case 5: M](/img/case_m_5.png)\n\n进一步考虑旋转时，我们将旋转分解为绕三个坐标轴的三次旋转，单次旋转矩阵如下所示：\n![绕单轴的旋转矩阵](/img/rotation_matrix.png)\n\n将它们按照旋转顺序左乘起来，可以得到修正后的变换形式如下：\n![case 6: M](/img/case_6_m.png)\n\n#### 最终形式\n综上所示，变换矩阵的最终形式为：\n![最终的投影变换矩阵](/img/generic_projection_matrix.png)\n\n其中，内参数矩阵中有5个自由度，外参数矩阵中有6个自由度（3平移，3旋转）。\n\n上面的内容总结起来，如下图所示。\n![things to remember](/img/camera_model_things_to_remember.png)\n","slug":"cs131-camera","published":1,"updated":"2017-02-02T15:16:19.000Z","_id":"ciyof8h060000cq1hyw87e08a","comments":1,"layout":"post","photos":[],"link":"","content":"<p>数字图像是现实世界的物体通过光学成像设备在感光材料上的投影。在3D到2D的转换过程中，深度信息丢失。如何从单幅或者多幅图像中恢复出有用的3D信息，需要使用立体视觉的知识进行分析。如下图所示。这篇博客对课程讲义中立体视觉部分做一整理，首先介绍针孔相机模型，<br><img src=\"/img/camera_geometry_application.png\" alt=\"立体视觉应用\"></p>\n<h2 id=\"针孔相机模型（Pinhole-Camera）\"><a href=\"#针孔相机模型（Pinhole-Camera）\" class=\"headerlink\" title=\"针孔相机模型（Pinhole Camera）\"></a>针孔相机模型（Pinhole Camera）</h2><p>针孔相机是简化的相机模型。光线沿直线传播。物体反射的光线，通过针孔，在成像面形成倒立的影像。针孔与成像面的距离，称为焦距。一般而言，针孔越小，影像越清晰，但针孔太小，会导致衍射，反而令影像模糊。</p>\n<h3 id=\"投影几何的重要性质\"><a href=\"#投影几何的重要性质\" class=\"headerlink\" title=\"投影几何的重要性质\"></a>投影几何的重要性质</h3><p>在对针孔相机详细说明之前，首先介绍投影几何（Projective Geometry）的几条性质。</p>\n<p>在投影变换前后，长度和角度信息丢失，但直线仍然保持是直线。如下图所示。原来垂直和平行的台球桌面的边不再保持原有的角度和相对长度，但是仍然是直线。<br><img src=\"/img/projective_geometry_property_1.png\" alt=\"性质1\"></p>\n<p>另一方面，虽然3D世界中的平行线在投影变换后相交（我们将交点称为Vanishing point），但是3D世界中互相平行的线，在2D平面上的Vanishing point为同一点。而所有平行线的Vanishing point又在同一条直线上。如下图所示（竖直的绿色平行线在投影变换后仍然保持平行，实际上并不想交，但我们这里认为其交于无穷远的某点）。<br><img src=\"/img/projective_geometry_property_2.png\" alt=\"性质2\"></p>\n<h3 id=\"针孔相机模型\"><a href=\"#针孔相机模型\" class=\"headerlink\" title=\"针孔相机模型\"></a>针孔相机模型</h3><p>如下图所示，为针孔相机成像原理示意图。外部世界的一点$P$发出（或反射）的光线，经过小孔$O$，成像在在像平面$\\Pi^{‘}$的点$P^{‘}$处。通过简单的相似三角形知识，可以得到图上的关系式。<br><img src=\"/img/pinhole_camera_model.png\" alt=\"针孔相机模型示意图\"></p>\n<p>由上图可以知道，3D空间的一点$P$与成像平面上的对应点$P^{‘}$坐标之间的数量关系为：</p>\n<script type=\"math/tex; mode=display\">\\left\\{\\begin{matrix}\nx^{'} = fx/z \\\\\ny^{'} = fy/z\n\\end{matrix}\\right.</script><p>可是，由于变量$z$位于分母的位置，也就是说如果直接写成变换矩阵的话，这个矩阵是和变量$z$有关的，我们不想这样，而是想得到一个完全由相机本身确定的变换矩阵。所以，我们借鉴齐次矩阵的思想，将原来的点增加一个维度，转换为齐次坐标。如下图的两个例子所示。<br><img src=\"/img/qicizuobiao.png\" alt=\"齐次坐标\"></p>\n<p>这样，我们可以将3D和2D之间的变换写成下面的形式。当实际计算的时候，我们首先将3D点转换为4维向量（在末尾补1），然后左乘变换矩阵。最后将得到的结果化为末尾元素为1的形式，这样，前面两个元素就代表了变换后2D点的坐标。这样做，使得变换矩阵$M$完全由相机参数（即焦距$f$）决定。<br><img src=\"/img/qicizuobiao_transform.png\" alt=\"\"></p>\n<p>上面的式子只是理想情况下的相机模型，成立的假设条件较强，主要有以下几点假设：</p>\n<ol>\n<li>内假设（和相机本身有关）<ul>\n<li>不同方向上焦距相同；</li>\n<li>光学中心在相平面的坐标原点$(0, 0)$</li>\n<li>没有倾斜（no skew）</li>\n</ul>\n</li>\n<li>外假设（和相机位姿有关，和相机本身参数无关）<ul>\n<li>相机没有旋转（坐标轴与世界坐标系方向重合）</li>\n<li>相机没有平移（相机中心与世界坐标系中心重合）</li>\n</ul>\n</li>\n</ol>\n<p>其中，no skew情形我也不知道中文应该如何翻译。这种情况如图所示，由于剪切变形，成像平面的坐标轴并不是严格正交，使得两个轴之间实际存在一个很小的夹角。<br><img src=\"/img/camera_skew.png\" alt=\"what is &quot;skew&quot;?\"></p>\n<p>下面，按照slide的顺序逐渐将上述假设移去，分析变换矩阵$M$应该如何修正。</p>\n<h4 id=\"理想情况\"><a href=\"#理想情况\" class=\"headerlink\" title=\"理想情况\"></a>理想情况</h4><p>理想情况以上假设全部满足，矩阵$M$如下所示。<br><img src=\"/img/case_1_m.png\" alt=\"case 1: M\"></p>\n<h4 id=\"光学中心不在像平面的坐标原点\"><a href=\"#光学中心不在像平面的坐标原点\" class=\"headerlink\" title=\"光学中心不在像平面的坐标原点\"></a>光学中心不在像平面的坐标原点</h4><p>假设光学中心位于像平面内坐标为$(u_0, v_0)$的位置。则需要在理想情况计算的坐标基础上加上这个偏移量。所以，矩阵$M$被修正为：<br><img src=\"/img/case_2_m.png\" alt=\"case 2: M\"></p>\n<h4 id=\"像素非正方形\"><a href=\"#像素非正方形\" class=\"headerlink\" title=\"像素非正方形\"></a>像素非正方形</h4><p>由于透镜在$x$和$y$方向上的焦距不同，使得两个方向上的比例因子不同，不能再使用同一个$f$计算。修正如下：<br><img src=\"/img/case_3_m.png\" alt=\"case 3: M\"></p>\n<h4 id=\"no-skew\"><a href=\"#no-skew\" class=\"headerlink\" title=\"no skew\"></a>no skew</h4><p>这时候$x$方向上其实有$y$轴坐标的分量，所以修正如下：<br><img src=\"/img/case_4_m.png\" alt=\"case 4: M\"></p>\n<h4 id=\"相机的旋转和平移\"><a href=\"#相机的旋转和平移\" class=\"headerlink\" title=\"相机的旋转和平移\"></a>相机的旋转和平移</h4><p>相机外部姿态很可能经过了旋转和平移，从而不与世界坐标系完全重合。如图所示。<br><img src=\"/img/camera_translation_rotation.png\" alt=\"相机旋转和平移\"></p>\n<p>所以我们需要先对世界坐标系内的3D点做一个齐次变换，将其变换为一个中间坐标系，这个中间坐标系和相机坐标系是重合的。也就是我们的变换矩阵应该是下面这个形式的，其中，$H$是表征旋转和平移的齐次矩阵，$H\\in \\mathbb{R}^{3\\times 4}$。</p>\n<script type=\"math/tex; mode=display\">P^{'} = MHP</script><p>首先考虑较为简单的平移。所做的修正如下所示，也就是将原来的$\\mathbb{0}$矩阵变为了一个平移向量。<br><img src=\"/img/case_m_5.png\" alt=\"case 5: M\"></p>\n<p>进一步考虑旋转时，我们将旋转分解为绕三个坐标轴的三次旋转，单次旋转矩阵如下所示：<br><img src=\"/img/rotation_matrix.png\" alt=\"绕单轴的旋转矩阵\"></p>\n<p>将它们按照旋转顺序左乘起来，可以得到修正后的变换形式如下：<br><img src=\"/img/case_6_m.png\" alt=\"case 6: M\"></p>\n<h4 id=\"最终形式\"><a href=\"#最终形式\" class=\"headerlink\" title=\"最终形式\"></a>最终形式</h4><p>综上所示，变换矩阵的最终形式为：<br><img src=\"/img/generic_projection_matrix.png\" alt=\"最终的投影变换矩阵\"></p>\n<p>其中，内参数矩阵中有5个自由度，外参数矩阵中有6个自由度（3平移，3旋转）。</p>\n<p>上面的内容总结起来，如下图所示。<br><img src=\"/img/camera_model_things_to_remember.png\" alt=\"things to remember\"></p>\n","excerpt":"","more":"<p>数字图像是现实世界的物体通过光学成像设备在感光材料上的投影。在3D到2D的转换过程中，深度信息丢失。如何从单幅或者多幅图像中恢复出有用的3D信息，需要使用立体视觉的知识进行分析。如下图所示。这篇博客对课程讲义中立体视觉部分做一整理，首先介绍针孔相机模型，<br><img src=\"/img/camera_geometry_application.png\" alt=\"立体视觉应用\"></p>\n<h2 id=\"针孔相机模型（Pinhole-Camera）\"><a href=\"#针孔相机模型（Pinhole-Camera）\" class=\"headerlink\" title=\"针孔相机模型（Pinhole Camera）\"></a>针孔相机模型（Pinhole Camera）</h2><p>针孔相机是简化的相机模型。光线沿直线传播。物体反射的光线，通过针孔，在成像面形成倒立的影像。针孔与成像面的距离，称为焦距。一般而言，针孔越小，影像越清晰，但针孔太小，会导致衍射，反而令影像模糊。</p>\n<h3 id=\"投影几何的重要性质\"><a href=\"#投影几何的重要性质\" class=\"headerlink\" title=\"投影几何的重要性质\"></a>投影几何的重要性质</h3><p>在对针孔相机详细说明之前，首先介绍投影几何（Projective Geometry）的几条性质。</p>\n<p>在投影变换前后，长度和角度信息丢失，但直线仍然保持是直线。如下图所示。原来垂直和平行的台球桌面的边不再保持原有的角度和相对长度，但是仍然是直线。<br><img src=\"/img/projective_geometry_property_1.png\" alt=\"性质1\"></p>\n<p>另一方面，虽然3D世界中的平行线在投影变换后相交（我们将交点称为Vanishing point），但是3D世界中互相平行的线，在2D平面上的Vanishing point为同一点。而所有平行线的Vanishing point又在同一条直线上。如下图所示（竖直的绿色平行线在投影变换后仍然保持平行，实际上并不想交，但我们这里认为其交于无穷远的某点）。<br><img src=\"/img/projective_geometry_property_2.png\" alt=\"性质2\"></p>\n<h3 id=\"针孔相机模型\"><a href=\"#针孔相机模型\" class=\"headerlink\" title=\"针孔相机模型\"></a>针孔相机模型</h3><p>如下图所示，为针孔相机成像原理示意图。外部世界的一点$P$发出（或反射）的光线，经过小孔$O$，成像在在像平面$\\Pi^{‘}$的点$P^{‘}$处。通过简单的相似三角形知识，可以得到图上的关系式。<br><img src=\"/img/pinhole_camera_model.png\" alt=\"针孔相机模型示意图\"></p>\n<p>由上图可以知道，3D空间的一点$P$与成像平面上的对应点$P^{‘}$坐标之间的数量关系为：</p>\n<script type=\"math/tex; mode=display\">\\left\\{\\begin{matrix}\nx^{'} = fx/z \\\\\ny^{'} = fy/z\n\\end{matrix}\\right.</script><p>可是，由于变量$z$位于分母的位置，也就是说如果直接写成变换矩阵的话，这个矩阵是和变量$z$有关的，我们不想这样，而是想得到一个完全由相机本身确定的变换矩阵。所以，我们借鉴齐次矩阵的思想，将原来的点增加一个维度，转换为齐次坐标。如下图的两个例子所示。<br><img src=\"/img/qicizuobiao.png\" alt=\"齐次坐标\"></p>\n<p>这样，我们可以将3D和2D之间的变换写成下面的形式。当实际计算的时候，我们首先将3D点转换为4维向量（在末尾补1），然后左乘变换矩阵。最后将得到的结果化为末尾元素为1的形式，这样，前面两个元素就代表了变换后2D点的坐标。这样做，使得变换矩阵$M$完全由相机参数（即焦距$f$）决定。<br><img src=\"/img/qicizuobiao_transform.png\" alt=\"\"></p>\n<p>上面的式子只是理想情况下的相机模型，成立的假设条件较强，主要有以下几点假设：</p>\n<ol>\n<li>内假设（和相机本身有关）<ul>\n<li>不同方向上焦距相同；</li>\n<li>光学中心在相平面的坐标原点$(0, 0)$</li>\n<li>没有倾斜（no skew）</li>\n</ul>\n</li>\n<li>外假设（和相机位姿有关，和相机本身参数无关）<ul>\n<li>相机没有旋转（坐标轴与世界坐标系方向重合）</li>\n<li>相机没有平移（相机中心与世界坐标系中心重合）</li>\n</ul>\n</li>\n</ol>\n<p>其中，no skew情形我也不知道中文应该如何翻译。这种情况如图所示，由于剪切变形，成像平面的坐标轴并不是严格正交，使得两个轴之间实际存在一个很小的夹角。<br><img src=\"/img/camera_skew.png\" alt=\"what is &quot;skew&quot;?\"></p>\n<p>下面，按照slide的顺序逐渐将上述假设移去，分析变换矩阵$M$应该如何修正。</p>\n<h4 id=\"理想情况\"><a href=\"#理想情况\" class=\"headerlink\" title=\"理想情况\"></a>理想情况</h4><p>理想情况以上假设全部满足，矩阵$M$如下所示。<br><img src=\"/img/case_1_m.png\" alt=\"case 1: M\"></p>\n<h4 id=\"光学中心不在像平面的坐标原点\"><a href=\"#光学中心不在像平面的坐标原点\" class=\"headerlink\" title=\"光学中心不在像平面的坐标原点\"></a>光学中心不在像平面的坐标原点</h4><p>假设光学中心位于像平面内坐标为$(u_0, v_0)$的位置。则需要在理想情况计算的坐标基础上加上这个偏移量。所以，矩阵$M$被修正为：<br><img src=\"/img/case_2_m.png\" alt=\"case 2: M\"></p>\n<h4 id=\"像素非正方形\"><a href=\"#像素非正方形\" class=\"headerlink\" title=\"像素非正方形\"></a>像素非正方形</h4><p>由于透镜在$x$和$y$方向上的焦距不同，使得两个方向上的比例因子不同，不能再使用同一个$f$计算。修正如下：<br><img src=\"/img/case_3_m.png\" alt=\"case 3: M\"></p>\n<h4 id=\"no-skew\"><a href=\"#no-skew\" class=\"headerlink\" title=\"no skew\"></a>no skew</h4><p>这时候$x$方向上其实有$y$轴坐标的分量，所以修正如下：<br><img src=\"/img/case_4_m.png\" alt=\"case 4: M\"></p>\n<h4 id=\"相机的旋转和平移\"><a href=\"#相机的旋转和平移\" class=\"headerlink\" title=\"相机的旋转和平移\"></a>相机的旋转和平移</h4><p>相机外部姿态很可能经过了旋转和平移，从而不与世界坐标系完全重合。如图所示。<br><img src=\"/img/camera_translation_rotation.png\" alt=\"相机旋转和平移\"></p>\n<p>所以我们需要先对世界坐标系内的3D点做一个齐次变换，将其变换为一个中间坐标系，这个中间坐标系和相机坐标系是重合的。也就是我们的变换矩阵应该是下面这个形式的，其中，$H$是表征旋转和平移的齐次矩阵，$H\\in \\mathbb{R}^{3\\times 4}$。</p>\n<script type=\"math/tex; mode=display\">P^{'} = MHP</script><p>首先考虑较为简单的平移。所做的修正如下所示，也就是将原来的$\\mathbb{0}$矩阵变为了一个平移向量。<br><img src=\"/img/case_m_5.png\" alt=\"case 5: M\"></p>\n<p>进一步考虑旋转时，我们将旋转分解为绕三个坐标轴的三次旋转，单次旋转矩阵如下所示：<br><img src=\"/img/rotation_matrix.png\" alt=\"绕单轴的旋转矩阵\"></p>\n<p>将它们按照旋转顺序左乘起来，可以得到修正后的变换形式如下：<br><img src=\"/img/case_6_m.png\" alt=\"case 6: M\"></p>\n<h4 id=\"最终形式\"><a href=\"#最终形式\" class=\"headerlink\" title=\"最终形式\"></a>最终形式</h4><p>综上所示，变换矩阵的最终形式为：<br><img src=\"/img/generic_projection_matrix.png\" alt=\"最终的投影变换矩阵\"></p>\n<p>其中，内参数矩阵中有5个自由度，外参数矩阵中有6个自由度（3平移，3旋转）。</p>\n<p>上面的内容总结起来，如下图所示。<br><img src=\"/img/camera_model_things_to_remember.png\" alt=\"things to remember\"></p>\n"},{"title":"CS131-边缘检测","date":"2017-01-24T02:42:47.000Z","_content":"边缘(Edge)在哺乳动物的视觉中有重要意义。在由若干卷积层构成的深度神经网络中，较低层的卷积层就被训练成为对特定形状的边缘做出响应。边缘检测也是计算机视觉和图像处理领域中一个重要的问题。\n\n## 边缘的产生\n若仍采取将图像视作某一函数的观点，边缘是指这个函数中的不连续点。边缘检测是后续进行目标检测和形状识别的基础，也能够在立体视觉中恢复视角等。边缘的来源主要有以下几点：\n- 物体表面不平造成灰度值的不连续；\n- 深度值不同造成灰度值不连续；\n- 物体表面颜色的突变造成灰度值不连续\n\n## 朴素思想\n利用边缘是图像中不连续点的这一性质，可以通过计算图像的一阶导数，再找到一阶导数的极大值，即认为是边缘点。如下图所示，在白黑交界处，图像一阶导数的值非常大，表明此处灰度值变化剧烈，是边缘。\n![边缘点处导数很大](/img/edge_deriative.png)\n\n问题转换为如何求取图像的一阶导数（或梯度）。由于图像是离散的二元函数，所以下文不再区分求导与差分。\n\n在$x$方向上，令$g_x = \\frac{\\partial f}{\\partial x}$；在$y$方向上，令$g_y = \\frac{\\partial f}{\\partial y}$。梯度的大小和方向为\n$$g = \\lbrack g_x, g_y\\rbrack, \\theta = \\arctan(g_y/g_x)$$\n\n通过和Sobel算子等做卷积，可以求取两个正交方向上图像的一阶导数，并计算梯度，之后检测梯度的局部极大值就能够找出边缘点了。\n\n只是这种方法很容易受到噪声影响。如图所示，真实的边缘点被湮没在了噪声中。\n![噪声影响湮没了边缘点](/img/fun_noise.png)\n\n## 改进1：先平滑\n改进措施1，可以首先对图像进行高斯平滑，再按照上面的方法求取边缘点。根据卷积的性质，有：\n\n$$\\frac{d}{dx}(f\\ast g) = f\\ast\\frac{d}{dx}g$$\n\n所以我们可以先求取高斯核的一阶导数，再和原始图像直接做一次卷积就可以一举两得了。这样，引出了DoG(Deriative of Gaussian)。$x$方向的DoG如图所示。\n![x方向的DoG](/img/dog_x.png)\n\n进行高斯平滑不可避免会使图像中原本的细节部分模糊，所以需要在克服噪声和引入模糊之间做好折中。\n![不同](/img/dog_different_size.png)\n\n## 改进2：Canny检测子\n改进措施2，使用Canny检测子进行检测。Canny检测方法同样基于梯度，其基本原理如下：\n- 使用DoG计算梯度幅值和方向。\n- 非极大值抑制，这个过程需要根据梯度方向做线性插值。如图，沿着点$q$的梯度方向找到了$p$和$r$两个点。这两个点的梯度幅值需要根据其临近的两点做插值得到。\n- 利用梯度方向和边缘线互相垂直这一性质，如图，若已经确定点$p$为边缘点，则向它的梯度方向正交方向上寻找下一个边缘点（点$r$或$s$）。这一步也叫edge linking。\n\n![nms示意图](/img/canny_nms.png)\n![linking示意图](/img/canny_linking.png)\n\n同时，为了提高算法性能，Canny中采用了迟滞阈值的方法，设定`low`和`high`两个阈值，来判定某个点是否属于**强**或**弱**边缘点。在做edge linking的时候，从强边缘点开始，如果遇到了弱边缘点，则继续，直到某点的梯度幅值甚至比`low`还要小，则在此停止。\n\n## 改进3：RANSAC方法\n有的时候，我们并不是想要找到所有的边缘点，可能只是想找到图像中水平方向的某些边缘。这时候可以考虑采用RANSAC方法。\n\nRANSAC方法的思想在于，认为已有的feature大部分都是**好的**。这样，每次随机抽取出若干feature，建立model，再在整个feature集合上进行验证。那么由那些好的feature得到的model一定是得分较高的。（世界上还是好人多啊！）这样就剔除了离群点的影响。\n\n以直线拟合为例，在下图中，给出了使用RANSAC方法拟合直线的步骤。如图1所示，由于离群点的存在，如果直接使用最小二乘法进行拟合，拟合结果效果会很不理想。由于确定一条直线需要两个点，所以从点集中选取两个点，并计算拟合直线。并计算点集中的点在这条直线附近的个数，作为对模型好坏的判定，这些点是新的内点。找出最优的那条直线，使用其所有内点再进行拟合，重复上述操作，直至迭代终止。\n![ransac step](/img/ransac_step.png)\n\n上述RANSAC方法进行直线拟合的过程可以总结如下：\n![ransac line fit alg](/img/ransac_line_fit.png)\n\n按照上述思想，我分别使用最小二乘法和RANSAC方法尝试进行直线拟合。在下面的代码中，我首先产生了正常受到一定高斯噪声污染的数据（图中的红色点），这些点的真值都落在直线$y = 2x+1$上。而后，我随机变化了斜率和截距，以期产生一些离群点（图中的蓝色点）。当然，由于随机性，这种方法生成的点有可能仍然是内点。\n\n而后，我分别使用上述两种方法进行拟合。可以从结果图中看出，RANSAC（绿色线）能够有效避免离群点的干扰，获得更好的拟合效果。在某次实验中，两种方法的拟合结果如下：\n``` bash\nleast square: a = 3.319566, b = -1.446528\nransac method: a = 1.899640, b= 1.298608\n```\n![demo result](/img/line_fit_demo.png)\n\n实验使用的MATLAB代码如下：\n``` matlab\n%% generate data\nx = 0:1:10;\ny_gt = 2*x+1;\ny = y_gt + randn(size(y_gt));\nscatter(x, y, [], [1,0,0]);\nhold on\nout_x = 0:1:10;\nout_y = 5*rand(size(out_x)).*out_x + 4*rand(size(out_x));\nscatter(out_x, out_y, [], [0,0,1]);\nX = [x, out_x]';\nY = [y, out_y]';\nX = [X, ones(length(X), 1)];\n[a, b] = ls_fit(X, Y);\nplot(x, a*x+b, 'linestyle', '--', 'color', 'r');\n\n[ra, rb] = ransac_fit(X, Y, 100, 2, 0.5, 3);\nplot(x, ra*x+rb, 'linestyle', '-.', 'color', 'g');\nfprintf('least square: a = %f, b = %f\\n',a, b);\nfprintf('ransac method: a = %f, b= %f\\n', ra, rb)\nfunction [a, b] = ransac_fit(X, Y, k, n, t ,d)\n% ransac fit\n% k -- maximum iteration number\n% n -- smallest point numer required\n% t -- threshold to identify a point is fit well\n% d -- the number of nearby points to assert a model is fine\ndata = [X, Y];\nN = size(data, 1);\nbest_good_cnt = -1;\nbest_a = 0;\nbest_b = 0;\nfor i = 1:k\n    % sample point\n    idx = randsample(N, n);\n    data_sampled = data(idx, :);\n    % fit with least square\n    [a, b] = ls_fit(data_sampled(:, 1:2), data_sampled(:, 3));\n    % test model\n    not_sampled = ones(N, 1);\n    not_sampled(idx) = 0;\n    not_sampled_data = data(not_sampled == 1, :);\n    distance = abs(not_sampled_data(:, 1:2) * [a; b] - not_sampled_data(:, 3)) / sqrt(a^2+1);\n    inner_flag = distance < t;\n    good_cnt = sum(inner_flag);\n    if good_cnt >= d && good_cnt > best_good_cnt\n        best_good_cnt = good_cnt;\n        data_refine = data(find(inner_flag), :);\n        [a, b] = ls_fit(data_refine(:, 1:2), data_refine(:, 3));\n        best_a = a;\n        best_b = b;\n    end\n    fprintf('iteration %d, best_a = %f, best_b = %f\\n', i, best_a, best_b);\nend\na = best_a;\nb = best_b;\nend\n\nfunction [a, b] = ls_fit(X, Y)\n% least square fit\nA = X'*X\\X'*Y;\na = A(1);\nb = A(2);\nend\n```\n\n我们对RANSAC稍作分析，可以大概了解试验次数$k$的确定方法。\n\n仍然使用上述直线拟合的例子。如果所有点中内点所占的比例为$\\omega$，每次挑选$n$个点尝试（上述demo代码中取$n=2$）。那么每次挑选的两个点全部是内点的概率为$\\omega^n$。当选取的$n$个点全部为内点时，视为有效实验。那么，重复$k$次实验，有效实验次数为0的概率为$(1-\\omega^n)^k$。由于底数小于1，所以我们只需尽量增大$k$，就能够降低这种倒霉的概率。下图是不同$n$和$\\omega$情况下为了使得实验成功的概率大于0.99所需的$k$的分布。\n![k](/img/ransac_k.png)\n\nRANSAC方法的有点在于能够较为鲁棒地估计模型的参数，而且实现简单。缺点在于当离群点比例较大时，为保证实验成功所需的$k$值较大。这时候，可能Hough变换等基于投票的方法更适合用于图像中的直线检测问题。\n","source":"_posts/cs131-edge-detection.md","raw":"---\ntitle: CS131-边缘检测\ndate: 2017-01-24 10:42:47\ntags:\n     - cs131\n     - 公开课\n---\n边缘(Edge)在哺乳动物的视觉中有重要意义。在由若干卷积层构成的深度神经网络中，较低层的卷积层就被训练成为对特定形状的边缘做出响应。边缘检测也是计算机视觉和图像处理领域中一个重要的问题。\n\n## 边缘的产生\n若仍采取将图像视作某一函数的观点，边缘是指这个函数中的不连续点。边缘检测是后续进行目标检测和形状识别的基础，也能够在立体视觉中恢复视角等。边缘的来源主要有以下几点：\n- 物体表面不平造成灰度值的不连续；\n- 深度值不同造成灰度值不连续；\n- 物体表面颜色的突变造成灰度值不连续\n\n## 朴素思想\n利用边缘是图像中不连续点的这一性质，可以通过计算图像的一阶导数，再找到一阶导数的极大值，即认为是边缘点。如下图所示，在白黑交界处，图像一阶导数的值非常大，表明此处灰度值变化剧烈，是边缘。\n![边缘点处导数很大](/img/edge_deriative.png)\n\n问题转换为如何求取图像的一阶导数（或梯度）。由于图像是离散的二元函数，所以下文不再区分求导与差分。\n\n在$x$方向上，令$g_x = \\frac{\\partial f}{\\partial x}$；在$y$方向上，令$g_y = \\frac{\\partial f}{\\partial y}$。梯度的大小和方向为\n$$g = \\lbrack g_x, g_y\\rbrack, \\theta = \\arctan(g_y/g_x)$$\n\n通过和Sobel算子等做卷积，可以求取两个正交方向上图像的一阶导数，并计算梯度，之后检测梯度的局部极大值就能够找出边缘点了。\n\n只是这种方法很容易受到噪声影响。如图所示，真实的边缘点被湮没在了噪声中。\n![噪声影响湮没了边缘点](/img/fun_noise.png)\n\n## 改进1：先平滑\n改进措施1，可以首先对图像进行高斯平滑，再按照上面的方法求取边缘点。根据卷积的性质，有：\n\n$$\\frac{d}{dx}(f\\ast g) = f\\ast\\frac{d}{dx}g$$\n\n所以我们可以先求取高斯核的一阶导数，再和原始图像直接做一次卷积就可以一举两得了。这样，引出了DoG(Deriative of Gaussian)。$x$方向的DoG如图所示。\n![x方向的DoG](/img/dog_x.png)\n\n进行高斯平滑不可避免会使图像中原本的细节部分模糊，所以需要在克服噪声和引入模糊之间做好折中。\n![不同](/img/dog_different_size.png)\n\n## 改进2：Canny检测子\n改进措施2，使用Canny检测子进行检测。Canny检测方法同样基于梯度，其基本原理如下：\n- 使用DoG计算梯度幅值和方向。\n- 非极大值抑制，这个过程需要根据梯度方向做线性插值。如图，沿着点$q$的梯度方向找到了$p$和$r$两个点。这两个点的梯度幅值需要根据其临近的两点做插值得到。\n- 利用梯度方向和边缘线互相垂直这一性质，如图，若已经确定点$p$为边缘点，则向它的梯度方向正交方向上寻找下一个边缘点（点$r$或$s$）。这一步也叫edge linking。\n\n![nms示意图](/img/canny_nms.png)\n![linking示意图](/img/canny_linking.png)\n\n同时，为了提高算法性能，Canny中采用了迟滞阈值的方法，设定`low`和`high`两个阈值，来判定某个点是否属于**强**或**弱**边缘点。在做edge linking的时候，从强边缘点开始，如果遇到了弱边缘点，则继续，直到某点的梯度幅值甚至比`low`还要小，则在此停止。\n\n## 改进3：RANSAC方法\n有的时候，我们并不是想要找到所有的边缘点，可能只是想找到图像中水平方向的某些边缘。这时候可以考虑采用RANSAC方法。\n\nRANSAC方法的思想在于，认为已有的feature大部分都是**好的**。这样，每次随机抽取出若干feature，建立model，再在整个feature集合上进行验证。那么由那些好的feature得到的model一定是得分较高的。（世界上还是好人多啊！）这样就剔除了离群点的影响。\n\n以直线拟合为例，在下图中，给出了使用RANSAC方法拟合直线的步骤。如图1所示，由于离群点的存在，如果直接使用最小二乘法进行拟合，拟合结果效果会很不理想。由于确定一条直线需要两个点，所以从点集中选取两个点，并计算拟合直线。并计算点集中的点在这条直线附近的个数，作为对模型好坏的判定，这些点是新的内点。找出最优的那条直线，使用其所有内点再进行拟合，重复上述操作，直至迭代终止。\n![ransac step](/img/ransac_step.png)\n\n上述RANSAC方法进行直线拟合的过程可以总结如下：\n![ransac line fit alg](/img/ransac_line_fit.png)\n\n按照上述思想，我分别使用最小二乘法和RANSAC方法尝试进行直线拟合。在下面的代码中，我首先产生了正常受到一定高斯噪声污染的数据（图中的红色点），这些点的真值都落在直线$y = 2x+1$上。而后，我随机变化了斜率和截距，以期产生一些离群点（图中的蓝色点）。当然，由于随机性，这种方法生成的点有可能仍然是内点。\n\n而后，我分别使用上述两种方法进行拟合。可以从结果图中看出，RANSAC（绿色线）能够有效避免离群点的干扰，获得更好的拟合效果。在某次实验中，两种方法的拟合结果如下：\n``` bash\nleast square: a = 3.319566, b = -1.446528\nransac method: a = 1.899640, b= 1.298608\n```\n![demo result](/img/line_fit_demo.png)\n\n实验使用的MATLAB代码如下：\n``` matlab\n%% generate data\nx = 0:1:10;\ny_gt = 2*x+1;\ny = y_gt + randn(size(y_gt));\nscatter(x, y, [], [1,0,0]);\nhold on\nout_x = 0:1:10;\nout_y = 5*rand(size(out_x)).*out_x + 4*rand(size(out_x));\nscatter(out_x, out_y, [], [0,0,1]);\nX = [x, out_x]';\nY = [y, out_y]';\nX = [X, ones(length(X), 1)];\n[a, b] = ls_fit(X, Y);\nplot(x, a*x+b, 'linestyle', '--', 'color', 'r');\n\n[ra, rb] = ransac_fit(X, Y, 100, 2, 0.5, 3);\nplot(x, ra*x+rb, 'linestyle', '-.', 'color', 'g');\nfprintf('least square: a = %f, b = %f\\n',a, b);\nfprintf('ransac method: a = %f, b= %f\\n', ra, rb)\nfunction [a, b] = ransac_fit(X, Y, k, n, t ,d)\n% ransac fit\n% k -- maximum iteration number\n% n -- smallest point numer required\n% t -- threshold to identify a point is fit well\n% d -- the number of nearby points to assert a model is fine\ndata = [X, Y];\nN = size(data, 1);\nbest_good_cnt = -1;\nbest_a = 0;\nbest_b = 0;\nfor i = 1:k\n    % sample point\n    idx = randsample(N, n);\n    data_sampled = data(idx, :);\n    % fit with least square\n    [a, b] = ls_fit(data_sampled(:, 1:2), data_sampled(:, 3));\n    % test model\n    not_sampled = ones(N, 1);\n    not_sampled(idx) = 0;\n    not_sampled_data = data(not_sampled == 1, :);\n    distance = abs(not_sampled_data(:, 1:2) * [a; b] - not_sampled_data(:, 3)) / sqrt(a^2+1);\n    inner_flag = distance < t;\n    good_cnt = sum(inner_flag);\n    if good_cnt >= d && good_cnt > best_good_cnt\n        best_good_cnt = good_cnt;\n        data_refine = data(find(inner_flag), :);\n        [a, b] = ls_fit(data_refine(:, 1:2), data_refine(:, 3));\n        best_a = a;\n        best_b = b;\n    end\n    fprintf('iteration %d, best_a = %f, best_b = %f\\n', i, best_a, best_b);\nend\na = best_a;\nb = best_b;\nend\n\nfunction [a, b] = ls_fit(X, Y)\n% least square fit\nA = X'*X\\X'*Y;\na = A(1);\nb = A(2);\nend\n```\n\n我们对RANSAC稍作分析，可以大概了解试验次数$k$的确定方法。\n\n仍然使用上述直线拟合的例子。如果所有点中内点所占的比例为$\\omega$，每次挑选$n$个点尝试（上述demo代码中取$n=2$）。那么每次挑选的两个点全部是内点的概率为$\\omega^n$。当选取的$n$个点全部为内点时，视为有效实验。那么，重复$k$次实验，有效实验次数为0的概率为$(1-\\omega^n)^k$。由于底数小于1，所以我们只需尽量增大$k$，就能够降低这种倒霉的概率。下图是不同$n$和$\\omega$情况下为了使得实验成功的概率大于0.99所需的$k$的分布。\n![k](/img/ransac_k.png)\n\nRANSAC方法的有点在于能够较为鲁棒地估计模型的参数，而且实现简单。缺点在于当离群点比例较大时，为保证实验成功所需的$k$值较大。这时候，可能Hough变换等基于投票的方法更适合用于图像中的直线检测问题。\n","slug":"cs131-edge-detection","published":1,"updated":"2017-02-01T15:10:29.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciyof8h0c0001cq1hi7obv7j8","content":"<p>边缘(Edge)在哺乳动物的视觉中有重要意义。在由若干卷积层构成的深度神经网络中，较低层的卷积层就被训练成为对特定形状的边缘做出响应。边缘检测也是计算机视觉和图像处理领域中一个重要的问题。</p>\n<h2 id=\"边缘的产生\"><a href=\"#边缘的产生\" class=\"headerlink\" title=\"边缘的产生\"></a>边缘的产生</h2><p>若仍采取将图像视作某一函数的观点，边缘是指这个函数中的不连续点。边缘检测是后续进行目标检测和形状识别的基础，也能够在立体视觉中恢复视角等。边缘的来源主要有以下几点：</p>\n<ul>\n<li>物体表面不平造成灰度值的不连续；</li>\n<li>深度值不同造成灰度值不连续；</li>\n<li>物体表面颜色的突变造成灰度值不连续</li>\n</ul>\n<h2 id=\"朴素思想\"><a href=\"#朴素思想\" class=\"headerlink\" title=\"朴素思想\"></a>朴素思想</h2><p>利用边缘是图像中不连续点的这一性质，可以通过计算图像的一阶导数，再找到一阶导数的极大值，即认为是边缘点。如下图所示，在白黑交界处，图像一阶导数的值非常大，表明此处灰度值变化剧烈，是边缘。<br><img src=\"/img/edge_deriative.png\" alt=\"边缘点处导数很大\"></p>\n<p>问题转换为如何求取图像的一阶导数（或梯度）。由于图像是离散的二元函数，所以下文不再区分求导与差分。</p>\n<p>在$x$方向上，令$g_x = \\frac{\\partial f}{\\partial x}$；在$y$方向上，令$g_y = \\frac{\\partial f}{\\partial y}$。梯度的大小和方向为</p>\n<script type=\"math/tex; mode=display\">g = \\lbrack g_x, g_y\\rbrack, \\theta = \\arctan(g_y/g_x)</script><p>通过和Sobel算子等做卷积，可以求取两个正交方向上图像的一阶导数，并计算梯度，之后检测梯度的局部极大值就能够找出边缘点了。</p>\n<p>只是这种方法很容易受到噪声影响。如图所示，真实的边缘点被湮没在了噪声中。<br><img src=\"/img/fun_noise.png\" alt=\"噪声影响湮没了边缘点\"></p>\n<h2 id=\"改进1：先平滑\"><a href=\"#改进1：先平滑\" class=\"headerlink\" title=\"改进1：先平滑\"></a>改进1：先平滑</h2><p>改进措施1，可以首先对图像进行高斯平滑，再按照上面的方法求取边缘点。根据卷积的性质，有：</p>\n<script type=\"math/tex; mode=display\">\\frac{d}{dx}(f\\ast g) = f\\ast\\frac{d}{dx}g</script><p>所以我们可以先求取高斯核的一阶导数，再和原始图像直接做一次卷积就可以一举两得了。这样，引出了DoG(Deriative of Gaussian)。$x$方向的DoG如图所示。<br><img src=\"/img/dog_x.png\" alt=\"x方向的DoG\"></p>\n<p>进行高斯平滑不可避免会使图像中原本的细节部分模糊，所以需要在克服噪声和引入模糊之间做好折中。<br><img src=\"/img/dog_different_size.png\" alt=\"不同\"></p>\n<h2 id=\"改进2：Canny检测子\"><a href=\"#改进2：Canny检测子\" class=\"headerlink\" title=\"改进2：Canny检测子\"></a>改进2：Canny检测子</h2><p>改进措施2，使用Canny检测子进行检测。Canny检测方法同样基于梯度，其基本原理如下：</p>\n<ul>\n<li>使用DoG计算梯度幅值和方向。</li>\n<li>非极大值抑制，这个过程需要根据梯度方向做线性插值。如图，沿着点$q$的梯度方向找到了$p$和$r$两个点。这两个点的梯度幅值需要根据其临近的两点做插值得到。</li>\n<li>利用梯度方向和边缘线互相垂直这一性质，如图，若已经确定点$p$为边缘点，则向它的梯度方向正交方向上寻找下一个边缘点（点$r$或$s$）。这一步也叫edge linking。</li>\n</ul>\n<p><img src=\"/img/canny_nms.png\" alt=\"nms示意图\"><br><img src=\"/img/canny_linking.png\" alt=\"linking示意图\"></p>\n<p>同时，为了提高算法性能，Canny中采用了迟滞阈值的方法，设定<code>low</code>和<code>high</code>两个阈值，来判定某个点是否属于<strong>强</strong>或<strong>弱</strong>边缘点。在做edge linking的时候，从强边缘点开始，如果遇到了弱边缘点，则继续，直到某点的梯度幅值甚至比<code>low</code>还要小，则在此停止。</p>\n<h2 id=\"改进3：RANSAC方法\"><a href=\"#改进3：RANSAC方法\" class=\"headerlink\" title=\"改进3：RANSAC方法\"></a>改进3：RANSAC方法</h2><p>有的时候，我们并不是想要找到所有的边缘点，可能只是想找到图像中水平方向的某些边缘。这时候可以考虑采用RANSAC方法。</p>\n<p>RANSAC方法的思想在于，认为已有的feature大部分都是<strong>好的</strong>。这样，每次随机抽取出若干feature，建立model，再在整个feature集合上进行验证。那么由那些好的feature得到的model一定是得分较高的。（世界上还是好人多啊！）这样就剔除了离群点的影响。</p>\n<p>以直线拟合为例，在下图中，给出了使用RANSAC方法拟合直线的步骤。如图1所示，由于离群点的存在，如果直接使用最小二乘法进行拟合，拟合结果效果会很不理想。由于确定一条直线需要两个点，所以从点集中选取两个点，并计算拟合直线。并计算点集中的点在这条直线附近的个数，作为对模型好坏的判定，这些点是新的内点。找出最优的那条直线，使用其所有内点再进行拟合，重复上述操作，直至迭代终止。<br><img src=\"/img/ransac_step.png\" alt=\"ransac step\"></p>\n<p>上述RANSAC方法进行直线拟合的过程可以总结如下：<br><img src=\"/img/ransac_line_fit.png\" alt=\"ransac line fit alg\"></p>\n<p>按照上述思想，我分别使用最小二乘法和RANSAC方法尝试进行直线拟合。在下面的代码中，我首先产生了正常受到一定高斯噪声污染的数据（图中的红色点），这些点的真值都落在直线$y = 2x+1$上。而后，我随机变化了斜率和截距，以期产生一些离群点（图中的蓝色点）。当然，由于随机性，这种方法生成的点有可能仍然是内点。</p>\n<p>而后，我分别使用上述两种方法进行拟合。可以从结果图中看出，RANSAC（绿色线）能够有效避免离群点的干扰，获得更好的拟合效果。在某次实验中，两种方法的拟合结果如下：<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">least square: a = 3.319566, b = -1.446528</div><div class=\"line\">ransac method: a = 1.899640, b= 1.298608</div></pre></td></tr></table></figure></p>\n<p><img src=\"/img/line_fit_demo.png\" alt=\"demo result\"></p>\n<p>实验使用的MATLAB代码如下：<br><figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">%% generate data</span></div><div class=\"line\">x = <span class=\"number\">0</span>:<span class=\"number\">1</span>:<span class=\"number\">10</span>;</div><div class=\"line\">y_gt = <span class=\"number\">2</span>*x+<span class=\"number\">1</span>;</div><div class=\"line\">y = y_gt + <span class=\"built_in\">randn</span>(<span class=\"built_in\">size</span>(y_gt));</div><div class=\"line\">scatter(x, y, [], [<span class=\"number\">1</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>]);</div><div class=\"line\">hold on</div><div class=\"line\">out_x = <span class=\"number\">0</span>:<span class=\"number\">1</span>:<span class=\"number\">10</span>;</div><div class=\"line\">out_y = <span class=\"number\">5</span>*<span class=\"built_in\">rand</span>(<span class=\"built_in\">size</span>(out_x)).*out_x + <span class=\"number\">4</span>*<span class=\"built_in\">rand</span>(<span class=\"built_in\">size</span>(out_x));</div><div class=\"line\">scatter(out_x, out_y, [], [<span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">1</span>]);</div><div class=\"line\">X = [x, out_x]';</div><div class=\"line\">Y = [y, out_y]';</div><div class=\"line\">X = [X, ones(length(X), <span class=\"number\">1</span>)];</div><div class=\"line\">[a, b] = ls_fit(X, Y);</div><div class=\"line\">plot(x, a*x+b, <span class=\"string\">'linestyle'</span>, <span class=\"string\">'--'</span>, <span class=\"string\">'color'</span>, <span class=\"string\">'r'</span>);</div><div class=\"line\"></div><div class=\"line\">[ra, rb] = ransac_fit(X, Y, <span class=\"number\">100</span>, <span class=\"number\">2</span>, <span class=\"number\">0.5</span>, <span class=\"number\">3</span>);</div><div class=\"line\">plot(x, ra*x+rb, <span class=\"string\">'linestyle'</span>, <span class=\"string\">'-.'</span>, <span class=\"string\">'color'</span>, <span class=\"string\">'g'</span>);</div><div class=\"line\">fprintf(<span class=\"string\">'least square: a = %f, b = %f\\n'</span>,a, b);</div><div class=\"line\">fprintf(<span class=\"string\">'ransac method: a = %f, b= %f\\n'</span>, ra, rb)</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"params\">[a, b]</span> = <span class=\"title\">ransac_fit</span><span class=\"params\">(X, Y, k, n, t ,d)</span></span></div><div class=\"line\"><span class=\"comment\">% ransac fit</span></div><div class=\"line\"><span class=\"comment\">% k -- maximum iteration number</span></div><div class=\"line\"><span class=\"comment\">% n -- smallest point numer required</span></div><div class=\"line\"><span class=\"comment\">% t -- threshold to identify a point is fit well</span></div><div class=\"line\"><span class=\"comment\">% d -- the number of nearby points to assert a model is fine</span></div><div class=\"line\">data = [X, Y];</div><div class=\"line\">N = <span class=\"built_in\">size</span>(data, <span class=\"number\">1</span>);</div><div class=\"line\">best_good_cnt = <span class=\"number\">-1</span>;</div><div class=\"line\">best_a = <span class=\"number\">0</span>;</div><div class=\"line\">best_b = <span class=\"number\">0</span>;</div><div class=\"line\"><span class=\"keyword\">for</span> <span class=\"built_in\">i</span> = <span class=\"number\">1</span>:k</div><div class=\"line\">    <span class=\"comment\">% sample point</span></div><div class=\"line\">    idx = randsample(N, n);</div><div class=\"line\">    data_sampled = data(idx, :);</div><div class=\"line\">    <span class=\"comment\">% fit with least square</span></div><div class=\"line\">    [a, b] = ls_fit(data_sampled(:, <span class=\"number\">1</span>:<span class=\"number\">2</span>), data_sampled(:, <span class=\"number\">3</span>));</div><div class=\"line\">    <span class=\"comment\">% test model</span></div><div class=\"line\">    not_sampled = <span class=\"built_in\">ones</span>(N, <span class=\"number\">1</span>);</div><div class=\"line\">    not_sampled(idx) = <span class=\"number\">0</span>;</div><div class=\"line\">    not_sampled_data = data(not_sampled == <span class=\"number\">1</span>, :);</div><div class=\"line\">    distance = <span class=\"built_in\">abs</span>(not_sampled_data(:, <span class=\"number\">1</span>:<span class=\"number\">2</span>) * [a; b] - not_sampled_data(:, <span class=\"number\">3</span>)) / <span class=\"built_in\">sqrt</span>(a^<span class=\"number\">2</span>+<span class=\"number\">1</span>);</div><div class=\"line\">    inner_flag = distance &lt; t;</div><div class=\"line\">    good_cnt = sum(inner_flag);</div><div class=\"line\">    <span class=\"keyword\">if</span> good_cnt &gt;= d &amp;&amp; good_cnt &gt; best_good_cnt</div><div class=\"line\">        best_good_cnt = good_cnt;</div><div class=\"line\">        data_refine = data(<span class=\"built_in\">find</span>(inner_flag), :);</div><div class=\"line\">        [a, b] = ls_fit(data_refine(:, <span class=\"number\">1</span>:<span class=\"number\">2</span>), data_refine(:, <span class=\"number\">3</span>));</div><div class=\"line\">        best_a = a;</div><div class=\"line\">        best_b = b;</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\">    fprintf(<span class=\"string\">'iteration %d, best_a = %f, best_b = %f\\n'</span>, <span class=\"built_in\">i</span>, best_a, best_b);</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\">a = best_a;</div><div class=\"line\">b = best_b;</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"params\">[a, b]</span> = <span class=\"title\">ls_fit</span><span class=\"params\">(X, Y)</span></span></div><div class=\"line\"><span class=\"comment\">% least square fit</span></div><div class=\"line\">A = X'*X\\X'*Y;</div><div class=\"line\">a = A(<span class=\"number\">1</span>);</div><div class=\"line\">b = A(<span class=\"number\">2</span>);</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure></p>\n<p>我们对RANSAC稍作分析，可以大概了解试验次数$k$的确定方法。</p>\n<p>仍然使用上述直线拟合的例子。如果所有点中内点所占的比例为$\\omega$，每次挑选$n$个点尝试（上述demo代码中取$n=2$）。那么每次挑选的两个点全部是内点的概率为$\\omega^n$。当选取的$n$个点全部为内点时，视为有效实验。那么，重复$k$次实验，有效实验次数为0的概率为$(1-\\omega^n)^k$。由于底数小于1，所以我们只需尽量增大$k$，就能够降低这种倒霉的概率。下图是不同$n$和$\\omega$情况下为了使得实验成功的概率大于0.99所需的$k$的分布。<br><img src=\"/img/ransac_k.png\" alt=\"k\"></p>\n<p>RANSAC方法的有点在于能够较为鲁棒地估计模型的参数，而且实现简单。缺点在于当离群点比例较大时，为保证实验成功所需的$k$值较大。这时候，可能Hough变换等基于投票的方法更适合用于图像中的直线检测问题。</p>\n","excerpt":"","more":"<p>边缘(Edge)在哺乳动物的视觉中有重要意义。在由若干卷积层构成的深度神经网络中，较低层的卷积层就被训练成为对特定形状的边缘做出响应。边缘检测也是计算机视觉和图像处理领域中一个重要的问题。</p>\n<h2 id=\"边缘的产生\"><a href=\"#边缘的产生\" class=\"headerlink\" title=\"边缘的产生\"></a>边缘的产生</h2><p>若仍采取将图像视作某一函数的观点，边缘是指这个函数中的不连续点。边缘检测是后续进行目标检测和形状识别的基础，也能够在立体视觉中恢复视角等。边缘的来源主要有以下几点：</p>\n<ul>\n<li>物体表面不平造成灰度值的不连续；</li>\n<li>深度值不同造成灰度值不连续；</li>\n<li>物体表面颜色的突变造成灰度值不连续</li>\n</ul>\n<h2 id=\"朴素思想\"><a href=\"#朴素思想\" class=\"headerlink\" title=\"朴素思想\"></a>朴素思想</h2><p>利用边缘是图像中不连续点的这一性质，可以通过计算图像的一阶导数，再找到一阶导数的极大值，即认为是边缘点。如下图所示，在白黑交界处，图像一阶导数的值非常大，表明此处灰度值变化剧烈，是边缘。<br><img src=\"/img/edge_deriative.png\" alt=\"边缘点处导数很大\"></p>\n<p>问题转换为如何求取图像的一阶导数（或梯度）。由于图像是离散的二元函数，所以下文不再区分求导与差分。</p>\n<p>在$x$方向上，令$g_x = \\frac{\\partial f}{\\partial x}$；在$y$方向上，令$g_y = \\frac{\\partial f}{\\partial y}$。梯度的大小和方向为</p>\n<script type=\"math/tex; mode=display\">g = \\lbrack g_x, g_y\\rbrack, \\theta = \\arctan(g_y/g_x)</script><p>通过和Sobel算子等做卷积，可以求取两个正交方向上图像的一阶导数，并计算梯度，之后检测梯度的局部极大值就能够找出边缘点了。</p>\n<p>只是这种方法很容易受到噪声影响。如图所示，真实的边缘点被湮没在了噪声中。<br><img src=\"/img/fun_noise.png\" alt=\"噪声影响湮没了边缘点\"></p>\n<h2 id=\"改进1：先平滑\"><a href=\"#改进1：先平滑\" class=\"headerlink\" title=\"改进1：先平滑\"></a>改进1：先平滑</h2><p>改进措施1，可以首先对图像进行高斯平滑，再按照上面的方法求取边缘点。根据卷积的性质，有：</p>\n<script type=\"math/tex; mode=display\">\\frac{d}{dx}(f\\ast g) = f\\ast\\frac{d}{dx}g</script><p>所以我们可以先求取高斯核的一阶导数，再和原始图像直接做一次卷积就可以一举两得了。这样，引出了DoG(Deriative of Gaussian)。$x$方向的DoG如图所示。<br><img src=\"/img/dog_x.png\" alt=\"x方向的DoG\"></p>\n<p>进行高斯平滑不可避免会使图像中原本的细节部分模糊，所以需要在克服噪声和引入模糊之间做好折中。<br><img src=\"/img/dog_different_size.png\" alt=\"不同\"></p>\n<h2 id=\"改进2：Canny检测子\"><a href=\"#改进2：Canny检测子\" class=\"headerlink\" title=\"改进2：Canny检测子\"></a>改进2：Canny检测子</h2><p>改进措施2，使用Canny检测子进行检测。Canny检测方法同样基于梯度，其基本原理如下：</p>\n<ul>\n<li>使用DoG计算梯度幅值和方向。</li>\n<li>非极大值抑制，这个过程需要根据梯度方向做线性插值。如图，沿着点$q$的梯度方向找到了$p$和$r$两个点。这两个点的梯度幅值需要根据其临近的两点做插值得到。</li>\n<li>利用梯度方向和边缘线互相垂直这一性质，如图，若已经确定点$p$为边缘点，则向它的梯度方向正交方向上寻找下一个边缘点（点$r$或$s$）。这一步也叫edge linking。</li>\n</ul>\n<p><img src=\"/img/canny_nms.png\" alt=\"nms示意图\"><br><img src=\"/img/canny_linking.png\" alt=\"linking示意图\"></p>\n<p>同时，为了提高算法性能，Canny中采用了迟滞阈值的方法，设定<code>low</code>和<code>high</code>两个阈值，来判定某个点是否属于<strong>强</strong>或<strong>弱</strong>边缘点。在做edge linking的时候，从强边缘点开始，如果遇到了弱边缘点，则继续，直到某点的梯度幅值甚至比<code>low</code>还要小，则在此停止。</p>\n<h2 id=\"改进3：RANSAC方法\"><a href=\"#改进3：RANSAC方法\" class=\"headerlink\" title=\"改进3：RANSAC方法\"></a>改进3：RANSAC方法</h2><p>有的时候，我们并不是想要找到所有的边缘点，可能只是想找到图像中水平方向的某些边缘。这时候可以考虑采用RANSAC方法。</p>\n<p>RANSAC方法的思想在于，认为已有的feature大部分都是<strong>好的</strong>。这样，每次随机抽取出若干feature，建立model，再在整个feature集合上进行验证。那么由那些好的feature得到的model一定是得分较高的。（世界上还是好人多啊！）这样就剔除了离群点的影响。</p>\n<p>以直线拟合为例，在下图中，给出了使用RANSAC方法拟合直线的步骤。如图1所示，由于离群点的存在，如果直接使用最小二乘法进行拟合，拟合结果效果会很不理想。由于确定一条直线需要两个点，所以从点集中选取两个点，并计算拟合直线。并计算点集中的点在这条直线附近的个数，作为对模型好坏的判定，这些点是新的内点。找出最优的那条直线，使用其所有内点再进行拟合，重复上述操作，直至迭代终止。<br><img src=\"/img/ransac_step.png\" alt=\"ransac step\"></p>\n<p>上述RANSAC方法进行直线拟合的过程可以总结如下：<br><img src=\"/img/ransac_line_fit.png\" alt=\"ransac line fit alg\"></p>\n<p>按照上述思想，我分别使用最小二乘法和RANSAC方法尝试进行直线拟合。在下面的代码中，我首先产生了正常受到一定高斯噪声污染的数据（图中的红色点），这些点的真值都落在直线$y = 2x+1$上。而后，我随机变化了斜率和截距，以期产生一些离群点（图中的蓝色点）。当然，由于随机性，这种方法生成的点有可能仍然是内点。</p>\n<p>而后，我分别使用上述两种方法进行拟合。可以从结果图中看出，RANSAC（绿色线）能够有效避免离群点的干扰，获得更好的拟合效果。在某次实验中，两种方法的拟合结果如下：<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">least square: a = 3.319566, b = -1.446528</div><div class=\"line\">ransac method: a = 1.899640, b= 1.298608</div></pre></td></tr></table></figure></p>\n<p><img src=\"/img/line_fit_demo.png\" alt=\"demo result\"></p>\n<p>实验使用的MATLAB代码如下：<br><figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">%% generate data</span></div><div class=\"line\">x = <span class=\"number\">0</span>:<span class=\"number\">1</span>:<span class=\"number\">10</span>;</div><div class=\"line\">y_gt = <span class=\"number\">2</span>*x+<span class=\"number\">1</span>;</div><div class=\"line\">y = y_gt + <span class=\"built_in\">randn</span>(<span class=\"built_in\">size</span>(y_gt));</div><div class=\"line\">scatter(x, y, [], [<span class=\"number\">1</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>]);</div><div class=\"line\">hold on</div><div class=\"line\">out_x = <span class=\"number\">0</span>:<span class=\"number\">1</span>:<span class=\"number\">10</span>;</div><div class=\"line\">out_y = <span class=\"number\">5</span>*<span class=\"built_in\">rand</span>(<span class=\"built_in\">size</span>(out_x)).*out_x + <span class=\"number\">4</span>*<span class=\"built_in\">rand</span>(<span class=\"built_in\">size</span>(out_x));</div><div class=\"line\">scatter(out_x, out_y, [], [<span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">1</span>]);</div><div class=\"line\">X = [x, out_x]';</div><div class=\"line\">Y = [y, out_y]';</div><div class=\"line\">X = [X, ones(length(X), <span class=\"number\">1</span>)];</div><div class=\"line\">[a, b] = ls_fit(X, Y);</div><div class=\"line\">plot(x, a*x+b, <span class=\"string\">'linestyle'</span>, <span class=\"string\">'--'</span>, <span class=\"string\">'color'</span>, <span class=\"string\">'r'</span>);</div><div class=\"line\"></div><div class=\"line\">[ra, rb] = ransac_fit(X, Y, <span class=\"number\">100</span>, <span class=\"number\">2</span>, <span class=\"number\">0.5</span>, <span class=\"number\">3</span>);</div><div class=\"line\">plot(x, ra*x+rb, <span class=\"string\">'linestyle'</span>, <span class=\"string\">'-.'</span>, <span class=\"string\">'color'</span>, <span class=\"string\">'g'</span>);</div><div class=\"line\">fprintf(<span class=\"string\">'least square: a = %f, b = %f\\n'</span>,a, b);</div><div class=\"line\">fprintf(<span class=\"string\">'ransac method: a = %f, b= %f\\n'</span>, ra, rb)</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"params\">[a, b]</span> = <span class=\"title\">ransac_fit</span><span class=\"params\">(X, Y, k, n, t ,d)</span></span></div><div class=\"line\"><span class=\"comment\">% ransac fit</span></div><div class=\"line\"><span class=\"comment\">% k -- maximum iteration number</span></div><div class=\"line\"><span class=\"comment\">% n -- smallest point numer required</span></div><div class=\"line\"><span class=\"comment\">% t -- threshold to identify a point is fit well</span></div><div class=\"line\"><span class=\"comment\">% d -- the number of nearby points to assert a model is fine</span></div><div class=\"line\">data = [X, Y];</div><div class=\"line\">N = <span class=\"built_in\">size</span>(data, <span class=\"number\">1</span>);</div><div class=\"line\">best_good_cnt = <span class=\"number\">-1</span>;</div><div class=\"line\">best_a = <span class=\"number\">0</span>;</div><div class=\"line\">best_b = <span class=\"number\">0</span>;</div><div class=\"line\"><span class=\"keyword\">for</span> <span class=\"built_in\">i</span> = <span class=\"number\">1</span>:k</div><div class=\"line\">    <span class=\"comment\">% sample point</span></div><div class=\"line\">    idx = randsample(N, n);</div><div class=\"line\">    data_sampled = data(idx, :);</div><div class=\"line\">    <span class=\"comment\">% fit with least square</span></div><div class=\"line\">    [a, b] = ls_fit(data_sampled(:, <span class=\"number\">1</span>:<span class=\"number\">2</span>), data_sampled(:, <span class=\"number\">3</span>));</div><div class=\"line\">    <span class=\"comment\">% test model</span></div><div class=\"line\">    not_sampled = <span class=\"built_in\">ones</span>(N, <span class=\"number\">1</span>);</div><div class=\"line\">    not_sampled(idx) = <span class=\"number\">0</span>;</div><div class=\"line\">    not_sampled_data = data(not_sampled == <span class=\"number\">1</span>, :);</div><div class=\"line\">    distance = <span class=\"built_in\">abs</span>(not_sampled_data(:, <span class=\"number\">1</span>:<span class=\"number\">2</span>) * [a; b] - not_sampled_data(:, <span class=\"number\">3</span>)) / <span class=\"built_in\">sqrt</span>(a^<span class=\"number\">2</span>+<span class=\"number\">1</span>);</div><div class=\"line\">    inner_flag = distance &lt; t;</div><div class=\"line\">    good_cnt = sum(inner_flag);</div><div class=\"line\">    <span class=\"keyword\">if</span> good_cnt &gt;= d &amp;&amp; good_cnt &gt; best_good_cnt</div><div class=\"line\">        best_good_cnt = good_cnt;</div><div class=\"line\">        data_refine = data(<span class=\"built_in\">find</span>(inner_flag), :);</div><div class=\"line\">        [a, b] = ls_fit(data_refine(:, <span class=\"number\">1</span>:<span class=\"number\">2</span>), data_refine(:, <span class=\"number\">3</span>));</div><div class=\"line\">        best_a = a;</div><div class=\"line\">        best_b = b;</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\">    fprintf(<span class=\"string\">'iteration %d, best_a = %f, best_b = %f\\n'</span>, <span class=\"built_in\">i</span>, best_a, best_b);</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\">a = best_a;</div><div class=\"line\">b = best_b;</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"params\">[a, b]</span> = <span class=\"title\">ls_fit</span><span class=\"params\">(X, Y)</span></span></div><div class=\"line\"><span class=\"comment\">% least square fit</span></div><div class=\"line\">A = X'*X\\X'*Y;</div><div class=\"line\">a = A(<span class=\"number\">1</span>);</div><div class=\"line\">b = A(<span class=\"number\">2</span>);</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure></p>\n<p>我们对RANSAC稍作分析，可以大概了解试验次数$k$的确定方法。</p>\n<p>仍然使用上述直线拟合的例子。如果所有点中内点所占的比例为$\\omega$，每次挑选$n$个点尝试（上述demo代码中取$n=2$）。那么每次挑选的两个点全部是内点的概率为$\\omega^n$。当选取的$n$个点全部为内点时，视为有效实验。那么，重复$k$次实验，有效实验次数为0的概率为$(1-\\omega^n)^k$。由于底数小于1，所以我们只需尽量增大$k$，就能够降低这种倒霉的概率。下图是不同$n$和$\\omega$情况下为了使得实验成功的概率大于0.99所需的$k$的分布。<br><img src=\"/img/ransac_k.png\" alt=\"k\"></p>\n<p>RANSAC方法的有点在于能够较为鲁棒地估计模型的参数，而且实现简单。缺点在于当离群点比例较大时，为保证实验成功所需的$k$值较大。这时候，可能Hough变换等基于投票的方法更适合用于图像中的直线检测问题。</p>\n"},{"title":"CS131-线性滤波器和矩阵的SVD分解","date":"2017-01-23T04:19:05.000Z","_content":"\n数字图像可以看做$\\mathbb{R}^2 \\rightarrow \\mathbb{R}^c$的映射，其中$c$是图像的channel数。使用信号与系统的角度来看，如果单独考察某个channel，可以将图像看做是二维离散系统。\n\n## 卷积\n卷积的概念不再详述，利用不同的kernel与原始图像做卷积，就是对图像进行线性滤波的过程。卷积操作时，以某一个点为中心点，最终结果是这个点以及它的邻域点的线性组合，组合系数由kernel决定。一般kernel的大小取成奇数。如下图所示。（图片来自[博客《图像卷积与滤波的一些知识点》](http://blog.csdn.net/zouxy09/article/details/49080029)）\n![卷积操作示意图](/img/convolution.png)\n\n在卷积操作时，常常需要对图像做padding，常用的padding方法有：\n- zero padding，也就是填充0值。\n- edge replication，也就是复制边缘值进行填充。\n- mirror extension，也就是将图像看做是周期性的，相当于使用对侧像素值进行填充。\n\n## 作业1\n### 调整图像灰度值为0到255\n\n计算相应的k和offset值即可。另外MATLAB中的`uint8`函数可以将结果削顶与截底为0到255之间。\n``` matlab\nscale_ratio = 255.0 / (max_val - min_val);\noffset = -min_val * scale_ratio;\nfixedimg = scale_ratio * dark + offset;\n```\n\n### SVD图像压缩\n\n使用SVD进行图像压缩，下图是将所有奇异值按照从大到小的顺序排列的大小示意图。可以看到，第一个奇异值比其他高出一个数量级。\n![SVD值大小示意图](/img/svd_ranking.png)\n\n#### MATLAB实现\n分别使用10，50， 100个分量进行图像压缩，如下图所示。可以看到，k=10时，已经能够复原出原图像的大致轮廓。当k更大时，更多细节被复原出来。\n![不同分量个数的图像压缩](/img/svd_flower.png)\n\nMATLAB代码如下：\n``` matlab\n%% read image\nim = imread('./flower.bmp');\nim_gray = double(rgb2gray(im));\n[u, s, v] = svd(im_gray);\n%% get sigular value\nsigma = diag(s);\ntop_k = sigma(1:10);\nfigure\nplot(1:length(sigma), sigma, 'r-', 'marker', 's', 'markerfacecolor', 'g');\n\nfigure\nsubplot(2, 2, 1);\nimshow(uint8(im_gray));\ntitle('flower.bmp')\nindex = 2;\nfor k = [10, 50, 100]\n    uk = u(:, 1:k);\n    sk = s(1:k, 1:k);\n    vk = v(:, 1:k);\n    im_rec = uk * sk * vk';\n    subplot(2, 2, index);\n    index = index + 1;\n    imshow(uint8(im_rec));\n    title(sprintf('k = %d', k));\nend\n```\n\n#### 图像SVD压缩中的误差分析\n完全是个人随手推导，不严格的说明：\n\n将矩阵分块。由SVD分解公式$\\mathbf{U}\\mathbf{\\Sigma} \\mathbf{V^\\dagger} = \\mathbf{A}$，把$\\mathbf{U}$按列分块，$\\mathbf{V^\\dagger}$按行分块，有下式成立：\n$$\n\\begin{bmatrix}\nu_1 & u_2 &\\vdots  &u_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\sigma_1 &  &  & \\\\\\\\\n &  \\sigma_2&  & \\\\\\\\\n &  &  \\ddots& \\\\\\\\\n &  &  &\\sigma_m\n\\end{bmatrix}\n\\begin{bmatrix}\nv_1^\\dagger\\\\\\\\\nv_2^\\dagger\\\\\\\\\n\\dots\\\\\\\\\nv_m^\\dagger\n\\end{bmatrix}=\\mathbf{A}\n$$\n\n由于\n$$\n\\begin{bmatrix}\nu_1 & u_2 &\\vdots  &u_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\sigma_1 &  &  & \\\\\\\\\n &  \\sigma_2&  & \\\\\\\\\n &  &  \\ddots& \\\\\\\\\n &  &  &\\sigma_m\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\sigma_1u_1 & \\sigma_2u_2 &\\vdots  &\\sigma_nu_n\n\\end{bmatrix}\n$$\n\n所以，\n\n$$\\mathbf{A} = \\sum_{i = 1}^{r}\\sigma_iu_iv_i^\\dagger$$\n\n上面的式子和式里面只有$r$项，是因为当$k > r$时，$\\sigma_k = 0$。\n\n所以$$\\mathbf{A} - \\hat{\\mathbf{A}} = \\sum_{i = k+1}^{r}\\sigma_iu_iv_i^\\dagger$$\n\n根绝矩阵范数的[性质](https://zh.wikipedia.org/wiki/矩陣範數)，我们有，\n$$\\left\\lVert\\mathbf{A} - \\hat{\\mathbf{A}}\\right\\rVert \\le \\sum_{i=k+1}^{r}\\sigma_i\\left\\lVert u_i\\right\\rVert\\left\\lVert v_i^\\dagger\\right\\rVert$$\n\n由于$u_i$和$v_i$都是标准正交基，所以范数小于1.故，\n\n$$\\left\\lVert\\mathbf{A} - \\hat{\\mathbf{A}}\\right\\rVert \\le \\sum_{i=k+1}^{r}\\sigma_i$$\n\n取无穷范数，可以知道对于误差矩阵中的任意元素（也就是压缩重建之后任意位置的像素灰度值之差），都有：\n\n$$e \\le \\sum_{i=k+1}^{r}\\sigma_i$$\n\n### SVD与矩阵范数\n\n如果某个函数$f$满足以下的性质，就可以作为矩阵的范数。\n- $f(\\mathbf{A}) = \\mathbf{0} \\Leftrightarrow \\mathbf{A} = \\mathbf{0}$\n- $f(c\\mathbf{A}) = c f(\\mathbf{A}), \\forall c \\in \\mathbb{R}$\n- $f(\\mathbf{A+b}) \\le f(\\mathbf{A}) + f(\\mathbf{B})$\n\n其中，矩阵的2范数可以定义为\n$$\\left\\lVert\\mathbf{A}\\right\\rVert_2 = \\max{\\sqrt{(\\mathbf{A}x)^\\dagger\\mathbf{A}x}}\n$$\n\n其中，$x$是单位向量。上式的意义在于表明矩阵的2范数是对于所有向量，经过该矩阵线性变换后摸长最大的那个变换后向量的长度。\n\n下面，给出不严格的说明，证明矩阵的2范数数值上等于其最大的奇异值。\n\n对于空间内的任意单位向量$x$，利用矩阵的SVD分解，有（为了书写简单，矩阵不再单独加粗）：\n$$(Ax)^\\dagger Ax = x^\\dagger V \\Sigma^\\dagger \\Sigma V^\\dagger x$$\n其中，$U^\\dagger U = I$，已经被消去了。\n\n进一步化简，我们将$V^\\dagger x$看做一个整体，令$\\omega = V\\dagger x$，那么有，\n$$(Ax)^\\dagger Ax = (\\Sigma \\omega)^\\dagger \\Sigma \\omega$$\n\n也就是说，矩阵的2范转换为了$\\Sigma \\omega$的幅值的最大值。由于$\\omega$是酉矩阵和一个单位向量的乘积，所以$\\omega$仍然是单位阵。\n\n由于$\\Sigma$是对角阵，所以$\\omega$与其相乘后，相当于每个分量分别被放大了$\\sigma_i$倍。即\n\n$$\\Sigma \\omega =\n\\begin{bmatrix}\n\\sigma_1 \\omega_1\\\\\\\\\n\\sigma_2 \\omega_2\\\\\\\\\n\\cdots\\\\\\\\\n\\sigma_n \\omega_n\n\\end{bmatrix}\n$$\n\n它的幅值平方为\n\n$$\\left\\lVert \\Sigma \\omega \\right \\rVert ^2 = \\sum_{i=1}^{n}\\sigma_i^2 \\omega_i^2 \\le \\sigma_{1} \\sum_{i=1}^{n}\\omega_i^2 = \\sigma_1^2$$\n\n当且仅当，$\\omega_1 = 1$, $\\omega_k = 0, k > 1$时取得等号。\n\n综上所述，矩阵2范数的值等于其最大的奇异值。\n\n矩阵的另一种范数定义方法Frobenius norm定义如下：\n$$\\left\\lVert A \\right\\rVert_{F} = \\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n}\\left\\vert a_{i,j}\\right\\rvert}$$\n\n如果我们两边平方，可以得到，矩阵的F范数实际等于某个矩阵的迹，见下式：\n\n$$\\left\\lVert A\\right \\rVert_F^2 = \\text{trace}(A^\\dagger A)$$\n\n利用矩阵的SVD分解，可以很容易得出，$\\text{trace}(A^\\dagger A) = \\sum_{i=1}^{r}\\sigma_i^2$\n\n说明如下：\n$$\\text{trace}(A^\\dagger A) = \\text{trace}(V\\Sigma^\\dagger\\Sigma V^\\dagger)$$\n\n由于$V^\\dagger = V^{-1}$，而且$\\text{trace}(BAB^{-1}) = \\text{trace}(A)$，所以，\n$$\\text{trace}(A^\\dagger A) = \\text{trace}(\\Sigma^\\dagger \\Sigma) = \\sum_{i=1}^{r}\\sigma_i^2$$\n\n也就是说，矩阵的F范数等于它的奇异值平方和的平方根。\n\n$$\\left\\lVert A\\right\\rVert_F= \\sqrt{\\sum_{i=1}^{r}\\sigma_i^2}$$\n","source":"_posts/cs131-filter-svd.md","raw":"---\ntitle: CS131-线性滤波器和矩阵的SVD分解\ndate: 2017-01-23 12:19:05\ntags:\n     - cs131\n     - 公开课\n---\n\n数字图像可以看做$\\mathbb{R}^2 \\rightarrow \\mathbb{R}^c$的映射，其中$c$是图像的channel数。使用信号与系统的角度来看，如果单独考察某个channel，可以将图像看做是二维离散系统。\n\n## 卷积\n卷积的概念不再详述，利用不同的kernel与原始图像做卷积，就是对图像进行线性滤波的过程。卷积操作时，以某一个点为中心点，最终结果是这个点以及它的邻域点的线性组合，组合系数由kernel决定。一般kernel的大小取成奇数。如下图所示。（图片来自[博客《图像卷积与滤波的一些知识点》](http://blog.csdn.net/zouxy09/article/details/49080029)）\n![卷积操作示意图](/img/convolution.png)\n\n在卷积操作时，常常需要对图像做padding，常用的padding方法有：\n- zero padding，也就是填充0值。\n- edge replication，也就是复制边缘值进行填充。\n- mirror extension，也就是将图像看做是周期性的，相当于使用对侧像素值进行填充。\n\n## 作业1\n### 调整图像灰度值为0到255\n\n计算相应的k和offset值即可。另外MATLAB中的`uint8`函数可以将结果削顶与截底为0到255之间。\n``` matlab\nscale_ratio = 255.0 / (max_val - min_val);\noffset = -min_val * scale_ratio;\nfixedimg = scale_ratio * dark + offset;\n```\n\n### SVD图像压缩\n\n使用SVD进行图像压缩，下图是将所有奇异值按照从大到小的顺序排列的大小示意图。可以看到，第一个奇异值比其他高出一个数量级。\n![SVD值大小示意图](/img/svd_ranking.png)\n\n#### MATLAB实现\n分别使用10，50， 100个分量进行图像压缩，如下图所示。可以看到，k=10时，已经能够复原出原图像的大致轮廓。当k更大时，更多细节被复原出来。\n![不同分量个数的图像压缩](/img/svd_flower.png)\n\nMATLAB代码如下：\n``` matlab\n%% read image\nim = imread('./flower.bmp');\nim_gray = double(rgb2gray(im));\n[u, s, v] = svd(im_gray);\n%% get sigular value\nsigma = diag(s);\ntop_k = sigma(1:10);\nfigure\nplot(1:length(sigma), sigma, 'r-', 'marker', 's', 'markerfacecolor', 'g');\n\nfigure\nsubplot(2, 2, 1);\nimshow(uint8(im_gray));\ntitle('flower.bmp')\nindex = 2;\nfor k = [10, 50, 100]\n    uk = u(:, 1:k);\n    sk = s(1:k, 1:k);\n    vk = v(:, 1:k);\n    im_rec = uk * sk * vk';\n    subplot(2, 2, index);\n    index = index + 1;\n    imshow(uint8(im_rec));\n    title(sprintf('k = %d', k));\nend\n```\n\n#### 图像SVD压缩中的误差分析\n完全是个人随手推导，不严格的说明：\n\n将矩阵分块。由SVD分解公式$\\mathbf{U}\\mathbf{\\Sigma} \\mathbf{V^\\dagger} = \\mathbf{A}$，把$\\mathbf{U}$按列分块，$\\mathbf{V^\\dagger}$按行分块，有下式成立：\n$$\n\\begin{bmatrix}\nu_1 & u_2 &\\vdots  &u_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\sigma_1 &  &  & \\\\\\\\\n &  \\sigma_2&  & \\\\\\\\\n &  &  \\ddots& \\\\\\\\\n &  &  &\\sigma_m\n\\end{bmatrix}\n\\begin{bmatrix}\nv_1^\\dagger\\\\\\\\\nv_2^\\dagger\\\\\\\\\n\\dots\\\\\\\\\nv_m^\\dagger\n\\end{bmatrix}=\\mathbf{A}\n$$\n\n由于\n$$\n\\begin{bmatrix}\nu_1 & u_2 &\\vdots  &u_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\sigma_1 &  &  & \\\\\\\\\n &  \\sigma_2&  & \\\\\\\\\n &  &  \\ddots& \\\\\\\\\n &  &  &\\sigma_m\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\sigma_1u_1 & \\sigma_2u_2 &\\vdots  &\\sigma_nu_n\n\\end{bmatrix}\n$$\n\n所以，\n\n$$\\mathbf{A} = \\sum_{i = 1}^{r}\\sigma_iu_iv_i^\\dagger$$\n\n上面的式子和式里面只有$r$项，是因为当$k > r$时，$\\sigma_k = 0$。\n\n所以$$\\mathbf{A} - \\hat{\\mathbf{A}} = \\sum_{i = k+1}^{r}\\sigma_iu_iv_i^\\dagger$$\n\n根绝矩阵范数的[性质](https://zh.wikipedia.org/wiki/矩陣範數)，我们有，\n$$\\left\\lVert\\mathbf{A} - \\hat{\\mathbf{A}}\\right\\rVert \\le \\sum_{i=k+1}^{r}\\sigma_i\\left\\lVert u_i\\right\\rVert\\left\\lVert v_i^\\dagger\\right\\rVert$$\n\n由于$u_i$和$v_i$都是标准正交基，所以范数小于1.故，\n\n$$\\left\\lVert\\mathbf{A} - \\hat{\\mathbf{A}}\\right\\rVert \\le \\sum_{i=k+1}^{r}\\sigma_i$$\n\n取无穷范数，可以知道对于误差矩阵中的任意元素（也就是压缩重建之后任意位置的像素灰度值之差），都有：\n\n$$e \\le \\sum_{i=k+1}^{r}\\sigma_i$$\n\n### SVD与矩阵范数\n\n如果某个函数$f$满足以下的性质，就可以作为矩阵的范数。\n- $f(\\mathbf{A}) = \\mathbf{0} \\Leftrightarrow \\mathbf{A} = \\mathbf{0}$\n- $f(c\\mathbf{A}) = c f(\\mathbf{A}), \\forall c \\in \\mathbb{R}$\n- $f(\\mathbf{A+b}) \\le f(\\mathbf{A}) + f(\\mathbf{B})$\n\n其中，矩阵的2范数可以定义为\n$$\\left\\lVert\\mathbf{A}\\right\\rVert_2 = \\max{\\sqrt{(\\mathbf{A}x)^\\dagger\\mathbf{A}x}}\n$$\n\n其中，$x$是单位向量。上式的意义在于表明矩阵的2范数是对于所有向量，经过该矩阵线性变换后摸长最大的那个变换后向量的长度。\n\n下面，给出不严格的说明，证明矩阵的2范数数值上等于其最大的奇异值。\n\n对于空间内的任意单位向量$x$，利用矩阵的SVD分解，有（为了书写简单，矩阵不再单独加粗）：\n$$(Ax)^\\dagger Ax = x^\\dagger V \\Sigma^\\dagger \\Sigma V^\\dagger x$$\n其中，$U^\\dagger U = I$，已经被消去了。\n\n进一步化简，我们将$V^\\dagger x$看做一个整体，令$\\omega = V\\dagger x$，那么有，\n$$(Ax)^\\dagger Ax = (\\Sigma \\omega)^\\dagger \\Sigma \\omega$$\n\n也就是说，矩阵的2范转换为了$\\Sigma \\omega$的幅值的最大值。由于$\\omega$是酉矩阵和一个单位向量的乘积，所以$\\omega$仍然是单位阵。\n\n由于$\\Sigma$是对角阵，所以$\\omega$与其相乘后，相当于每个分量分别被放大了$\\sigma_i$倍。即\n\n$$\\Sigma \\omega =\n\\begin{bmatrix}\n\\sigma_1 \\omega_1\\\\\\\\\n\\sigma_2 \\omega_2\\\\\\\\\n\\cdots\\\\\\\\\n\\sigma_n \\omega_n\n\\end{bmatrix}\n$$\n\n它的幅值平方为\n\n$$\\left\\lVert \\Sigma \\omega \\right \\rVert ^2 = \\sum_{i=1}^{n}\\sigma_i^2 \\omega_i^2 \\le \\sigma_{1} \\sum_{i=1}^{n}\\omega_i^2 = \\sigma_1^2$$\n\n当且仅当，$\\omega_1 = 1$, $\\omega_k = 0, k > 1$时取得等号。\n\n综上所述，矩阵2范数的值等于其最大的奇异值。\n\n矩阵的另一种范数定义方法Frobenius norm定义如下：\n$$\\left\\lVert A \\right\\rVert_{F} = \\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n}\\left\\vert a_{i,j}\\right\\rvert}$$\n\n如果我们两边平方，可以得到，矩阵的F范数实际等于某个矩阵的迹，见下式：\n\n$$\\left\\lVert A\\right \\rVert_F^2 = \\text{trace}(A^\\dagger A)$$\n\n利用矩阵的SVD分解，可以很容易得出，$\\text{trace}(A^\\dagger A) = \\sum_{i=1}^{r}\\sigma_i^2$\n\n说明如下：\n$$\\text{trace}(A^\\dagger A) = \\text{trace}(V\\Sigma^\\dagger\\Sigma V^\\dagger)$$\n\n由于$V^\\dagger = V^{-1}$，而且$\\text{trace}(BAB^{-1}) = \\text{trace}(A)$，所以，\n$$\\text{trace}(A^\\dagger A) = \\text{trace}(\\Sigma^\\dagger \\Sigma) = \\sum_{i=1}^{r}\\sigma_i^2$$\n\n也就是说，矩阵的F范数等于它的奇异值平方和的平方根。\n\n$$\\left\\lVert A\\right\\rVert_F= \\sqrt{\\sum_{i=1}^{r}\\sigma_i^2}$$\n","slug":"cs131-filter-svd","published":1,"updated":"2017-02-01T15:10:29.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciyof8h0j0003cq1hpilis28r","content":"<p>数字图像可以看做$\\mathbb{R}^2 \\rightarrow \\mathbb{R}^c$的映射，其中$c$是图像的channel数。使用信号与系统的角度来看，如果单独考察某个channel，可以将图像看做是二维离散系统。</p>\n<h2 id=\"卷积\"><a href=\"#卷积\" class=\"headerlink\" title=\"卷积\"></a>卷积</h2><p>卷积的概念不再详述，利用不同的kernel与原始图像做卷积，就是对图像进行线性滤波的过程。卷积操作时，以某一个点为中心点，最终结果是这个点以及它的邻域点的线性组合，组合系数由kernel决定。一般kernel的大小取成奇数。如下图所示。（图片来自<a href=\"http://blog.csdn.net/zouxy09/article/details/49080029\" target=\"_blank\" rel=\"external\">博客《图像卷积与滤波的一些知识点》</a>）<br><img src=\"/img/convolution.png\" alt=\"卷积操作示意图\"></p>\n<p>在卷积操作时，常常需要对图像做padding，常用的padding方法有：</p>\n<ul>\n<li>zero padding，也就是填充0值。</li>\n<li>edge replication，也就是复制边缘值进行填充。</li>\n<li>mirror extension，也就是将图像看做是周期性的，相当于使用对侧像素值进行填充。</li>\n</ul>\n<h2 id=\"作业1\"><a href=\"#作业1\" class=\"headerlink\" title=\"作业1\"></a>作业1</h2><h3 id=\"调整图像灰度值为0到255\"><a href=\"#调整图像灰度值为0到255\" class=\"headerlink\" title=\"调整图像灰度值为0到255\"></a>调整图像灰度值为0到255</h3><p>计算相应的k和offset值即可。另外MATLAB中的<code>uint8</code>函数可以将结果削顶与截底为0到255之间。<br><figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">scale_ratio = <span class=\"number\">255.0</span> / (max_val - min_val);</div><div class=\"line\">offset = -min_val * scale_ratio;</div><div class=\"line\">fixedimg = scale_ratio * dark + offset;</div></pre></td></tr></table></figure></p>\n<h3 id=\"SVD图像压缩\"><a href=\"#SVD图像压缩\" class=\"headerlink\" title=\"SVD图像压缩\"></a>SVD图像压缩</h3><p>使用SVD进行图像压缩，下图是将所有奇异值按照从大到小的顺序排列的大小示意图。可以看到，第一个奇异值比其他高出一个数量级。<br><img src=\"/img/svd_ranking.png\" alt=\"SVD值大小示意图\"></p>\n<h4 id=\"MATLAB实现\"><a href=\"#MATLAB实现\" class=\"headerlink\" title=\"MATLAB实现\"></a>MATLAB实现</h4><p>分别使用10，50， 100个分量进行图像压缩，如下图所示。可以看到，k=10时，已经能够复原出原图像的大致轮廓。当k更大时，更多细节被复原出来。<br><img src=\"/img/svd_flower.png\" alt=\"不同分量个数的图像压缩\"></p>\n<p>MATLAB代码如下：<br><figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">%% read image</span></div><div class=\"line\">im = imread(<span class=\"string\">'./flower.bmp'</span>);</div><div class=\"line\">im_gray = double(rgb2gray(im));</div><div class=\"line\">[u, s, v] = svd(im_gray);</div><div class=\"line\"><span class=\"comment\">%% get sigular value</span></div><div class=\"line\">sigma = <span class=\"built_in\">diag</span>(s);</div><div class=\"line\">top_k = sigma(<span class=\"number\">1</span>:<span class=\"number\">10</span>);</div><div class=\"line\">figure</div><div class=\"line\">plot(<span class=\"number\">1</span>:<span class=\"built_in\">length</span>(sigma), sigma, <span class=\"string\">'r-'</span>, <span class=\"string\">'marker'</span>, <span class=\"string\">'s'</span>, <span class=\"string\">'markerfacecolor'</span>, <span class=\"string\">'g'</span>);</div><div class=\"line\"></div><div class=\"line\">figure</div><div class=\"line\">subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>);</div><div class=\"line\">imshow(uint8(im_gray));</div><div class=\"line\">title(<span class=\"string\">'flower.bmp'</span>)</div><div class=\"line\">index = <span class=\"number\">2</span>;</div><div class=\"line\"><span class=\"keyword\">for</span> k = [<span class=\"number\">10</span>, <span class=\"number\">50</span>, <span class=\"number\">100</span>]</div><div class=\"line\">    uk = u(:, <span class=\"number\">1</span>:k);</div><div class=\"line\">    sk = s(<span class=\"number\">1</span>:k, <span class=\"number\">1</span>:k);</div><div class=\"line\">    vk = v(:, <span class=\"number\">1</span>:k);</div><div class=\"line\">    im_rec = uk * sk * vk';</div><div class=\"line\">    subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, index);</div><div class=\"line\">    index = index + <span class=\"number\">1</span>;</div><div class=\"line\">    imshow(uint8(im_rec));</div><div class=\"line\">    title(sprintf(<span class=\"string\">'k = %d'</span>, k));</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure></p>\n<h4 id=\"图像SVD压缩中的误差分析\"><a href=\"#图像SVD压缩中的误差分析\" class=\"headerlink\" title=\"图像SVD压缩中的误差分析\"></a>图像SVD压缩中的误差分析</h4><p>完全是个人随手推导，不严格的说明：</p>\n<p>将矩阵分块。由SVD分解公式$\\mathbf{U}\\mathbf{\\Sigma} \\mathbf{V^\\dagger} = \\mathbf{A}$，把$\\mathbf{U}$按列分块，$\\mathbf{V^\\dagger}$按行分块，有下式成立：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{bmatrix}\nu_1 & u_2 &\\vdots  &u_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\sigma_1 &  &  & \\\\\\\\\n &  \\sigma_2&  & \\\\\\\\\n &  &  \\ddots& \\\\\\\\\n &  &  &\\sigma_m\n\\end{bmatrix}\n\\begin{bmatrix}\nv_1^\\dagger\\\\\\\\\nv_2^\\dagger\\\\\\\\\n\\dots\\\\\\\\\nv_m^\\dagger\n\\end{bmatrix}=\\mathbf{A}</script><p>由于</p>\n<script type=\"math/tex; mode=display\">\n\\begin{bmatrix}\nu_1 & u_2 &\\vdots  &u_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\sigma_1 &  &  & \\\\\\\\\n &  \\sigma_2&  & \\\\\\\\\n &  &  \\ddots& \\\\\\\\\n &  &  &\\sigma_m\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\sigma_1u_1 & \\sigma_2u_2 &\\vdots  &\\sigma_nu_n\n\\end{bmatrix}</script><p>所以，</p>\n<script type=\"math/tex; mode=display\">\\mathbf{A} = \\sum_{i = 1}^{r}\\sigma_iu_iv_i^\\dagger</script><p>上面的式子和式里面只有$r$项，是因为当$k &gt; r$时，$\\sigma_k = 0$。</p>\n<p>所以<script type=\"math/tex\">\\mathbf{A} - \\hat{\\mathbf{A}} = \\sum_{i = k+1}^{r}\\sigma_iu_iv_i^\\dagger</script></p>\n<p>根绝矩阵范数的<a href=\"https://zh.wikipedia.org/wiki/矩陣範數\" target=\"_blank\" rel=\"external\">性质</a>，我们有，</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert\\mathbf{A} - \\hat{\\mathbf{A}}\\right\\rVert \\le \\sum_{i=k+1}^{r}\\sigma_i\\left\\lVert u_i\\right\\rVert\\left\\lVert v_i^\\dagger\\right\\rVert</script><p>由于$u_i$和$v_i$都是标准正交基，所以范数小于1.故，</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert\\mathbf{A} - \\hat{\\mathbf{A}}\\right\\rVert \\le \\sum_{i=k+1}^{r}\\sigma_i</script><p>取无穷范数，可以知道对于误差矩阵中的任意元素（也就是压缩重建之后任意位置的像素灰度值之差），都有：</p>\n<script type=\"math/tex; mode=display\">e \\le \\sum_{i=k+1}^{r}\\sigma_i</script><h3 id=\"SVD与矩阵范数\"><a href=\"#SVD与矩阵范数\" class=\"headerlink\" title=\"SVD与矩阵范数\"></a>SVD与矩阵范数</h3><p>如果某个函数$f$满足以下的性质，就可以作为矩阵的范数。</p>\n<ul>\n<li>$f(\\mathbf{A}) = \\mathbf{0} \\Leftrightarrow \\mathbf{A} = \\mathbf{0}$</li>\n<li>$f(c\\mathbf{A}) = c f(\\mathbf{A}), \\forall c \\in \\mathbb{R}$</li>\n<li>$f(\\mathbf{A+b}) \\le f(\\mathbf{A}) + f(\\mathbf{B})$</li>\n</ul>\n<p>其中，矩阵的2范数可以定义为</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert\\mathbf{A}\\right\\rVert_2 = \\max{\\sqrt{(\\mathbf{A}x)^\\dagger\\mathbf{A}x}}</script><p>其中，$x$是单位向量。上式的意义在于表明矩阵的2范数是对于所有向量，经过该矩阵线性变换后摸长最大的那个变换后向量的长度。</p>\n<p>下面，给出不严格的说明，证明矩阵的2范数数值上等于其最大的奇异值。</p>\n<p>对于空间内的任意单位向量$x$，利用矩阵的SVD分解，有（为了书写简单，矩阵不再单独加粗）：</p>\n<script type=\"math/tex; mode=display\">(Ax)^\\dagger Ax = x^\\dagger V \\Sigma^\\dagger \\Sigma V^\\dagger x</script><p>其中，$U^\\dagger U = I$，已经被消去了。</p>\n<p>进一步化简，我们将$V^\\dagger x$看做一个整体，令$\\omega = V\\dagger x$，那么有，</p>\n<script type=\"math/tex; mode=display\">(Ax)^\\dagger Ax = (\\Sigma \\omega)^\\dagger \\Sigma \\omega</script><p>也就是说，矩阵的2范转换为了$\\Sigma \\omega$的幅值的最大值。由于$\\omega$是酉矩阵和一个单位向量的乘积，所以$\\omega$仍然是单位阵。</p>\n<p>由于$\\Sigma$是对角阵，所以$\\omega$与其相乘后，相当于每个分量分别被放大了$\\sigma_i$倍。即</p>\n<script type=\"math/tex; mode=display\">\\Sigma \\omega =\n\\begin{bmatrix}\n\\sigma_1 \\omega_1\\\\\\\\\n\\sigma_2 \\omega_2\\\\\\\\\n\\cdots\\\\\\\\\n\\sigma_n \\omega_n\n\\end{bmatrix}</script><p>它的幅值平方为</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert \\Sigma \\omega \\right \\rVert ^2 = \\sum_{i=1}^{n}\\sigma_i^2 \\omega_i^2 \\le \\sigma_{1} \\sum_{i=1}^{n}\\omega_i^2 = \\sigma_1^2</script><p>当且仅当，$\\omega_1 = 1$, $\\omega_k = 0, k &gt; 1$时取得等号。</p>\n<p>综上所述，矩阵2范数的值等于其最大的奇异值。</p>\n<p>矩阵的另一种范数定义方法Frobenius norm定义如下：</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert A \\right\\rVert_{F} = \\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n}\\left\\vert a_{i,j}\\right\\rvert}</script><p>如果我们两边平方，可以得到，矩阵的F范数实际等于某个矩阵的迹，见下式：</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert A\\right \\rVert_F^2 = \\text{trace}(A^\\dagger A)</script><p>利用矩阵的SVD分解，可以很容易得出，$\\text{trace}(A^\\dagger A) = \\sum_{i=1}^{r}\\sigma_i^2$</p>\n<p>说明如下：</p>\n<script type=\"math/tex; mode=display\">\\text{trace}(A^\\dagger A) = \\text{trace}(V\\Sigma^\\dagger\\Sigma V^\\dagger)</script><p>由于$V^\\dagger = V^{-1}$，而且$\\text{trace}(BAB^{-1}) = \\text{trace}(A)$，所以，</p>\n<script type=\"math/tex; mode=display\">\\text{trace}(A^\\dagger A) = \\text{trace}(\\Sigma^\\dagger \\Sigma) = \\sum_{i=1}^{r}\\sigma_i^2</script><p>也就是说，矩阵的F范数等于它的奇异值平方和的平方根。</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert A\\right\\rVert_F= \\sqrt{\\sum_{i=1}^{r}\\sigma_i^2}</script>","excerpt":"","more":"<p>数字图像可以看做$\\mathbb{R}^2 \\rightarrow \\mathbb{R}^c$的映射，其中$c$是图像的channel数。使用信号与系统的角度来看，如果单独考察某个channel，可以将图像看做是二维离散系统。</p>\n<h2 id=\"卷积\"><a href=\"#卷积\" class=\"headerlink\" title=\"卷积\"></a>卷积</h2><p>卷积的概念不再详述，利用不同的kernel与原始图像做卷积，就是对图像进行线性滤波的过程。卷积操作时，以某一个点为中心点，最终结果是这个点以及它的邻域点的线性组合，组合系数由kernel决定。一般kernel的大小取成奇数。如下图所示。（图片来自<a href=\"http://blog.csdn.net/zouxy09/article/details/49080029\">博客《图像卷积与滤波的一些知识点》</a>）<br><img src=\"/img/convolution.png\" alt=\"卷积操作示意图\"></p>\n<p>在卷积操作时，常常需要对图像做padding，常用的padding方法有：</p>\n<ul>\n<li>zero padding，也就是填充0值。</li>\n<li>edge replication，也就是复制边缘值进行填充。</li>\n<li>mirror extension，也就是将图像看做是周期性的，相当于使用对侧像素值进行填充。</li>\n</ul>\n<h2 id=\"作业1\"><a href=\"#作业1\" class=\"headerlink\" title=\"作业1\"></a>作业1</h2><h3 id=\"调整图像灰度值为0到255\"><a href=\"#调整图像灰度值为0到255\" class=\"headerlink\" title=\"调整图像灰度值为0到255\"></a>调整图像灰度值为0到255</h3><p>计算相应的k和offset值即可。另外MATLAB中的<code>uint8</code>函数可以将结果削顶与截底为0到255之间。<br><figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">scale_ratio = <span class=\"number\">255.0</span> / (max_val - min_val);</div><div class=\"line\">offset = -min_val * scale_ratio;</div><div class=\"line\">fixedimg = scale_ratio * dark + offset;</div></pre></td></tr></table></figure></p>\n<h3 id=\"SVD图像压缩\"><a href=\"#SVD图像压缩\" class=\"headerlink\" title=\"SVD图像压缩\"></a>SVD图像压缩</h3><p>使用SVD进行图像压缩，下图是将所有奇异值按照从大到小的顺序排列的大小示意图。可以看到，第一个奇异值比其他高出一个数量级。<br><img src=\"/img/svd_ranking.png\" alt=\"SVD值大小示意图\"></p>\n<h4 id=\"MATLAB实现\"><a href=\"#MATLAB实现\" class=\"headerlink\" title=\"MATLAB实现\"></a>MATLAB实现</h4><p>分别使用10，50， 100个分量进行图像压缩，如下图所示。可以看到，k=10时，已经能够复原出原图像的大致轮廓。当k更大时，更多细节被复原出来。<br><img src=\"/img/svd_flower.png\" alt=\"不同分量个数的图像压缩\"></p>\n<p>MATLAB代码如下：<br><figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">%% read image</span></div><div class=\"line\">im = imread(<span class=\"string\">'./flower.bmp'</span>);</div><div class=\"line\">im_gray = double(rgb2gray(im));</div><div class=\"line\">[u, s, v] = svd(im_gray);</div><div class=\"line\"><span class=\"comment\">%% get sigular value</span></div><div class=\"line\">sigma = <span class=\"built_in\">diag</span>(s);</div><div class=\"line\">top_k = sigma(<span class=\"number\">1</span>:<span class=\"number\">10</span>);</div><div class=\"line\">figure</div><div class=\"line\">plot(<span class=\"number\">1</span>:<span class=\"built_in\">length</span>(sigma), sigma, <span class=\"string\">'r-'</span>, <span class=\"string\">'marker'</span>, <span class=\"string\">'s'</span>, <span class=\"string\">'markerfacecolor'</span>, <span class=\"string\">'g'</span>);</div><div class=\"line\"></div><div class=\"line\">figure</div><div class=\"line\">subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>);</div><div class=\"line\">imshow(uint8(im_gray));</div><div class=\"line\">title(<span class=\"string\">'flower.bmp'</span>)</div><div class=\"line\">index = <span class=\"number\">2</span>;</div><div class=\"line\"><span class=\"keyword\">for</span> k = [<span class=\"number\">10</span>, <span class=\"number\">50</span>, <span class=\"number\">100</span>]</div><div class=\"line\">    uk = u(:, <span class=\"number\">1</span>:k);</div><div class=\"line\">    sk = s(<span class=\"number\">1</span>:k, <span class=\"number\">1</span>:k);</div><div class=\"line\">    vk = v(:, <span class=\"number\">1</span>:k);</div><div class=\"line\">    im_rec = uk * sk * vk';</div><div class=\"line\">    subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, index);</div><div class=\"line\">    index = index + <span class=\"number\">1</span>;</div><div class=\"line\">    imshow(uint8(im_rec));</div><div class=\"line\">    title(sprintf(<span class=\"string\">'k = %d'</span>, k));</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure></p>\n<h4 id=\"图像SVD压缩中的误差分析\"><a href=\"#图像SVD压缩中的误差分析\" class=\"headerlink\" title=\"图像SVD压缩中的误差分析\"></a>图像SVD压缩中的误差分析</h4><p>完全是个人随手推导，不严格的说明：</p>\n<p>将矩阵分块。由SVD分解公式$\\mathbf{U}\\mathbf{\\Sigma} \\mathbf{V^\\dagger} = \\mathbf{A}$，把$\\mathbf{U}$按列分块，$\\mathbf{V^\\dagger}$按行分块，有下式成立：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{bmatrix}\nu_1 & u_2 &\\vdots  &u_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\sigma_1 &  &  & \\\\\\\\\n &  \\sigma_2&  & \\\\\\\\\n &  &  \\ddots& \\\\\\\\\n &  &  &\\sigma_m\n\\end{bmatrix}\n\\begin{bmatrix}\nv_1^\\dagger\\\\\\\\\nv_2^\\dagger\\\\\\\\\n\\dots\\\\\\\\\nv_m^\\dagger\n\\end{bmatrix}=\\mathbf{A}</script><p>由于</p>\n<script type=\"math/tex; mode=display\">\n\\begin{bmatrix}\nu_1 & u_2 &\\vdots  &u_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\sigma_1 &  &  & \\\\\\\\\n &  \\sigma_2&  & \\\\\\\\\n &  &  \\ddots& \\\\\\\\\n &  &  &\\sigma_m\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\sigma_1u_1 & \\sigma_2u_2 &\\vdots  &\\sigma_nu_n\n\\end{bmatrix}</script><p>所以，</p>\n<script type=\"math/tex; mode=display\">\\mathbf{A} = \\sum_{i = 1}^{r}\\sigma_iu_iv_i^\\dagger</script><p>上面的式子和式里面只有$r$项，是因为当$k &gt; r$时，$\\sigma_k = 0$。</p>\n<p>所以<script type=\"math/tex\">\\mathbf{A} - \\hat{\\mathbf{A}} = \\sum_{i = k+1}^{r}\\sigma_iu_iv_i^\\dagger</script></p>\n<p>根绝矩阵范数的<a href=\"https://zh.wikipedia.org/wiki/矩陣範數\">性质</a>，我们有，</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert\\mathbf{A} - \\hat{\\mathbf{A}}\\right\\rVert \\le \\sum_{i=k+1}^{r}\\sigma_i\\left\\lVert u_i\\right\\rVert\\left\\lVert v_i^\\dagger\\right\\rVert</script><p>由于$u_i$和$v_i$都是标准正交基，所以范数小于1.故，</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert\\mathbf{A} - \\hat{\\mathbf{A}}\\right\\rVert \\le \\sum_{i=k+1}^{r}\\sigma_i</script><p>取无穷范数，可以知道对于误差矩阵中的任意元素（也就是压缩重建之后任意位置的像素灰度值之差），都有：</p>\n<script type=\"math/tex; mode=display\">e \\le \\sum_{i=k+1}^{r}\\sigma_i</script><h3 id=\"SVD与矩阵范数\"><a href=\"#SVD与矩阵范数\" class=\"headerlink\" title=\"SVD与矩阵范数\"></a>SVD与矩阵范数</h3><p>如果某个函数$f$满足以下的性质，就可以作为矩阵的范数。</p>\n<ul>\n<li>$f(\\mathbf{A}) = \\mathbf{0} \\Leftrightarrow \\mathbf{A} = \\mathbf{0}$</li>\n<li>$f(c\\mathbf{A}) = c f(\\mathbf{A}), \\forall c \\in \\mathbb{R}$</li>\n<li>$f(\\mathbf{A+b}) \\le f(\\mathbf{A}) + f(\\mathbf{B})$</li>\n</ul>\n<p>其中，矩阵的2范数可以定义为</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert\\mathbf{A}\\right\\rVert_2 = \\max{\\sqrt{(\\mathbf{A}x)^\\dagger\\mathbf{A}x}}</script><p>其中，$x$是单位向量。上式的意义在于表明矩阵的2范数是对于所有向量，经过该矩阵线性变换后摸长最大的那个变换后向量的长度。</p>\n<p>下面，给出不严格的说明，证明矩阵的2范数数值上等于其最大的奇异值。</p>\n<p>对于空间内的任意单位向量$x$，利用矩阵的SVD分解，有（为了书写简单，矩阵不再单独加粗）：</p>\n<script type=\"math/tex; mode=display\">(Ax)^\\dagger Ax = x^\\dagger V \\Sigma^\\dagger \\Sigma V^\\dagger x</script><p>其中，$U^\\dagger U = I$，已经被消去了。</p>\n<p>进一步化简，我们将$V^\\dagger x$看做一个整体，令$\\omega = V\\dagger x$，那么有，</p>\n<script type=\"math/tex; mode=display\">(Ax)^\\dagger Ax = (\\Sigma \\omega)^\\dagger \\Sigma \\omega</script><p>也就是说，矩阵的2范转换为了$\\Sigma \\omega$的幅值的最大值。由于$\\omega$是酉矩阵和一个单位向量的乘积，所以$\\omega$仍然是单位阵。</p>\n<p>由于$\\Sigma$是对角阵，所以$\\omega$与其相乘后，相当于每个分量分别被放大了$\\sigma_i$倍。即</p>\n<script type=\"math/tex; mode=display\">\\Sigma \\omega =\n\\begin{bmatrix}\n\\sigma_1 \\omega_1\\\\\\\\\n\\sigma_2 \\omega_2\\\\\\\\\n\\cdots\\\\\\\\\n\\sigma_n \\omega_n\n\\end{bmatrix}</script><p>它的幅值平方为</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert \\Sigma \\omega \\right \\rVert ^2 = \\sum_{i=1}^{n}\\sigma_i^2 \\omega_i^2 \\le \\sigma_{1} \\sum_{i=1}^{n}\\omega_i^2 = \\sigma_1^2</script><p>当且仅当，$\\omega_1 = 1$, $\\omega_k = 0, k &gt; 1$时取得等号。</p>\n<p>综上所述，矩阵2范数的值等于其最大的奇异值。</p>\n<p>矩阵的另一种范数定义方法Frobenius norm定义如下：</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert A \\right\\rVert_{F} = \\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n}\\left\\vert a_{i,j}\\right\\rvert}</script><p>如果我们两边平方，可以得到，矩阵的F范数实际等于某个矩阵的迹，见下式：</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert A\\right \\rVert_F^2 = \\text{trace}(A^\\dagger A)</script><p>利用矩阵的SVD分解，可以很容易得出，$\\text{trace}(A^\\dagger A) = \\sum_{i=1}^{r}\\sigma_i^2$</p>\n<p>说明如下：</p>\n<script type=\"math/tex; mode=display\">\\text{trace}(A^\\dagger A) = \\text{trace}(V\\Sigma^\\dagger\\Sigma V^\\dagger)</script><p>由于$V^\\dagger = V^{-1}$，而且$\\text{trace}(BAB^{-1}) = \\text{trace}(A)$，所以，</p>\n<script type=\"math/tex; mode=display\">\\text{trace}(A^\\dagger A) = \\text{trace}(\\Sigma^\\dagger \\Sigma) = \\sum_{i=1}^{r}\\sigma_i^2</script><p>也就是说，矩阵的F范数等于它的奇异值平方和的平方根。</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert A\\right\\rVert_F= \\sqrt{\\sum_{i=1}^{r}\\sigma_i^2}</script>"},{"title":"CS131-描述图像的特征(Harris 角点)","date":"2017-01-25T02:51:47.000Z","_content":"\n\n## 局部不变特征\nfeature是对图像的描述。比如，图像整体灰度值的均值和方差就可以作为feature。如果我们想在一副图像中检测足球时，可以使用滑动窗方法，逐一检查窗口内的灰度值分布是否和一张给定的典型黑白格子足球相似。可想而知，这种方法的性能一定让人捉急。而在image matching问题中，常常需要将不同视角的同一目标物进行matching，进而计算相机转过的角度。这在SLAM问题中很有意义。如下图所示，同一处景观，在不同摄影师的镜头下，不仅视角不同，而且明暗变化也有很多差别，右侧的图暖色调更浓。这也告诉我们，上面提到的只使用全局图像灰度值来做feature的做法有多么不靠谱。\n![image matching example](/img/image_matching_hard.png)\n\n首先，让我们脱离全局特征，转而将注意力集中在局部特征上。这是因为使用局部特征能够更好地处理图像中的遮挡、变形等情况，而且我们的研究对象常常是图像中的部分区域而不是图像整体。更特殊地，在这一讲中，我们主要探究key point作为local feature的描述。\n\n## Harris角点\n角点，即corner，和edge类似，区别在于其在两个方向上都有较为剧烈的灰度变化（而edge只在某一个方向上灰度值变化剧烈）。如图所示。\n![what is corner](/img/what_is_corner.png)\n\n[Harris角点](http://www.bmva.org/bmvc/1988/avc-88-023.pdf)得名于其发明者Harris，是一种常见的角点检测方法。\n给定观察窗口大小，计算平移后窗口内各个像素差值的加权平方和，如下式。\n$$E(u,v) = \\sum_x\\sum_yw(x,y)[I(x+u, y+v) - I(x,y)]^2$$\n\n其中，窗口加权函数$w$可以取做门限函数或gaussian函数。如图所示。\n![window function](/img/corner_window_fun.png)\n\n使用泰勒级数展开，并忽略非线性项，我们有\n$$I(x+u,y+v) = I(x,y) + I_x(x,y)u+I_y(x,y)v$$\n\n所以上式可以写成（线性二次型写成了矩阵形式），\n$$E(u,v) = \\sum_{x,y}w(I_xu+I_yv)^2 = \\begin{bmatrix}u&v\\end{bmatrix}M\\begin{bmatrix}u\\\\\\\\v\\end{bmatrix}$$\n\n其中，\n$$M = w\\begin{bmatrix}I_x^2& I_xI_y\\\\\\\\I_xI_y&I_y^2\\end{bmatrix}$$\n\n当使用门限函数时，权值$w_{i,j} = 1$，则，\n$$M = \\begin{bmatrix}\\sum I_xI_x& \\sum I_xI_y\\\\\\\\\\sum I_xI_y&\\sum I_yI_y\\end{bmatrix} = \\sum \\begin{bmatrix}I_x \\\\\\\\I_y\\end{bmatrix}\\begin{bmatrix}I_x &I_y\\end{bmatrix}$$\n\n当corner与xy坐标轴对齐时候，如下图所示。由于在黑色观察窗口内，只有上侧和左侧存在边缘，且在上边缘，$I_y$很大，而$I_x=0$，在左侧边缘，$I_x$很大而$I_y = 0$，所以，矩阵\n$$M = \\begin{bmatrix}\\lambda_1 & 0 \\\\\\\\ 0&\\lambda_2 \\end{bmatrix}$$\n![M为对角阵](/img/corner_type_1.png)\n\n当corner与坐标轴没有对齐时，经过旋转变换就可以将其转换到与坐标轴对齐的角度，而这种旋转操作可以使用矩阵的相似化来表示（其实是二次型的化简，可以使用合同变换，而旋转变换的矩阵是酉矩阵，转置即为矩阵的逆，所以也是相似变换）。也就是说，矩阵$M$相似于某个对角阵。\n$$M = R^{-1}\\Sigma R, \\text{其中}\\Sigma = \\begin{bmatrix}\\lambda_1&0\\\\\\\\0&\\lambda_2\\end{bmatrix}$$\n\n所以，可以根据下面这张图利用矩阵$M$的特征值来判定角点和边缘点。当两个特征值都较大时为角点；当某个分量近似为0而另一个分量较大时，可以判定为边缘点（因为某个方向的导数为0）；当两个特征值都近似为0时，说明是普通点（flat point）。（课件原图如此，空缺的问号处应分别为$\\lambda_1$和$\\lambda_2$）。\n![使用M矩阵特征值判定](/img/corner_judge.png)\n\n 然而矩阵的特征值计算较为复杂，所以使用下面的方法进行近似计算。\n $$\\theta = \\det(M)-\\alpha\\text{trace}(M)^2 = \\lambda_1\\lambda_2-\\alpha(\\lambda_1+\\lambda_2)^2$$\n![使用theta判定](/img/corner_judge_2.png)\n\n为了减弱噪声的影响，常常使用gaussian窗函数。如下式所示：\n$$w(x,y) = \\exp(-(x^2+y^2)/2\\sigma^2)$$\n","source":"_posts/cs131-finding-features.md","raw":"---\ntitle: CS131-描述图像的特征(Harris 角点)\ndate: 2017-01-25 10:51:47\ntags:\n    - cs131\n    - 公开课\n---\n\n\n## 局部不变特征\nfeature是对图像的描述。比如，图像整体灰度值的均值和方差就可以作为feature。如果我们想在一副图像中检测足球时，可以使用滑动窗方法，逐一检查窗口内的灰度值分布是否和一张给定的典型黑白格子足球相似。可想而知，这种方法的性能一定让人捉急。而在image matching问题中，常常需要将不同视角的同一目标物进行matching，进而计算相机转过的角度。这在SLAM问题中很有意义。如下图所示，同一处景观，在不同摄影师的镜头下，不仅视角不同，而且明暗变化也有很多差别，右侧的图暖色调更浓。这也告诉我们，上面提到的只使用全局图像灰度值来做feature的做法有多么不靠谱。\n![image matching example](/img/image_matching_hard.png)\n\n首先，让我们脱离全局特征，转而将注意力集中在局部特征上。这是因为使用局部特征能够更好地处理图像中的遮挡、变形等情况，而且我们的研究对象常常是图像中的部分区域而不是图像整体。更特殊地，在这一讲中，我们主要探究key point作为local feature的描述。\n\n## Harris角点\n角点，即corner，和edge类似，区别在于其在两个方向上都有较为剧烈的灰度变化（而edge只在某一个方向上灰度值变化剧烈）。如图所示。\n![what is corner](/img/what_is_corner.png)\n\n[Harris角点](http://www.bmva.org/bmvc/1988/avc-88-023.pdf)得名于其发明者Harris，是一种常见的角点检测方法。\n给定观察窗口大小，计算平移后窗口内各个像素差值的加权平方和，如下式。\n$$E(u,v) = \\sum_x\\sum_yw(x,y)[I(x+u, y+v) - I(x,y)]^2$$\n\n其中，窗口加权函数$w$可以取做门限函数或gaussian函数。如图所示。\n![window function](/img/corner_window_fun.png)\n\n使用泰勒级数展开，并忽略非线性项，我们有\n$$I(x+u,y+v) = I(x,y) + I_x(x,y)u+I_y(x,y)v$$\n\n所以上式可以写成（线性二次型写成了矩阵形式），\n$$E(u,v) = \\sum_{x,y}w(I_xu+I_yv)^2 = \\begin{bmatrix}u&v\\end{bmatrix}M\\begin{bmatrix}u\\\\\\\\v\\end{bmatrix}$$\n\n其中，\n$$M = w\\begin{bmatrix}I_x^2& I_xI_y\\\\\\\\I_xI_y&I_y^2\\end{bmatrix}$$\n\n当使用门限函数时，权值$w_{i,j} = 1$，则，\n$$M = \\begin{bmatrix}\\sum I_xI_x& \\sum I_xI_y\\\\\\\\\\sum I_xI_y&\\sum I_yI_y\\end{bmatrix} = \\sum \\begin{bmatrix}I_x \\\\\\\\I_y\\end{bmatrix}\\begin{bmatrix}I_x &I_y\\end{bmatrix}$$\n\n当corner与xy坐标轴对齐时候，如下图所示。由于在黑色观察窗口内，只有上侧和左侧存在边缘，且在上边缘，$I_y$很大，而$I_x=0$，在左侧边缘，$I_x$很大而$I_y = 0$，所以，矩阵\n$$M = \\begin{bmatrix}\\lambda_1 & 0 \\\\\\\\ 0&\\lambda_2 \\end{bmatrix}$$\n![M为对角阵](/img/corner_type_1.png)\n\n当corner与坐标轴没有对齐时，经过旋转变换就可以将其转换到与坐标轴对齐的角度，而这种旋转操作可以使用矩阵的相似化来表示（其实是二次型的化简，可以使用合同变换，而旋转变换的矩阵是酉矩阵，转置即为矩阵的逆，所以也是相似变换）。也就是说，矩阵$M$相似于某个对角阵。\n$$M = R^{-1}\\Sigma R, \\text{其中}\\Sigma = \\begin{bmatrix}\\lambda_1&0\\\\\\\\0&\\lambda_2\\end{bmatrix}$$\n\n所以，可以根据下面这张图利用矩阵$M$的特征值来判定角点和边缘点。当两个特征值都较大时为角点；当某个分量近似为0而另一个分量较大时，可以判定为边缘点（因为某个方向的导数为0）；当两个特征值都近似为0时，说明是普通点（flat point）。（课件原图如此，空缺的问号处应分别为$\\lambda_1$和$\\lambda_2$）。\n![使用M矩阵特征值判定](/img/corner_judge.png)\n\n 然而矩阵的特征值计算较为复杂，所以使用下面的方法进行近似计算。\n $$\\theta = \\det(M)-\\alpha\\text{trace}(M)^2 = \\lambda_1\\lambda_2-\\alpha(\\lambda_1+\\lambda_2)^2$$\n![使用theta判定](/img/corner_judge_2.png)\n\n为了减弱噪声的影响，常常使用gaussian窗函数。如下式所示：\n$$w(x,y) = \\exp(-(x^2+y^2)/2\\sigma^2)$$\n","slug":"cs131-finding-features","published":1,"updated":"2017-02-01T15:10:29.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciyof8h0n0004cq1hdzl9brfg","content":"<h2 id=\"局部不变特征\"><a href=\"#局部不变特征\" class=\"headerlink\" title=\"局部不变特征\"></a>局部不变特征</h2><p>feature是对图像的描述。比如，图像整体灰度值的均值和方差就可以作为feature。如果我们想在一副图像中检测足球时，可以使用滑动窗方法，逐一检查窗口内的灰度值分布是否和一张给定的典型黑白格子足球相似。可想而知，这种方法的性能一定让人捉急。而在image matching问题中，常常需要将不同视角的同一目标物进行matching，进而计算相机转过的角度。这在SLAM问题中很有意义。如下图所示，同一处景观，在不同摄影师的镜头下，不仅视角不同，而且明暗变化也有很多差别，右侧的图暖色调更浓。这也告诉我们，上面提到的只使用全局图像灰度值来做feature的做法有多么不靠谱。<br><img src=\"/img/image_matching_hard.png\" alt=\"image matching example\"></p>\n<p>首先，让我们脱离全局特征，转而将注意力集中在局部特征上。这是因为使用局部特征能够更好地处理图像中的遮挡、变形等情况，而且我们的研究对象常常是图像中的部分区域而不是图像整体。更特殊地，在这一讲中，我们主要探究key point作为local feature的描述。</p>\n<h2 id=\"Harris角点\"><a href=\"#Harris角点\" class=\"headerlink\" title=\"Harris角点\"></a>Harris角点</h2><p>角点，即corner，和edge类似，区别在于其在两个方向上都有较为剧烈的灰度变化（而edge只在某一个方向上灰度值变化剧烈）。如图所示。<br><img src=\"/img/what_is_corner.png\" alt=\"what is corner\"></p>\n<p><a href=\"http://www.bmva.org/bmvc/1988/avc-88-023.pdf\" target=\"_blank\" rel=\"external\">Harris角点</a>得名于其发明者Harris，是一种常见的角点检测方法。<br>给定观察窗口大小，计算平移后窗口内各个像素差值的加权平方和，如下式。</p>\n<script type=\"math/tex; mode=display\">E(u,v) = \\sum_x\\sum_yw(x,y)[I(x+u, y+v) - I(x,y)]^2</script><p>其中，窗口加权函数$w$可以取做门限函数或gaussian函数。如图所示。<br><img src=\"/img/corner_window_fun.png\" alt=\"window function\"></p>\n<p>使用泰勒级数展开，并忽略非线性项，我们有</p>\n<script type=\"math/tex; mode=display\">I(x+u,y+v) = I(x,y) + I_x(x,y)u+I_y(x,y)v</script><p>所以上式可以写成（线性二次型写成了矩阵形式），</p>\n<script type=\"math/tex; mode=display\">E(u,v) = \\sum_{x,y}w(I_xu+I_yv)^2 = \\begin{bmatrix}u&v\\end{bmatrix}M\\begin{bmatrix}u\\\\\\\\v\\end{bmatrix}</script><p>其中，</p>\n<script type=\"math/tex; mode=display\">M = w\\begin{bmatrix}I_x^2& I_xI_y\\\\\\\\I_xI_y&I_y^2\\end{bmatrix}</script><p>当使用门限函数时，权值$w_{i,j} = 1$，则，</p>\n<script type=\"math/tex; mode=display\">M = \\begin{bmatrix}\\sum I_xI_x& \\sum I_xI_y\\\\\\\\\\sum I_xI_y&\\sum I_yI_y\\end{bmatrix} = \\sum \\begin{bmatrix}I_x \\\\\\\\I_y\\end{bmatrix}\\begin{bmatrix}I_x &I_y\\end{bmatrix}</script><p>当corner与xy坐标轴对齐时候，如下图所示。由于在黑色观察窗口内，只有上侧和左侧存在边缘，且在上边缘，$I_y$很大，而$I_x=0$，在左侧边缘，$I_x$很大而$I_y = 0$，所以，矩阵</p>\n<script type=\"math/tex; mode=display\">M = \\begin{bmatrix}\\lambda_1 & 0 \\\\\\\\ 0&\\lambda_2 \\end{bmatrix}</script><p><img src=\"/img/corner_type_1.png\" alt=\"M为对角阵\"></p>\n<p>当corner与坐标轴没有对齐时，经过旋转变换就可以将其转换到与坐标轴对齐的角度，而这种旋转操作可以使用矩阵的相似化来表示（其实是二次型的化简，可以使用合同变换，而旋转变换的矩阵是酉矩阵，转置即为矩阵的逆，所以也是相似变换）。也就是说，矩阵$M$相似于某个对角阵。</p>\n<script type=\"math/tex; mode=display\">M = R^{-1}\\Sigma R, \\text{其中}\\Sigma = \\begin{bmatrix}\\lambda_1&0\\\\\\\\0&\\lambda_2\\end{bmatrix}</script><p>所以，可以根据下面这张图利用矩阵$M$的特征值来判定角点和边缘点。当两个特征值都较大时为角点；当某个分量近似为0而另一个分量较大时，可以判定为边缘点（因为某个方向的导数为0）；当两个特征值都近似为0时，说明是普通点（flat point）。（课件原图如此，空缺的问号处应分别为$\\lambda_1$和$\\lambda_2$）。<br><img src=\"/img/corner_judge.png\" alt=\"使用M矩阵特征值判定\"></p>\n<p> 然而矩阵的特征值计算较为复杂，所以使用下面的方法进行近似计算。</p>\n<script type=\"math/tex; mode=display\">\\theta = \\det(M)-\\alpha\\text{trace}(M)^2 = \\lambda_1\\lambda_2-\\alpha(\\lambda_1+\\lambda_2)^2</script><p><img src=\"/img/corner_judge_2.png\" alt=\"使用theta判定\"></p>\n<p>为了减弱噪声的影响，常常使用gaussian窗函数。如下式所示：</p>\n<script type=\"math/tex; mode=display\">w(x,y) = \\exp(-(x^2+y^2)/2\\sigma^2)</script>","excerpt":"","more":"<h2 id=\"局部不变特征\"><a href=\"#局部不变特征\" class=\"headerlink\" title=\"局部不变特征\"></a>局部不变特征</h2><p>feature是对图像的描述。比如，图像整体灰度值的均值和方差就可以作为feature。如果我们想在一副图像中检测足球时，可以使用滑动窗方法，逐一检查窗口内的灰度值分布是否和一张给定的典型黑白格子足球相似。可想而知，这种方法的性能一定让人捉急。而在image matching问题中，常常需要将不同视角的同一目标物进行matching，进而计算相机转过的角度。这在SLAM问题中很有意义。如下图所示，同一处景观，在不同摄影师的镜头下，不仅视角不同，而且明暗变化也有很多差别，右侧的图暖色调更浓。这也告诉我们，上面提到的只使用全局图像灰度值来做feature的做法有多么不靠谱。<br><img src=\"/img/image_matching_hard.png\" alt=\"image matching example\"></p>\n<p>首先，让我们脱离全局特征，转而将注意力集中在局部特征上。这是因为使用局部特征能够更好地处理图像中的遮挡、变形等情况，而且我们的研究对象常常是图像中的部分区域而不是图像整体。更特殊地，在这一讲中，我们主要探究key point作为local feature的描述。</p>\n<h2 id=\"Harris角点\"><a href=\"#Harris角点\" class=\"headerlink\" title=\"Harris角点\"></a>Harris角点</h2><p>角点，即corner，和edge类似，区别在于其在两个方向上都有较为剧烈的灰度变化（而edge只在某一个方向上灰度值变化剧烈）。如图所示。<br><img src=\"/img/what_is_corner.png\" alt=\"what is corner\"></p>\n<p><a href=\"http://www.bmva.org/bmvc/1988/avc-88-023.pdf\">Harris角点</a>得名于其发明者Harris，是一种常见的角点检测方法。<br>给定观察窗口大小，计算平移后窗口内各个像素差值的加权平方和，如下式。</p>\n<script type=\"math/tex; mode=display\">E(u,v) = \\sum_x\\sum_yw(x,y)[I(x+u, y+v) - I(x,y)]^2</script><p>其中，窗口加权函数$w$可以取做门限函数或gaussian函数。如图所示。<br><img src=\"/img/corner_window_fun.png\" alt=\"window function\"></p>\n<p>使用泰勒级数展开，并忽略非线性项，我们有</p>\n<script type=\"math/tex; mode=display\">I(x+u,y+v) = I(x,y) + I_x(x,y)u+I_y(x,y)v</script><p>所以上式可以写成（线性二次型写成了矩阵形式），</p>\n<script type=\"math/tex; mode=display\">E(u,v) = \\sum_{x,y}w(I_xu+I_yv)^2 = \\begin{bmatrix}u&v\\end{bmatrix}M\\begin{bmatrix}u\\\\\\\\v\\end{bmatrix}</script><p>其中，</p>\n<script type=\"math/tex; mode=display\">M = w\\begin{bmatrix}I_x^2& I_xI_y\\\\\\\\I_xI_y&I_y^2\\end{bmatrix}</script><p>当使用门限函数时，权值$w_{i,j} = 1$，则，</p>\n<script type=\"math/tex; mode=display\">M = \\begin{bmatrix}\\sum I_xI_x& \\sum I_xI_y\\\\\\\\\\sum I_xI_y&\\sum I_yI_y\\end{bmatrix} = \\sum \\begin{bmatrix}I_x \\\\\\\\I_y\\end{bmatrix}\\begin{bmatrix}I_x &I_y\\end{bmatrix}</script><p>当corner与xy坐标轴对齐时候，如下图所示。由于在黑色观察窗口内，只有上侧和左侧存在边缘，且在上边缘，$I_y$很大，而$I_x=0$，在左侧边缘，$I_x$很大而$I_y = 0$，所以，矩阵</p>\n<script type=\"math/tex; mode=display\">M = \\begin{bmatrix}\\lambda_1 & 0 \\\\\\\\ 0&\\lambda_2 \\end{bmatrix}</script><p><img src=\"/img/corner_type_1.png\" alt=\"M为对角阵\"></p>\n<p>当corner与坐标轴没有对齐时，经过旋转变换就可以将其转换到与坐标轴对齐的角度，而这种旋转操作可以使用矩阵的相似化来表示（其实是二次型的化简，可以使用合同变换，而旋转变换的矩阵是酉矩阵，转置即为矩阵的逆，所以也是相似变换）。也就是说，矩阵$M$相似于某个对角阵。</p>\n<script type=\"math/tex; mode=display\">M = R^{-1}\\Sigma R, \\text{其中}\\Sigma = \\begin{bmatrix}\\lambda_1&0\\\\\\\\0&\\lambda_2\\end{bmatrix}</script><p>所以，可以根据下面这张图利用矩阵$M$的特征值来判定角点和边缘点。当两个特征值都较大时为角点；当某个分量近似为0而另一个分量较大时，可以判定为边缘点（因为某个方向的导数为0）；当两个特征值都近似为0时，说明是普通点（flat point）。（课件原图如此，空缺的问号处应分别为$\\lambda_1$和$\\lambda_2$）。<br><img src=\"/img/corner_judge.png\" alt=\"使用M矩阵特征值判定\"></p>\n<p> 然而矩阵的特征值计算较为复杂，所以使用下面的方法进行近似计算。</p>\n<script type=\"math/tex; mode=display\">\\theta = \\det(M)-\\alpha\\text{trace}(M)^2 = \\lambda_1\\lambda_2-\\alpha(\\lambda_1+\\lambda_2)^2</script><p><img src=\"/img/corner_judge_2.png\" alt=\"使用theta判定\"></p>\n<p>为了减弱噪声的影响，常常使用gaussian窗函数。如下式所示：</p>\n<script type=\"math/tex; mode=display\">w(x,y) = \\exp(-(x^2+y^2)/2\\sigma^2)</script>"},{"title":"CS131-线代基础","date":"2017-01-22T07:38:01.000Z","_content":"\n## 课程简介\nCS131课程(Computer Vision: Foundations and Applications)，是斯坦福大学Li Feifei实验室开设的一门计算机视觉入门基础课程，[该课程](http://vision.stanford.edu/teaching/cs131_fall1617/index.html)目的在于为刚接触计算机视觉领域的学生提供基本原理和应用介绍。目前2016年冬季课程刚刚结束。CS131博客系列主要是关于本课的slide知识点总结与作业重点问题归纳，作为个人学习本门课程的心得体会和复习材料。\n\n由于是个人项目，所以会比较随意，只对个人感兴趣的内容做一总结。这篇文章是对课前的[线代基础](http://vision.stanford.edu/teaching/cs131_fall1617/lectures/lecture2_linalg_review_cs131_2016.pdf)做一复习与整理。\n\n## 向量与矩阵\n数字图像可以看做二维矩阵，向量是特殊的矩阵，本课程默认的向量都是列向量。\nslide中给出了一些矩阵行列式和迹的性质，都比较简单，这里不再多说。\n## 矩阵作为线性变换\n通过线代知识，我们知道，在线性空间中，如果给定一组基，线性变换可以通过对应的矩阵来进行描述。\n\n### scale变换\n对角阵可以用来表示放缩变换。\n$$\n\\begin{bmatrix}\ns_x & 0\\\\\\\\\n0 & s_y\n\\end{bmatrix}\\begin{bmatrix}\nx\\\\\\\\\ny\n\\end{bmatrix} = \\begin{bmatrix}\ns_xx\\\\\\\\\ns_yy\n\\end{bmatrix}\n$$\n\n### 旋转变换\n如图所示，逆时针旋转$theta$角度，对应的旋转矩阵为：\n![旋转变换](/img/rotation.png)\n$$\n\\mathbf{R} = \\begin{bmatrix}\n\\cos\\theta &-\\sin\\theta \\\\\\\\\n\\sin\\theta &\\cos\\theta\n\\end{bmatrix}\n$$\n旋转矩阵是[酉矩阵](https://zh.wikipedia.org/wiki/酉矩阵)，矩阵内的各列（或者各行）相互正交。满足如下的关系式：\n$$\n\\mathbf{R}\\mathbf{R^{\\dagger}} = \\mathbf{I}\n$$\n由于$\\det{\\mathbf{R}} = \\det{\\mathbf{R^{\\dagger}}}$，所以，对于酉矩阵，$\\det{\\mathbf{R}} = \\pm 1$\n旋转矩阵是[酉矩阵](https://zh.wikipedia.org/wiki/酉矩阵)，矩阵内的各列（或者各行）相互正交。满足如下的关系式：\n$$\n\\mathbf{R}\\mathbf{R^{\\dagger}} = \\mathbf{I}\n$$\n由于$\\det{\\mathbf{R}} = \\det{\\mathbf{R^{\\dagger}}}$，所以，对于酉矩阵，$\\det{\\mathbf{R}} = \\pm 1$.\n\n### 齐次变换(Homogeneous Transform)\n只用上面的二维矩阵不能表达平移，使用齐次矩阵可以表达放缩，旋转和平移操作。\n$$\n\\mathbf{H} =\\begin{bmatrix}\na & b & t_x\\\\\\\\\nc & d & t_y\\\\\\\\\n0 & 0 & 1\n\\end{bmatrix},\\mathbf{H}\\begin{bmatrix}\nx\\\\\\\\\ny\\\\\\\\\n1\\\\\\\\\n\\end{bmatrix}=\\begin{bmatrix}\nax+by+t_x\\\\\\\\\ncx+dy+t_y\\\\\\\\\n1\n\\end{bmatrix}\n$$\n\n### SVD分解\n可以将矩阵分成若干个矩阵的乘积，叫做矩阵分解，比如QR分解，满秩分解等。SVD分解，即奇异值分解，也是一种特殊的矩阵分解方法。如下式所示，是将矩阵分解成为三个矩阵的乘积：\n$$\\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V^\\dagger} = \\mathbf{A}$$\n其中矩阵$\\mathbf{A}$大小为$m\\times n$，矩阵$\\mathbf{U}$是大小为$m\\times m$的酉矩阵，$\\mathbf{V}$是大小为$n \\times n$的酉矩阵，$\\mathbf{\\Sigma}$是大小为$m \\times n$的旋转矩阵，即只有主对角元素不为0.\n\nSVD分解在主成分分析中年很有用。由于矩阵$\\mathbf{\\Sigma}$一般情况下是将奇异值按照从大到小的顺序摆放，所以矩阵$\\mathbf{U}$中，前面的若干列被视作主成分，后面的列显得相对不这么重要。可以抛弃后面的列，进行图像压缩。\n\n如下图，是使用前10个分量对原图片进行压缩的效果。\n\n``` matlab\nim = imread('./superman.png');\nim_gray = rbg2gray(im);\n[u, s, v] = svd(double(im_gray));\nk = 10;\nuk = u(:, 1:k);\nsigma = diag(s);\nsk = diag(sigma(1:k));\nvk = v(:, 1:k);\nim_k = uk*sk*vk';\nimshow(uint8(im_k))\n```\n\n![原始图像](/img/original_superman.png)\n![压缩图像](/img/svd_superman.png)\n","source":"_posts/cs131-linear-alg.md","raw":"---\ntitle: CS131-线代基础\ndate: 2017-01-22 15:38:01\ntags:\n    - cs131\n    - 公开课\n---\n\n## 课程简介\nCS131课程(Computer Vision: Foundations and Applications)，是斯坦福大学Li Feifei实验室开设的一门计算机视觉入门基础课程，[该课程](http://vision.stanford.edu/teaching/cs131_fall1617/index.html)目的在于为刚接触计算机视觉领域的学生提供基本原理和应用介绍。目前2016年冬季课程刚刚结束。CS131博客系列主要是关于本课的slide知识点总结与作业重点问题归纳，作为个人学习本门课程的心得体会和复习材料。\n\n由于是个人项目，所以会比较随意，只对个人感兴趣的内容做一总结。这篇文章是对课前的[线代基础](http://vision.stanford.edu/teaching/cs131_fall1617/lectures/lecture2_linalg_review_cs131_2016.pdf)做一复习与整理。\n\n## 向量与矩阵\n数字图像可以看做二维矩阵，向量是特殊的矩阵，本课程默认的向量都是列向量。\nslide中给出了一些矩阵行列式和迹的性质，都比较简单，这里不再多说。\n## 矩阵作为线性变换\n通过线代知识，我们知道，在线性空间中，如果给定一组基，线性变换可以通过对应的矩阵来进行描述。\n\n### scale变换\n对角阵可以用来表示放缩变换。\n$$\n\\begin{bmatrix}\ns_x & 0\\\\\\\\\n0 & s_y\n\\end{bmatrix}\\begin{bmatrix}\nx\\\\\\\\\ny\n\\end{bmatrix} = \\begin{bmatrix}\ns_xx\\\\\\\\\ns_yy\n\\end{bmatrix}\n$$\n\n### 旋转变换\n如图所示，逆时针旋转$theta$角度，对应的旋转矩阵为：\n![旋转变换](/img/rotation.png)\n$$\n\\mathbf{R} = \\begin{bmatrix}\n\\cos\\theta &-\\sin\\theta \\\\\\\\\n\\sin\\theta &\\cos\\theta\n\\end{bmatrix}\n$$\n旋转矩阵是[酉矩阵](https://zh.wikipedia.org/wiki/酉矩阵)，矩阵内的各列（或者各行）相互正交。满足如下的关系式：\n$$\n\\mathbf{R}\\mathbf{R^{\\dagger}} = \\mathbf{I}\n$$\n由于$\\det{\\mathbf{R}} = \\det{\\mathbf{R^{\\dagger}}}$，所以，对于酉矩阵，$\\det{\\mathbf{R}} = \\pm 1$\n旋转矩阵是[酉矩阵](https://zh.wikipedia.org/wiki/酉矩阵)，矩阵内的各列（或者各行）相互正交。满足如下的关系式：\n$$\n\\mathbf{R}\\mathbf{R^{\\dagger}} = \\mathbf{I}\n$$\n由于$\\det{\\mathbf{R}} = \\det{\\mathbf{R^{\\dagger}}}$，所以，对于酉矩阵，$\\det{\\mathbf{R}} = \\pm 1$.\n\n### 齐次变换(Homogeneous Transform)\n只用上面的二维矩阵不能表达平移，使用齐次矩阵可以表达放缩，旋转和平移操作。\n$$\n\\mathbf{H} =\\begin{bmatrix}\na & b & t_x\\\\\\\\\nc & d & t_y\\\\\\\\\n0 & 0 & 1\n\\end{bmatrix},\\mathbf{H}\\begin{bmatrix}\nx\\\\\\\\\ny\\\\\\\\\n1\\\\\\\\\n\\end{bmatrix}=\\begin{bmatrix}\nax+by+t_x\\\\\\\\\ncx+dy+t_y\\\\\\\\\n1\n\\end{bmatrix}\n$$\n\n### SVD分解\n可以将矩阵分成若干个矩阵的乘积，叫做矩阵分解，比如QR分解，满秩分解等。SVD分解，即奇异值分解，也是一种特殊的矩阵分解方法。如下式所示，是将矩阵分解成为三个矩阵的乘积：\n$$\\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V^\\dagger} = \\mathbf{A}$$\n其中矩阵$\\mathbf{A}$大小为$m\\times n$，矩阵$\\mathbf{U}$是大小为$m\\times m$的酉矩阵，$\\mathbf{V}$是大小为$n \\times n$的酉矩阵，$\\mathbf{\\Sigma}$是大小为$m \\times n$的旋转矩阵，即只有主对角元素不为0.\n\nSVD分解在主成分分析中年很有用。由于矩阵$\\mathbf{\\Sigma}$一般情况下是将奇异值按照从大到小的顺序摆放，所以矩阵$\\mathbf{U}$中，前面的若干列被视作主成分，后面的列显得相对不这么重要。可以抛弃后面的列，进行图像压缩。\n\n如下图，是使用前10个分量对原图片进行压缩的效果。\n\n``` matlab\nim = imread('./superman.png');\nim_gray = rbg2gray(im);\n[u, s, v] = svd(double(im_gray));\nk = 10;\nuk = u(:, 1:k);\nsigma = diag(s);\nsk = diag(sigma(1:k));\nvk = v(:, 1:k);\nim_k = uk*sk*vk';\nimshow(uint8(im_k))\n```\n\n![原始图像](/img/original_superman.png)\n![压缩图像](/img/svd_superman.png)\n","slug":"cs131-linear-alg","published":1,"updated":"2017-02-01T15:10:29.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciyof8h0u0005cq1h65s3tl67","content":"<h2 id=\"课程简介\"><a href=\"#课程简介\" class=\"headerlink\" title=\"课程简介\"></a>课程简介</h2><p>CS131课程(Computer Vision: Foundations and Applications)，是斯坦福大学Li Feifei实验室开设的一门计算机视觉入门基础课程，<a href=\"http://vision.stanford.edu/teaching/cs131_fall1617/index.html\" target=\"_blank\" rel=\"external\">该课程</a>目的在于为刚接触计算机视觉领域的学生提供基本原理和应用介绍。目前2016年冬季课程刚刚结束。CS131博客系列主要是关于本课的slide知识点总结与作业重点问题归纳，作为个人学习本门课程的心得体会和复习材料。</p>\n<p>由于是个人项目，所以会比较随意，只对个人感兴趣的内容做一总结。这篇文章是对课前的<a href=\"http://vision.stanford.edu/teaching/cs131_fall1617/lectures/lecture2_linalg_review_cs131_2016.pdf\" target=\"_blank\" rel=\"external\">线代基础</a>做一复习与整理。</p>\n<h2 id=\"向量与矩阵\"><a href=\"#向量与矩阵\" class=\"headerlink\" title=\"向量与矩阵\"></a>向量与矩阵</h2><p>数字图像可以看做二维矩阵，向量是特殊的矩阵，本课程默认的向量都是列向量。<br>slide中给出了一些矩阵行列式和迹的性质，都比较简单，这里不再多说。</p>\n<h2 id=\"矩阵作为线性变换\"><a href=\"#矩阵作为线性变换\" class=\"headerlink\" title=\"矩阵作为线性变换\"></a>矩阵作为线性变换</h2><p>通过线代知识，我们知道，在线性空间中，如果给定一组基，线性变换可以通过对应的矩阵来进行描述。</p>\n<h3 id=\"scale变换\"><a href=\"#scale变换\" class=\"headerlink\" title=\"scale变换\"></a>scale变换</h3><p>对角阵可以用来表示放缩变换。</p>\n<script type=\"math/tex; mode=display\">\n\\begin{bmatrix}\ns_x & 0\\\\\\\\\n0 & s_y\n\\end{bmatrix}\\begin{bmatrix}\nx\\\\\\\\\ny\n\\end{bmatrix} = \\begin{bmatrix}\ns_xx\\\\\\\\\ns_yy\n\\end{bmatrix}</script><h3 id=\"旋转变换\"><a href=\"#旋转变换\" class=\"headerlink\" title=\"旋转变换\"></a>旋转变换</h3><p>如图所示，逆时针旋转$theta$角度，对应的旋转矩阵为：<br><img src=\"/img/rotation.png\" alt=\"旋转变换\"></p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{R} = \\begin{bmatrix}\n\\cos\\theta &-\\sin\\theta \\\\\\\\\n\\sin\\theta &\\cos\\theta\n\\end{bmatrix}</script><p>旋转矩阵是<a href=\"https://zh.wikipedia.org/wiki/酉矩阵\" target=\"_blank\" rel=\"external\">酉矩阵</a>，矩阵内的各列（或者各行）相互正交。满足如下的关系式：</p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{R}\\mathbf{R^{\\dagger}} = \\mathbf{I}</script><p>由于$\\det{\\mathbf{R}} = \\det{\\mathbf{R^{\\dagger}}}$，所以，对于酉矩阵，$\\det{\\mathbf{R}} = \\pm 1$<br>旋转矩阵是<a href=\"https://zh.wikipedia.org/wiki/酉矩阵\" target=\"_blank\" rel=\"external\">酉矩阵</a>，矩阵内的各列（或者各行）相互正交。满足如下的关系式：</p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{R}\\mathbf{R^{\\dagger}} = \\mathbf{I}</script><p>由于$\\det{\\mathbf{R}} = \\det{\\mathbf{R^{\\dagger}}}$，所以，对于酉矩阵，$\\det{\\mathbf{R}} = \\pm 1$.</p>\n<h3 id=\"齐次变换-Homogeneous-Transform\"><a href=\"#齐次变换-Homogeneous-Transform\" class=\"headerlink\" title=\"齐次变换(Homogeneous Transform)\"></a>齐次变换(Homogeneous Transform)</h3><p>只用上面的二维矩阵不能表达平移，使用齐次矩阵可以表达放缩，旋转和平移操作。</p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{H} =\\begin{bmatrix}\na & b & t_x\\\\\\\\\nc & d & t_y\\\\\\\\\n0 & 0 & 1\n\\end{bmatrix},\\mathbf{H}\\begin{bmatrix}\nx\\\\\\\\\ny\\\\\\\\\n1\\\\\\\\\n\\end{bmatrix}=\\begin{bmatrix}\nax+by+t_x\\\\\\\\\ncx+dy+t_y\\\\\\\\\n1\n\\end{bmatrix}</script><h3 id=\"SVD分解\"><a href=\"#SVD分解\" class=\"headerlink\" title=\"SVD分解\"></a>SVD分解</h3><p>可以将矩阵分成若干个矩阵的乘积，叫做矩阵分解，比如QR分解，满秩分解等。SVD分解，即奇异值分解，也是一种特殊的矩阵分解方法。如下式所示，是将矩阵分解成为三个矩阵的乘积：</p>\n<script type=\"math/tex; mode=display\">\\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V^\\dagger} = \\mathbf{A}</script><p>其中矩阵$\\mathbf{A}$大小为$m\\times n$，矩阵$\\mathbf{U}$是大小为$m\\times m$的酉矩阵，$\\mathbf{V}$是大小为$n \\times n$的酉矩阵，$\\mathbf{\\Sigma}$是大小为$m \\times n$的旋转矩阵，即只有主对角元素不为0.</p>\n<p>SVD分解在主成分分析中年很有用。由于矩阵$\\mathbf{\\Sigma}$一般情况下是将奇异值按照从大到小的顺序摆放，所以矩阵$\\mathbf{U}$中，前面的若干列被视作主成分，后面的列显得相对不这么重要。可以抛弃后面的列，进行图像压缩。</p>\n<p>如下图，是使用前10个分量对原图片进行压缩的效果。</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">im = imread(<span class=\"string\">'./superman.png'</span>);</div><div class=\"line\">im_gray = rbg2gray(im);</div><div class=\"line\">[u, s, v] = svd(double(im_gray));</div><div class=\"line\">k = <span class=\"number\">10</span>;</div><div class=\"line\">uk = u(:, <span class=\"number\">1</span>:k);</div><div class=\"line\">sigma = <span class=\"built_in\">diag</span>(s);</div><div class=\"line\">sk = <span class=\"built_in\">diag</span>(sigma(<span class=\"number\">1</span>:k));</div><div class=\"line\">vk = v(:, <span class=\"number\">1</span>:k);</div><div class=\"line\">im_k = uk*sk*vk';</div><div class=\"line\">imshow(uint8(im_k))</div></pre></td></tr></table></figure>\n<p><img src=\"/img/original_superman.png\" alt=\"原始图像\"><br><img src=\"/img/svd_superman.png\" alt=\"压缩图像\"></p>\n","excerpt":"","more":"<h2 id=\"课程简介\"><a href=\"#课程简介\" class=\"headerlink\" title=\"课程简介\"></a>课程简介</h2><p>CS131课程(Computer Vision: Foundations and Applications)，是斯坦福大学Li Feifei实验室开设的一门计算机视觉入门基础课程，<a href=\"http://vision.stanford.edu/teaching/cs131_fall1617/index.html\">该课程</a>目的在于为刚接触计算机视觉领域的学生提供基本原理和应用介绍。目前2016年冬季课程刚刚结束。CS131博客系列主要是关于本课的slide知识点总结与作业重点问题归纳，作为个人学习本门课程的心得体会和复习材料。</p>\n<p>由于是个人项目，所以会比较随意，只对个人感兴趣的内容做一总结。这篇文章是对课前的<a href=\"http://vision.stanford.edu/teaching/cs131_fall1617/lectures/lecture2_linalg_review_cs131_2016.pdf\">线代基础</a>做一复习与整理。</p>\n<h2 id=\"向量与矩阵\"><a href=\"#向量与矩阵\" class=\"headerlink\" title=\"向量与矩阵\"></a>向量与矩阵</h2><p>数字图像可以看做二维矩阵，向量是特殊的矩阵，本课程默认的向量都是列向量。<br>slide中给出了一些矩阵行列式和迹的性质，都比较简单，这里不再多说。</p>\n<h2 id=\"矩阵作为线性变换\"><a href=\"#矩阵作为线性变换\" class=\"headerlink\" title=\"矩阵作为线性变换\"></a>矩阵作为线性变换</h2><p>通过线代知识，我们知道，在线性空间中，如果给定一组基，线性变换可以通过对应的矩阵来进行描述。</p>\n<h3 id=\"scale变换\"><a href=\"#scale变换\" class=\"headerlink\" title=\"scale变换\"></a>scale变换</h3><p>对角阵可以用来表示放缩变换。</p>\n<script type=\"math/tex; mode=display\">\n\\begin{bmatrix}\ns_x & 0\\\\\\\\\n0 & s_y\n\\end{bmatrix}\\begin{bmatrix}\nx\\\\\\\\\ny\n\\end{bmatrix} = \\begin{bmatrix}\ns_xx\\\\\\\\\ns_yy\n\\end{bmatrix}</script><h3 id=\"旋转变换\"><a href=\"#旋转变换\" class=\"headerlink\" title=\"旋转变换\"></a>旋转变换</h3><p>如图所示，逆时针旋转$theta$角度，对应的旋转矩阵为：<br><img src=\"/img/rotation.png\" alt=\"旋转变换\"></p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{R} = \\begin{bmatrix}\n\\cos\\theta &-\\sin\\theta \\\\\\\\\n\\sin\\theta &\\cos\\theta\n\\end{bmatrix}</script><p>旋转矩阵是<a href=\"https://zh.wikipedia.org/wiki/酉矩阵\">酉矩阵</a>，矩阵内的各列（或者各行）相互正交。满足如下的关系式：</p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{R}\\mathbf{R^{\\dagger}} = \\mathbf{I}</script><p>由于$\\det{\\mathbf{R}} = \\det{\\mathbf{R^{\\dagger}}}$，所以，对于酉矩阵，$\\det{\\mathbf{R}} = \\pm 1$<br>旋转矩阵是<a href=\"https://zh.wikipedia.org/wiki/酉矩阵\">酉矩阵</a>，矩阵内的各列（或者各行）相互正交。满足如下的关系式：</p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{R}\\mathbf{R^{\\dagger}} = \\mathbf{I}</script><p>由于$\\det{\\mathbf{R}} = \\det{\\mathbf{R^{\\dagger}}}$，所以，对于酉矩阵，$\\det{\\mathbf{R}} = \\pm 1$.</p>\n<h3 id=\"齐次变换-Homogeneous-Transform\"><a href=\"#齐次变换-Homogeneous-Transform\" class=\"headerlink\" title=\"齐次变换(Homogeneous Transform)\"></a>齐次变换(Homogeneous Transform)</h3><p>只用上面的二维矩阵不能表达平移，使用齐次矩阵可以表达放缩，旋转和平移操作。</p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{H} =\\begin{bmatrix}\na & b & t_x\\\\\\\\\nc & d & t_y\\\\\\\\\n0 & 0 & 1\n\\end{bmatrix},\\mathbf{H}\\begin{bmatrix}\nx\\\\\\\\\ny\\\\\\\\\n1\\\\\\\\\n\\end{bmatrix}=\\begin{bmatrix}\nax+by+t_x\\\\\\\\\ncx+dy+t_y\\\\\\\\\n1\n\\end{bmatrix}</script><h3 id=\"SVD分解\"><a href=\"#SVD分解\" class=\"headerlink\" title=\"SVD分解\"></a>SVD分解</h3><p>可以将矩阵分成若干个矩阵的乘积，叫做矩阵分解，比如QR分解，满秩分解等。SVD分解，即奇异值分解，也是一种特殊的矩阵分解方法。如下式所示，是将矩阵分解成为三个矩阵的乘积：</p>\n<script type=\"math/tex; mode=display\">\\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V^\\dagger} = \\mathbf{A}</script><p>其中矩阵$\\mathbf{A}$大小为$m\\times n$，矩阵$\\mathbf{U}$是大小为$m\\times m$的酉矩阵，$\\mathbf{V}$是大小为$n \\times n$的酉矩阵，$\\mathbf{\\Sigma}$是大小为$m \\times n$的旋转矩阵，即只有主对角元素不为0.</p>\n<p>SVD分解在主成分分析中年很有用。由于矩阵$\\mathbf{\\Sigma}$一般情况下是将奇异值按照从大到小的顺序摆放，所以矩阵$\\mathbf{U}$中，前面的若干列被视作主成分，后面的列显得相对不这么重要。可以抛弃后面的列，进行图像压缩。</p>\n<p>如下图，是使用前10个分量对原图片进行压缩的效果。</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">im = imread(<span class=\"string\">'./superman.png'</span>);</div><div class=\"line\">im_gray = rbg2gray(im);</div><div class=\"line\">[u, s, v] = svd(double(im_gray));</div><div class=\"line\">k = <span class=\"number\">10</span>;</div><div class=\"line\">uk = u(:, <span class=\"number\">1</span>:k);</div><div class=\"line\">sigma = <span class=\"built_in\">diag</span>(s);</div><div class=\"line\">sk = <span class=\"built_in\">diag</span>(sigma(<span class=\"number\">1</span>:k));</div><div class=\"line\">vk = v(:, <span class=\"number\">1</span>:k);</div><div class=\"line\">im_k = uk*sk*vk';</div><div class=\"line\">imshow(uint8(im_k))</div></pre></td></tr></table></figure>\n<p><img src=\"/img/original_superman.png\" alt=\"原始图像\"><br><img src=\"/img/svd_superman.png\" alt=\"压缩图像\"></p>\n"},{"title":"CS131-描述图像的特征(SIFT)","date":"2017-01-30T14:16:18.000Z","_content":"\n[SIFT(尺度不变特征变换，Scale Invariant Feature Transform)](https://en.wikipedia.org/wiki/Scale-invariant_feature_transform),最早由Lowe提出，目的是为了解决目标检测（Object Detection）问题中提取图像特征的问题。从名字可以看出，SIFT的优势就在于对尺度变换的不变性，同时SIFT还满足平移变换和旋转变换下的不变性，并对光照变化和3D视角变换有一定的不变性。它的主要步骤如下：\n- scale space上的极值检测。使用DoG在不同的scaleast和image position下找到interest point。\n- interest point的localization。对上面的interest point进行稳定度检测，并确定其所在的scale和position。\n- 确定方向。通过计算图像的梯度图，确定key point的方向，下一步的feature operation就是在这个方向，scale和position上进行的。\n- 确定key point的描述子。使用图像的局部梯度作为key point的描述子，最终构成SIFT特征向量。\n\n## SIFT介绍\n上讲中介绍的Harris角点方法计算简便，并具有平移不变性和旋转不变性。特征$f$对某种变换$\\mathcal{T}$具有不变性，是指在经过变换后原特征保持不变，也就是$f(I) = f(\\mathcal{T}(I))$。但是Harris角点不具有尺度变换不变性，如下图所示。当图像被放大后，原图的角点被判定为了边缘点。\n![harris的尺度变换不满足尺度不变性](/img/harris_non_scale_constant.png)\n\n而我们想要得到一种对尺度变换保持不变性的特征计算方法。例如图像patch的像素平均亮度，如下图所示。region size缩小为原始的一半后，亮度直方图的形状不变，即平均亮度不变。\n![平均亮度满足尺度变化呢不变性](/img/patch_average_intensity_scale_constant.png)\n\n而Lowe想到了使用局部极值来作为feature来保证对scale变换的不变性。在算法的具体实现中，他使用DoG来获得局部极值。\n\n[Lowe的论文](http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf)中也提到了SIFT特征的应用。SIFT特征可以产生稠密（dense）的key point，例如一张500x500像素大小的图像，一般可以产生~2000个稳定的SIFT特征。在进行image matching和recognition时，可以将ref image的SIFT特征提前计算出来保存在数据库中，并计算待处理图像的SIFT特征，根据特征向量的欧氏距离进行匹配。\n\n这篇博客主要是[Lowe上述论文](http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf)的读书笔记，按照SIFT特征的计算步骤进行组织。\n\n## 尺度空间极值的检测方法\n前人研究已经指出，在一系列合理假设下，高斯核是唯一满足尺度不变性的。所谓的尺度空间，就是指原始图像$I(x,y)$和可变尺度的高斯核$G(x,y,\\sigma)$的卷积结果。如下式所示：\n$$L(x,y,\\sigma) = G(x,y,\\sigma)\\ast I(x,y)$$\n\n其中，$G(x,y, \\sigma) = \\frac{1}{2\\pi\\sigma^2}\\exp(-(x^2+y^2)/2\\sigma^2)$。不同的$\\sigma$代表不同的尺度。\n\nDoG(difference of Gaussian)函数定义为不同尺度的高斯核与图像卷积结果之差，即，\n$$D(x,y,\\sigma) = L(x,y,k\\sigma) - L(x,y,\\sigma)$$\n\n如下图所示，输入的图像重复地与高斯核进行卷积得到结果图像$L$（左侧），这样构成了一个octave。相邻的$L$之间作差得到DoG图像（右侧）。当一个octave处理完之后，将当前octave的最后一张高斯卷积结果图像降采样两倍，按照前述方法构造下一个octave。在图中，我们将一个octave划分为$s$个间隔（即$s+1$个图像）时，设$\\sigma$最终变成了2倍（即$\\sigma$加倍）。那么，显然有相邻两层之间的$k = 2^{1/s}$。不过为了保证首尾两张图像也能够计算差值，我们实际上需要再补上两张（做一个padding），也就是说一个octave内的总图像为$s+3$（下图中的$s=2$）。\n![DoG的计算](/img/sift_dog.png)\n\n为何我们要费力气得到DoG呢？论文中作者给出的解释是：DoG对scale-normalized后的Guassian Laplace函数$\\sigma^2\\Delta G$提供了足够的近似。其中前面的$\\sigma^2$系数正是为了保证尺度不变性。而前人的研究则指出，$\\sigma \\Delta G$函数的极值，和其他一大票其他function比较时，能够提供最稳定的feature。\n\n对于高斯核函数，有以下性质：\n$$\\frac{\\partial G}{\\partial \\sigma} = \\sigma \\Delta G$$\n\n我们将式子左侧的微分变成差分，得到了下式：\n$$\\sigma\\Delta G \\approx \\frac{G(x,y,k\\sigma)-G(x,y,\\sigma)}{k\\sigma - \\sigma}$$\n\n也就是：\n$$G(x,y,k\\sigma)-G(x,y,\\sigma) \\approx (k-1)\\sigma^2 \\Delta G$$\n当$k=1$时，上式的近似误差为0（即上面的$s=\\infty$，也就是说octave的划分是连续的）。但是当$k$较大时，如$\\sqrt{2}$（这时$s=2$，octave划分十分粗糙了），仍然保证了稳定性。同时，由于相邻两层的比例$k$是定值，所以$k-1$这个因子对于检测极值没有影响。我们在计算时，无需除以$k-1$。\n\n构造完了DoG图像金字塔，下面我们的任务就是检测其中的极值。如下图，对于每个点，我们将它与金字塔中相邻的26个点作比较，找到局部极值。\n![检测极值](/img/sift_detection_maximum.png)\n\n另外，我们将输入图像行列预先使用线性插值的方法resize为原来的2倍，获取更多的key point。\n\n此外，在Lowe的论文中还提到了使用DoG的泰勒展开和海森矩阵进行key point的精细确定方法，并对key point进行过滤。这里也不再赘述了。\n\n## 128维feature的获取\n我们需要在每个key point处提取128维的特征向量。这里结合CS131课程作业2的相关练习作出说明。对于每个key point，我们关注它位于图像金字塔中的具体层数以及像素点位置，也就是说通过索引`pyramid{scale}(y, x)`就可以获取key point。我们遍历key point，为它们赋予一个128维的特征向量。\n\n我们选取point周围16x16大小的区域，称为一个patch。将其分为4x4共计16个cell。这样，每个cell内共有像素点16个。对于每个cell，我们计算它的局部梯度方向直方图，直方图共有8个bin。也就是说每个cell可以得到一个8维的特征向量。将16个cell的特征向量首尾相接，就得到了128维的SIFT特征向量。在下面的代码中，使用变量`patch_mag`和`patch_theta`分别代表patch的梯度幅值和角度，它们可以很简单地使用卷积和数学运算得到。\n\n``` matlab\npatch_mag = sqrt(patch_dx.^2 + patch_dy.^2);\npatch_theta = atan2(patch_dy, patch_dx);  % atan2的返回结果在区间[-pi, pi]上。\npatch_theta = mod(patch_theta, 2*pi);   % 这里我们要将其转换为[0, 2pi]\n```\n\n之后，我们需要获取key point的主方向。其定义可见slide，即为key point扩展出来的patch的梯度方向直方图的峰值对应的角度。\n![何为主方向](/img/sift_dominant_orientation.png)\n\n所以我们首先应该设计如何构建局部梯度方向直方图。我们只要将`[0, 2pi]`区间划分为若干个`bin`，并将patch内的每个点使用其梯度大小向对应的`bin`内投票即可。如下所示：\n\n``` matlab\nfunction [histogram, angles] = ComputeGradientHistogram(num_bins, gradient_magnitudes, gradient_angles)\n% Compute a gradient histogram using gradient magnitudes and directions.\n% Each point is assigned to one of num_bins depending on its gradient\n% direction; the gradient magnitude of that point is added to its bin.\n%\n% INPUT\n% num_bins: The number of bins to which points should be assigned.\n% gradient_magnitudes, gradient angles:\n%       Two arrays of the same shape where gradient_magnitudes(i) and\n%       gradient_angles(i) give the magnitude and direction of the gradient\n%       for the ith point. gradient_angles ranges from 0 to 2*pi\n%                                      \n% OUTPUT\n% histogram: A 1 x num_bins array containing the gradient histogram. Entry 1 is\n%       the sum of entries in gradient_magnitudes whose corresponding\n%       gradient_angles lie between 0 and angle_step. Similarly, entry 2 is for\n%       angles between angle_step and 2*angle_step. Angle_step is calculated as\n%       2*pi/num_bins.\n\n% angles: A 1 x num_bins array which holds the histogram bin lower bounds.\n%       In other words, histogram(i) contains the sum of the\n%       gradient magnitudes of all points whose gradient directions fall\n%       in the range [angles(i), angles(i + 1))\n\n    angle_step = 2 * pi / num_bins;\n    angles = 0 : angle_step : (2*pi-angle_step);\n\n    histogram = zeros(1, num_bins);\n    num = numel(gradient_angles);\n    for n = 1:num\n        index = floor(gradient_angles(n) / angle_step) + 1;\n        histogram(index) = histogram(index) + gradient_magnitudes(n);\n    end    \nend\n\n```\n\nLowe论文中推荐的`bin`数目为36个，计算主方向的函数如下：\n\n``` matlab\nfunction direction = ComputeDominantDirection(gradient_magnitudes, gradient_angles)\n% Computes the dominant gradient direction for the region around a keypoint\n% given the scale of the keypoint and the gradient magnitudes and gradient\n% angles of the pixels in the region surrounding the keypoint.\n%\n% INPUT\n% gradient_magnitudes, gradient_angles:\n%   Two arrays of the same shape where gradient_magnitudes(i) and\n%   gradient_angles(i) give the magnitude and direction of the gradient for\n%   the ith point.\n\n    % Compute a gradient histogram using the weighted gradient magnitudes.\n    % In David Lowe's paper he suggests using 36 bins for this histogram.\n    num_bins = 36;\n    % Step 1:\n    % compute the 36-bin histogram of angles using ComputeGradientHistogram()\n    [histogram, angle_bound] = ComputeGradientHistogram(num_bins, gradient_magnitudes, gradient_angles);\n    % Step 2:\n    % Find the maximum value of the gradient histogram, and set \"direction\"\n    % to the angle corresponding to the maximum. (To match our solutions,\n    % just use the lower-bound angle of the max histogram bin. (E.g. return\n    % 0 radians if it's bin 1.)\n    [~, max_index] = max(histogram);\n    direction = angle_bound(max_index);\nend\n```\n\n之后，我们更新patch内各点的梯度方向，计算其与主方向的夹角，作为新的方向。并将梯度进行高斯平滑。\n\n``` matlab\npatch_theta = patch_theta - ComputeDominantDirection(patch_mag, patch_theta);;\npatch_theta = mod(patch_theta, 2*pi);\npatch_mag = patch_mag .* fspecial('gaussian', patch_size, patch_size / 2); % patch_size = 16\n```\n\n遍历cell，计算feature如下：\n\n``` matlab\nfeature = [];\nrow_iter = 1;\nfor y = 1:num_histograms\n    col_iter = 1;\n    for x = 1:num_histograms\n        cell_mag = patch_mag(row_iter: row_iter + pixelsPerHistogram - 1, ...\n                             col_iter: col_iter + pixelsPerHistogram - 1);\n        cell_theta = patch_theta(row_iter: row_iter + pixelsPerHistogram - 1, ...\n                             col_iter: col_iter + pixelsPerHistogram - 1);\n        [histogram, ~] = ComputeGradientHistogram(num_angles, cell_mag, cell_theta);\n        feature = [feature, histogram];\n        col_iter = col_iter + pixelsPerHistogram;\n    end\n    row_iter = row_iter + pixelsPerHistogram;\nend\n```\n\n最后，对feature做normalization。首先将feature化为单位长度，并将其中太大的分量进行限幅（如0.2的阈值），之后再重新将其转换为单位长度。\n\n这样，就完成了SIFT特征的计算。在Lowe的论文中，有更多对实现细节的讨论，这里只是跟随课程slide和作业走完了算法流程，不再赘述。\n\n## 应用：图像特征点匹配\n和Harris角点一样，SIFT特征可以用作两幅图像的特征点匹配，并且具有多种变换不变性的优点。对于两幅图像分别计算得到的特征点SIFT特征向量，可以使用下面简单的方法搜寻匹配点。计算每组点对之间的欧式距离，如果最近的距离比第二近的距离小得多，那么可以认为有一对成功匹配的特征点。其MATLAB代码如下，其中`descriptor`是两幅图像的SIFT特征向量。阈值默认为取做0.7。\n\n``` matlab\nfunction match = SIFTSimpleMatcher(descriptor1, descriptor2, thresh)\n% SIFTSimpleMatcher\n%   Match one set of SIFT descriptors (descriptor1) to another set of\n%   descriptors (decriptor2). Each descriptor from descriptor1 can at\n%   most be matched to one member of descriptor2, but descriptors from\n%   descriptor2 can be matched more than once.\n%   \n%   Matches are determined as follows:\n%   For each descriptor vector in descriptor1, find the Euclidean distance\n%   between it and each descriptor vector in descriptor2. If the smallest\n%   distance is less than thresh*(the next smallest distance), we say that\n%   the two vectors are a match, and we add the row [d1 index, d2 index] to\n%   the \"match\" array.\n%   \n% INPUT:\n%   descriptor1: N1 * 128 matrix, each row is a SIFT descriptor.\n%   descriptor2: N2 * 128 matrix, each row is a SIFT descriptor.\n%   thresh: a given threshold of ratio. Typically 0.7\n%\n% OUTPUT:\n%   Match: N * 2 matrix, each row is a match.\n%          For example, Match(k, :) = [i, j] means i-th descriptor in\n%          descriptor1 is matched to j-th descriptor in descriptor2.\n    if ~exist('thresh', 'var'),\n        thresh = 0.7;\n    end\n\n    match = [];\n    [N1, ~] = size(descriptor1);\n    for i = 1:N1\n        fea = descriptor1(i, :);\n        err = bsxfun(@minus, fea, descriptor2);\n        dis = sqrt(sum(err.^2, 2));\n        [sorted_dis, ind] = sort(dis, 1);\n        if sorted_dis(1) < thresh * sorted_dis(2)\n            match = [match; [i, ind(1)]];\n        end\n    end\nend\n\n```\n\n接下来，我们可以使用最小二乘法计算两幅图像之间的仿射变换矩阵（齐次变换矩阵）$H$。其中$H$满足：\n$$Hp_{\\text{before}} = p_{\\text{after}}$$\n\n其中\n$$p = \\begin{bmatrix}x \\\\\\\\ y \\\\\\\\ 1\\end{bmatrix}$$\n\n对上式稍作变形，有\n$$p_{\\text{before}}^\\dagger H^\\dagger = p_{\\text{after}}\\dagger$$\n\n就可以使用标准的最小二乘正则方程进行求解了。代码如下：\n\n``` matlab\nfunction H = ComputeAffineMatrix( Pt1, Pt2 )\n%ComputeAffineMatrix\n%   Computes the transformation matrix that transforms a point from\n%   coordinate frame 1 to coordinate frame 2\n%Input:\n%   Pt1: N * 2 matrix, each row is a point in image 1\n%       (N must be at least 3)\n%   Pt2: N * 2 matrix, each row is the point in image 2 that\n%       matches the same point in image 1 (N should be more than 3)\n%Output:\n%   H: 3 * 3 affine transformation matrix,\n%       such that H*pt1(i,:) = pt2(i,:)\n\n    N = size(Pt1,1);\n    if size(Pt1, 1) ~= size(Pt2, 1),\n        error('Dimensions unmatched.');\n    elseif N<3\n        error('At least 3 points are required.');\n    end\n\n    % Convert the input points to homogeneous coordintes.\n    P1 = [Pt1';ones(1,N)];\n    P2 = [Pt2';ones(1,N)];\n\n    H = P1*P1'\\P1*P2';\n    H = H';\n\n    % Sometimes numerical issues cause least-squares to produce a bottom\n    % row which is not exactly [0 0 1], which confuses some of the later\n    % code. So we'll ensure the bottom row is exactly [0 0 1].\n    H(3,:) = [0 0 1];\nend\n```\n\n作业中的其他例子也很有趣，这里不再多说了。贴上两张图像拼接的实验结果吧~\n![result 1](/img/sift_experiment_1.png)\n![result 2](/img/sift_experiment_2.png)\n","source":"_posts/cs131-sift.md","raw":"---\ntitle: CS131-描述图像的特征(SIFT)\ndate: 2017-01-30 22:16:18\ntags:\n     - cs131\n     - 公开课\n---\n\n[SIFT(尺度不变特征变换，Scale Invariant Feature Transform)](https://en.wikipedia.org/wiki/Scale-invariant_feature_transform),最早由Lowe提出，目的是为了解决目标检测（Object Detection）问题中提取图像特征的问题。从名字可以看出，SIFT的优势就在于对尺度变换的不变性，同时SIFT还满足平移变换和旋转变换下的不变性，并对光照变化和3D视角变换有一定的不变性。它的主要步骤如下：\n- scale space上的极值检测。使用DoG在不同的scaleast和image position下找到interest point。\n- interest point的localization。对上面的interest point进行稳定度检测，并确定其所在的scale和position。\n- 确定方向。通过计算图像的梯度图，确定key point的方向，下一步的feature operation就是在这个方向，scale和position上进行的。\n- 确定key point的描述子。使用图像的局部梯度作为key point的描述子，最终构成SIFT特征向量。\n\n## SIFT介绍\n上讲中介绍的Harris角点方法计算简便，并具有平移不变性和旋转不变性。特征$f$对某种变换$\\mathcal{T}$具有不变性，是指在经过变换后原特征保持不变，也就是$f(I) = f(\\mathcal{T}(I))$。但是Harris角点不具有尺度变换不变性，如下图所示。当图像被放大后，原图的角点被判定为了边缘点。\n![harris的尺度变换不满足尺度不变性](/img/harris_non_scale_constant.png)\n\n而我们想要得到一种对尺度变换保持不变性的特征计算方法。例如图像patch的像素平均亮度，如下图所示。region size缩小为原始的一半后，亮度直方图的形状不变，即平均亮度不变。\n![平均亮度满足尺度变化呢不变性](/img/patch_average_intensity_scale_constant.png)\n\n而Lowe想到了使用局部极值来作为feature来保证对scale变换的不变性。在算法的具体实现中，他使用DoG来获得局部极值。\n\n[Lowe的论文](http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf)中也提到了SIFT特征的应用。SIFT特征可以产生稠密（dense）的key point，例如一张500x500像素大小的图像，一般可以产生~2000个稳定的SIFT特征。在进行image matching和recognition时，可以将ref image的SIFT特征提前计算出来保存在数据库中，并计算待处理图像的SIFT特征，根据特征向量的欧氏距离进行匹配。\n\n这篇博客主要是[Lowe上述论文](http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf)的读书笔记，按照SIFT特征的计算步骤进行组织。\n\n## 尺度空间极值的检测方法\n前人研究已经指出，在一系列合理假设下，高斯核是唯一满足尺度不变性的。所谓的尺度空间，就是指原始图像$I(x,y)$和可变尺度的高斯核$G(x,y,\\sigma)$的卷积结果。如下式所示：\n$$L(x,y,\\sigma) = G(x,y,\\sigma)\\ast I(x,y)$$\n\n其中，$G(x,y, \\sigma) = \\frac{1}{2\\pi\\sigma^2}\\exp(-(x^2+y^2)/2\\sigma^2)$。不同的$\\sigma$代表不同的尺度。\n\nDoG(difference of Gaussian)函数定义为不同尺度的高斯核与图像卷积结果之差，即，\n$$D(x,y,\\sigma) = L(x,y,k\\sigma) - L(x,y,\\sigma)$$\n\n如下图所示，输入的图像重复地与高斯核进行卷积得到结果图像$L$（左侧），这样构成了一个octave。相邻的$L$之间作差得到DoG图像（右侧）。当一个octave处理完之后，将当前octave的最后一张高斯卷积结果图像降采样两倍，按照前述方法构造下一个octave。在图中，我们将一个octave划分为$s$个间隔（即$s+1$个图像）时，设$\\sigma$最终变成了2倍（即$\\sigma$加倍）。那么，显然有相邻两层之间的$k = 2^{1/s}$。不过为了保证首尾两张图像也能够计算差值，我们实际上需要再补上两张（做一个padding），也就是说一个octave内的总图像为$s+3$（下图中的$s=2$）。\n![DoG的计算](/img/sift_dog.png)\n\n为何我们要费力气得到DoG呢？论文中作者给出的解释是：DoG对scale-normalized后的Guassian Laplace函数$\\sigma^2\\Delta G$提供了足够的近似。其中前面的$\\sigma^2$系数正是为了保证尺度不变性。而前人的研究则指出，$\\sigma \\Delta G$函数的极值，和其他一大票其他function比较时，能够提供最稳定的feature。\n\n对于高斯核函数，有以下性质：\n$$\\frac{\\partial G}{\\partial \\sigma} = \\sigma \\Delta G$$\n\n我们将式子左侧的微分变成差分，得到了下式：\n$$\\sigma\\Delta G \\approx \\frac{G(x,y,k\\sigma)-G(x,y,\\sigma)}{k\\sigma - \\sigma}$$\n\n也就是：\n$$G(x,y,k\\sigma)-G(x,y,\\sigma) \\approx (k-1)\\sigma^2 \\Delta G$$\n当$k=1$时，上式的近似误差为0（即上面的$s=\\infty$，也就是说octave的划分是连续的）。但是当$k$较大时，如$\\sqrt{2}$（这时$s=2$，octave划分十分粗糙了），仍然保证了稳定性。同时，由于相邻两层的比例$k$是定值，所以$k-1$这个因子对于检测极值没有影响。我们在计算时，无需除以$k-1$。\n\n构造完了DoG图像金字塔，下面我们的任务就是检测其中的极值。如下图，对于每个点，我们将它与金字塔中相邻的26个点作比较，找到局部极值。\n![检测极值](/img/sift_detection_maximum.png)\n\n另外，我们将输入图像行列预先使用线性插值的方法resize为原来的2倍，获取更多的key point。\n\n此外，在Lowe的论文中还提到了使用DoG的泰勒展开和海森矩阵进行key point的精细确定方法，并对key point进行过滤。这里也不再赘述了。\n\n## 128维feature的获取\n我们需要在每个key point处提取128维的特征向量。这里结合CS131课程作业2的相关练习作出说明。对于每个key point，我们关注它位于图像金字塔中的具体层数以及像素点位置，也就是说通过索引`pyramid{scale}(y, x)`就可以获取key point。我们遍历key point，为它们赋予一个128维的特征向量。\n\n我们选取point周围16x16大小的区域，称为一个patch。将其分为4x4共计16个cell。这样，每个cell内共有像素点16个。对于每个cell，我们计算它的局部梯度方向直方图，直方图共有8个bin。也就是说每个cell可以得到一个8维的特征向量。将16个cell的特征向量首尾相接，就得到了128维的SIFT特征向量。在下面的代码中，使用变量`patch_mag`和`patch_theta`分别代表patch的梯度幅值和角度，它们可以很简单地使用卷积和数学运算得到。\n\n``` matlab\npatch_mag = sqrt(patch_dx.^2 + patch_dy.^2);\npatch_theta = atan2(patch_dy, patch_dx);  % atan2的返回结果在区间[-pi, pi]上。\npatch_theta = mod(patch_theta, 2*pi);   % 这里我们要将其转换为[0, 2pi]\n```\n\n之后，我们需要获取key point的主方向。其定义可见slide，即为key point扩展出来的patch的梯度方向直方图的峰值对应的角度。\n![何为主方向](/img/sift_dominant_orientation.png)\n\n所以我们首先应该设计如何构建局部梯度方向直方图。我们只要将`[0, 2pi]`区间划分为若干个`bin`，并将patch内的每个点使用其梯度大小向对应的`bin`内投票即可。如下所示：\n\n``` matlab\nfunction [histogram, angles] = ComputeGradientHistogram(num_bins, gradient_magnitudes, gradient_angles)\n% Compute a gradient histogram using gradient magnitudes and directions.\n% Each point is assigned to one of num_bins depending on its gradient\n% direction; the gradient magnitude of that point is added to its bin.\n%\n% INPUT\n% num_bins: The number of bins to which points should be assigned.\n% gradient_magnitudes, gradient angles:\n%       Two arrays of the same shape where gradient_magnitudes(i) and\n%       gradient_angles(i) give the magnitude and direction of the gradient\n%       for the ith point. gradient_angles ranges from 0 to 2*pi\n%                                      \n% OUTPUT\n% histogram: A 1 x num_bins array containing the gradient histogram. Entry 1 is\n%       the sum of entries in gradient_magnitudes whose corresponding\n%       gradient_angles lie between 0 and angle_step. Similarly, entry 2 is for\n%       angles between angle_step and 2*angle_step. Angle_step is calculated as\n%       2*pi/num_bins.\n\n% angles: A 1 x num_bins array which holds the histogram bin lower bounds.\n%       In other words, histogram(i) contains the sum of the\n%       gradient magnitudes of all points whose gradient directions fall\n%       in the range [angles(i), angles(i + 1))\n\n    angle_step = 2 * pi / num_bins;\n    angles = 0 : angle_step : (2*pi-angle_step);\n\n    histogram = zeros(1, num_bins);\n    num = numel(gradient_angles);\n    for n = 1:num\n        index = floor(gradient_angles(n) / angle_step) + 1;\n        histogram(index) = histogram(index) + gradient_magnitudes(n);\n    end    \nend\n\n```\n\nLowe论文中推荐的`bin`数目为36个，计算主方向的函数如下：\n\n``` matlab\nfunction direction = ComputeDominantDirection(gradient_magnitudes, gradient_angles)\n% Computes the dominant gradient direction for the region around a keypoint\n% given the scale of the keypoint and the gradient magnitudes and gradient\n% angles of the pixels in the region surrounding the keypoint.\n%\n% INPUT\n% gradient_magnitudes, gradient_angles:\n%   Two arrays of the same shape where gradient_magnitudes(i) and\n%   gradient_angles(i) give the magnitude and direction of the gradient for\n%   the ith point.\n\n    % Compute a gradient histogram using the weighted gradient magnitudes.\n    % In David Lowe's paper he suggests using 36 bins for this histogram.\n    num_bins = 36;\n    % Step 1:\n    % compute the 36-bin histogram of angles using ComputeGradientHistogram()\n    [histogram, angle_bound] = ComputeGradientHistogram(num_bins, gradient_magnitudes, gradient_angles);\n    % Step 2:\n    % Find the maximum value of the gradient histogram, and set \"direction\"\n    % to the angle corresponding to the maximum. (To match our solutions,\n    % just use the lower-bound angle of the max histogram bin. (E.g. return\n    % 0 radians if it's bin 1.)\n    [~, max_index] = max(histogram);\n    direction = angle_bound(max_index);\nend\n```\n\n之后，我们更新patch内各点的梯度方向，计算其与主方向的夹角，作为新的方向。并将梯度进行高斯平滑。\n\n``` matlab\npatch_theta = patch_theta - ComputeDominantDirection(patch_mag, patch_theta);;\npatch_theta = mod(patch_theta, 2*pi);\npatch_mag = patch_mag .* fspecial('gaussian', patch_size, patch_size / 2); % patch_size = 16\n```\n\n遍历cell，计算feature如下：\n\n``` matlab\nfeature = [];\nrow_iter = 1;\nfor y = 1:num_histograms\n    col_iter = 1;\n    for x = 1:num_histograms\n        cell_mag = patch_mag(row_iter: row_iter + pixelsPerHistogram - 1, ...\n                             col_iter: col_iter + pixelsPerHistogram - 1);\n        cell_theta = patch_theta(row_iter: row_iter + pixelsPerHistogram - 1, ...\n                             col_iter: col_iter + pixelsPerHistogram - 1);\n        [histogram, ~] = ComputeGradientHistogram(num_angles, cell_mag, cell_theta);\n        feature = [feature, histogram];\n        col_iter = col_iter + pixelsPerHistogram;\n    end\n    row_iter = row_iter + pixelsPerHistogram;\nend\n```\n\n最后，对feature做normalization。首先将feature化为单位长度，并将其中太大的分量进行限幅（如0.2的阈值），之后再重新将其转换为单位长度。\n\n这样，就完成了SIFT特征的计算。在Lowe的论文中，有更多对实现细节的讨论，这里只是跟随课程slide和作业走完了算法流程，不再赘述。\n\n## 应用：图像特征点匹配\n和Harris角点一样，SIFT特征可以用作两幅图像的特征点匹配，并且具有多种变换不变性的优点。对于两幅图像分别计算得到的特征点SIFT特征向量，可以使用下面简单的方法搜寻匹配点。计算每组点对之间的欧式距离，如果最近的距离比第二近的距离小得多，那么可以认为有一对成功匹配的特征点。其MATLAB代码如下，其中`descriptor`是两幅图像的SIFT特征向量。阈值默认为取做0.7。\n\n``` matlab\nfunction match = SIFTSimpleMatcher(descriptor1, descriptor2, thresh)\n% SIFTSimpleMatcher\n%   Match one set of SIFT descriptors (descriptor1) to another set of\n%   descriptors (decriptor2). Each descriptor from descriptor1 can at\n%   most be matched to one member of descriptor2, but descriptors from\n%   descriptor2 can be matched more than once.\n%   \n%   Matches are determined as follows:\n%   For each descriptor vector in descriptor1, find the Euclidean distance\n%   between it and each descriptor vector in descriptor2. If the smallest\n%   distance is less than thresh*(the next smallest distance), we say that\n%   the two vectors are a match, and we add the row [d1 index, d2 index] to\n%   the \"match\" array.\n%   \n% INPUT:\n%   descriptor1: N1 * 128 matrix, each row is a SIFT descriptor.\n%   descriptor2: N2 * 128 matrix, each row is a SIFT descriptor.\n%   thresh: a given threshold of ratio. Typically 0.7\n%\n% OUTPUT:\n%   Match: N * 2 matrix, each row is a match.\n%          For example, Match(k, :) = [i, j] means i-th descriptor in\n%          descriptor1 is matched to j-th descriptor in descriptor2.\n    if ~exist('thresh', 'var'),\n        thresh = 0.7;\n    end\n\n    match = [];\n    [N1, ~] = size(descriptor1);\n    for i = 1:N1\n        fea = descriptor1(i, :);\n        err = bsxfun(@minus, fea, descriptor2);\n        dis = sqrt(sum(err.^2, 2));\n        [sorted_dis, ind] = sort(dis, 1);\n        if sorted_dis(1) < thresh * sorted_dis(2)\n            match = [match; [i, ind(1)]];\n        end\n    end\nend\n\n```\n\n接下来，我们可以使用最小二乘法计算两幅图像之间的仿射变换矩阵（齐次变换矩阵）$H$。其中$H$满足：\n$$Hp_{\\text{before}} = p_{\\text{after}}$$\n\n其中\n$$p = \\begin{bmatrix}x \\\\\\\\ y \\\\\\\\ 1\\end{bmatrix}$$\n\n对上式稍作变形，有\n$$p_{\\text{before}}^\\dagger H^\\dagger = p_{\\text{after}}\\dagger$$\n\n就可以使用标准的最小二乘正则方程进行求解了。代码如下：\n\n``` matlab\nfunction H = ComputeAffineMatrix( Pt1, Pt2 )\n%ComputeAffineMatrix\n%   Computes the transformation matrix that transforms a point from\n%   coordinate frame 1 to coordinate frame 2\n%Input:\n%   Pt1: N * 2 matrix, each row is a point in image 1\n%       (N must be at least 3)\n%   Pt2: N * 2 matrix, each row is the point in image 2 that\n%       matches the same point in image 1 (N should be more than 3)\n%Output:\n%   H: 3 * 3 affine transformation matrix,\n%       such that H*pt1(i,:) = pt2(i,:)\n\n    N = size(Pt1,1);\n    if size(Pt1, 1) ~= size(Pt2, 1),\n        error('Dimensions unmatched.');\n    elseif N<3\n        error('At least 3 points are required.');\n    end\n\n    % Convert the input points to homogeneous coordintes.\n    P1 = [Pt1';ones(1,N)];\n    P2 = [Pt2';ones(1,N)];\n\n    H = P1*P1'\\P1*P2';\n    H = H';\n\n    % Sometimes numerical issues cause least-squares to produce a bottom\n    % row which is not exactly [0 0 1], which confuses some of the later\n    % code. So we'll ensure the bottom row is exactly [0 0 1].\n    H(3,:) = [0 0 1];\nend\n```\n\n作业中的其他例子也很有趣，这里不再多说了。贴上两张图像拼接的实验结果吧~\n![result 1](/img/sift_experiment_1.png)\n![result 2](/img/sift_experiment_2.png)\n","slug":"cs131-sift","published":1,"updated":"2017-02-01T15:10:29.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciyof8h0v0007cq1hb0ygumo9","content":"<p><a href=\"https://en.wikipedia.org/wiki/Scale-invariant_feature_transform\" target=\"_blank\" rel=\"external\">SIFT(尺度不变特征变换，Scale Invariant Feature Transform)</a>,最早由Lowe提出，目的是为了解决目标检测（Object Detection）问题中提取图像特征的问题。从名字可以看出，SIFT的优势就在于对尺度变换的不变性，同时SIFT还满足平移变换和旋转变换下的不变性，并对光照变化和3D视角变换有一定的不变性。它的主要步骤如下：</p>\n<ul>\n<li>scale space上的极值检测。使用DoG在不同的scaleast和image position下找到interest point。</li>\n<li>interest point的localization。对上面的interest point进行稳定度检测，并确定其所在的scale和position。</li>\n<li>确定方向。通过计算图像的梯度图，确定key point的方向，下一步的feature operation就是在这个方向，scale和position上进行的。</li>\n<li>确定key point的描述子。使用图像的局部梯度作为key point的描述子，最终构成SIFT特征向量。</li>\n</ul>\n<h2 id=\"SIFT介绍\"><a href=\"#SIFT介绍\" class=\"headerlink\" title=\"SIFT介绍\"></a>SIFT介绍</h2><p>上讲中介绍的Harris角点方法计算简便，并具有平移不变性和旋转不变性。特征$f$对某种变换$\\mathcal{T}$具有不变性，是指在经过变换后原特征保持不变，也就是$f(I) = f(\\mathcal{T}(I))$。但是Harris角点不具有尺度变换不变性，如下图所示。当图像被放大后，原图的角点被判定为了边缘点。<br><img src=\"/img/harris_non_scale_constant.png\" alt=\"harris的尺度变换不满足尺度不变性\"></p>\n<p>而我们想要得到一种对尺度变换保持不变性的特征计算方法。例如图像patch的像素平均亮度，如下图所示。region size缩小为原始的一半后，亮度直方图的形状不变，即平均亮度不变。<br><img src=\"/img/patch_average_intensity_scale_constant.png\" alt=\"平均亮度满足尺度变化呢不变性\"></p>\n<p>而Lowe想到了使用局部极值来作为feature来保证对scale变换的不变性。在算法的具体实现中，他使用DoG来获得局部极值。</p>\n<p><a href=\"http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf\" target=\"_blank\" rel=\"external\">Lowe的论文</a>中也提到了SIFT特征的应用。SIFT特征可以产生稠密（dense）的key point，例如一张500x500像素大小的图像，一般可以产生~2000个稳定的SIFT特征。在进行image matching和recognition时，可以将ref image的SIFT特征提前计算出来保存在数据库中，并计算待处理图像的SIFT特征，根据特征向量的欧氏距离进行匹配。</p>\n<p>这篇博客主要是<a href=\"http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf\" target=\"_blank\" rel=\"external\">Lowe上述论文</a>的读书笔记，按照SIFT特征的计算步骤进行组织。</p>\n<h2 id=\"尺度空间极值的检测方法\"><a href=\"#尺度空间极值的检测方法\" class=\"headerlink\" title=\"尺度空间极值的检测方法\"></a>尺度空间极值的检测方法</h2><p>前人研究已经指出，在一系列合理假设下，高斯核是唯一满足尺度不变性的。所谓的尺度空间，就是指原始图像$I(x,y)$和可变尺度的高斯核$G(x,y,\\sigma)$的卷积结果。如下式所示：</p>\n<script type=\"math/tex; mode=display\">L(x,y,\\sigma) = G(x,y,\\sigma)\\ast I(x,y)</script><p>其中，$G(x,y, \\sigma) = \\frac{1}{2\\pi\\sigma^2}\\exp(-(x^2+y^2)/2\\sigma^2)$。不同的$\\sigma$代表不同的尺度。</p>\n<p>DoG(difference of Gaussian)函数定义为不同尺度的高斯核与图像卷积结果之差，即，</p>\n<script type=\"math/tex; mode=display\">D(x,y,\\sigma) = L(x,y,k\\sigma) - L(x,y,\\sigma)</script><p>如下图所示，输入的图像重复地与高斯核进行卷积得到结果图像$L$（左侧），这样构成了一个octave。相邻的$L$之间作差得到DoG图像（右侧）。当一个octave处理完之后，将当前octave的最后一张高斯卷积结果图像降采样两倍，按照前述方法构造下一个octave。在图中，我们将一个octave划分为$s$个间隔（即$s+1$个图像）时，设$\\sigma$最终变成了2倍（即$\\sigma$加倍）。那么，显然有相邻两层之间的$k = 2^{1/s}$。不过为了保证首尾两张图像也能够计算差值，我们实际上需要再补上两张（做一个padding），也就是说一个octave内的总图像为$s+3$（下图中的$s=2$）。<br><img src=\"/img/sift_dog.png\" alt=\"DoG的计算\"></p>\n<p>为何我们要费力气得到DoG呢？论文中作者给出的解释是：DoG对scale-normalized后的Guassian Laplace函数$\\sigma^2\\Delta G$提供了足够的近似。其中前面的$\\sigma^2$系数正是为了保证尺度不变性。而前人的研究则指出，$\\sigma \\Delta G$函数的极值，和其他一大票其他function比较时，能够提供最稳定的feature。</p>\n<p>对于高斯核函数，有以下性质：</p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial G}{\\partial \\sigma} = \\sigma \\Delta G</script><p>我们将式子左侧的微分变成差分，得到了下式：</p>\n<script type=\"math/tex; mode=display\">\\sigma\\Delta G \\approx \\frac{G(x,y,k\\sigma)-G(x,y,\\sigma)}{k\\sigma - \\sigma}</script><p>也就是：</p>\n<script type=\"math/tex; mode=display\">G(x,y,k\\sigma)-G(x,y,\\sigma) \\approx (k-1)\\sigma^2 \\Delta G</script><p>当$k=1$时，上式的近似误差为0（即上面的$s=\\infty$，也就是说octave的划分是连续的）。但是当$k$较大时，如$\\sqrt{2}$（这时$s=2$，octave划分十分粗糙了），仍然保证了稳定性。同时，由于相邻两层的比例$k$是定值，所以$k-1$这个因子对于检测极值没有影响。我们在计算时，无需除以$k-1$。</p>\n<p>构造完了DoG图像金字塔，下面我们的任务就是检测其中的极值。如下图，对于每个点，我们将它与金字塔中相邻的26个点作比较，找到局部极值。<br><img src=\"/img/sift_detection_maximum.png\" alt=\"检测极值\"></p>\n<p>另外，我们将输入图像行列预先使用线性插值的方法resize为原来的2倍，获取更多的key point。</p>\n<p>此外，在Lowe的论文中还提到了使用DoG的泰勒展开和海森矩阵进行key point的精细确定方法，并对key point进行过滤。这里也不再赘述了。</p>\n<h2 id=\"128维feature的获取\"><a href=\"#128维feature的获取\" class=\"headerlink\" title=\"128维feature的获取\"></a>128维feature的获取</h2><p>我们需要在每个key point处提取128维的特征向量。这里结合CS131课程作业2的相关练习作出说明。对于每个key point，我们关注它位于图像金字塔中的具体层数以及像素点位置，也就是说通过索引<code>pyramid{scale}(y, x)</code>就可以获取key point。我们遍历key point，为它们赋予一个128维的特征向量。</p>\n<p>我们选取point周围16x16大小的区域，称为一个patch。将其分为4x4共计16个cell。这样，每个cell内共有像素点16个。对于每个cell，我们计算它的局部梯度方向直方图，直方图共有8个bin。也就是说每个cell可以得到一个8维的特征向量。将16个cell的特征向量首尾相接，就得到了128维的SIFT特征向量。在下面的代码中，使用变量<code>patch_mag</code>和<code>patch_theta</code>分别代表patch的梯度幅值和角度，它们可以很简单地使用卷积和数学运算得到。</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">patch_mag = <span class=\"built_in\">sqrt</span>(patch_dx.^<span class=\"number\">2</span> + patch_dy.^<span class=\"number\">2</span>);</div><div class=\"line\">patch_theta = <span class=\"built_in\">atan2</span>(patch_dy, patch_dx);  <span class=\"comment\">% atan2的返回结果在区间[-pi, pi]上。</span></div><div class=\"line\">patch_theta = <span class=\"built_in\">mod</span>(patch_theta, <span class=\"number\">2</span>*<span class=\"built_in\">pi</span>);   <span class=\"comment\">% 这里我们要将其转换为[0, 2pi]</span></div></pre></td></tr></table></figure>\n<p>之后，我们需要获取key point的主方向。其定义可见slide，即为key point扩展出来的patch的梯度方向直方图的峰值对应的角度。<br><img src=\"/img/sift_dominant_orientation.png\" alt=\"何为主方向\"></p>\n<p>所以我们首先应该设计如何构建局部梯度方向直方图。我们只要将<code>[0, 2pi]</code>区间划分为若干个<code>bin</code>，并将patch内的每个点使用其梯度大小向对应的<code>bin</code>内投票即可。如下所示：</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"params\">[histogram, angles]</span> = <span class=\"title\">ComputeGradientHistogram</span><span class=\"params\">(num_bins, gradient_magnitudes, gradient_angles)</span></span></div><div class=\"line\"><span class=\"comment\">% Compute a gradient histogram using gradient magnitudes and directions.</span></div><div class=\"line\"><span class=\"comment\">% Each point is assigned to one of num_bins depending on its gradient</span></div><div class=\"line\"><span class=\"comment\">% direction; the gradient magnitude of that point is added to its bin.</span></div><div class=\"line\"><span class=\"comment\">%</span></div><div class=\"line\"><span class=\"comment\">% INPUT</span></div><div class=\"line\"><span class=\"comment\">% num_bins: The number of bins to which points should be assigned.</span></div><div class=\"line\"><span class=\"comment\">% gradient_magnitudes, gradient angles:</span></div><div class=\"line\"><span class=\"comment\">%       Two arrays of the same shape where gradient_magnitudes(i) and</span></div><div class=\"line\"><span class=\"comment\">%       gradient_angles(i) give the magnitude and direction of the gradient</span></div><div class=\"line\"><span class=\"comment\">%       for the ith point. gradient_angles ranges from 0 to 2*pi</span></div><div class=\"line\"><span class=\"comment\">%                                      </span></div><div class=\"line\"><span class=\"comment\">% OUTPUT</span></div><div class=\"line\"><span class=\"comment\">% histogram: A 1 x num_bins array containing the gradient histogram. Entry 1 is</span></div><div class=\"line\"><span class=\"comment\">%       the sum of entries in gradient_magnitudes whose corresponding</span></div><div class=\"line\"><span class=\"comment\">%       gradient_angles lie between 0 and angle_step. Similarly, entry 2 is for</span></div><div class=\"line\"><span class=\"comment\">%       angles between angle_step and 2*angle_step. Angle_step is calculated as</span></div><div class=\"line\"><span class=\"comment\">%       2*pi/num_bins.</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">% angles: A 1 x num_bins array which holds the histogram bin lower bounds.</span></div><div class=\"line\"><span class=\"comment\">%       In other words, histogram(i) contains the sum of the</span></div><div class=\"line\"><span class=\"comment\">%       gradient magnitudes of all points whose gradient directions fall</span></div><div class=\"line\"><span class=\"comment\">%       in the range [angles(i), angles(i + 1))</span></div><div class=\"line\"></div><div class=\"line\">    angle_step = <span class=\"number\">2</span> * <span class=\"built_in\">pi</span> / num_bins;</div><div class=\"line\">    angles = <span class=\"number\">0</span> : angle_step : (<span class=\"number\">2</span>*<span class=\"built_in\">pi</span>-angle_step);</div><div class=\"line\"></div><div class=\"line\">    histogram = <span class=\"built_in\">zeros</span>(<span class=\"number\">1</span>, num_bins);</div><div class=\"line\">    num = <span class=\"built_in\">numel</span>(gradient_angles);</div><div class=\"line\">    <span class=\"keyword\">for</span> n = <span class=\"number\">1</span>:num</div><div class=\"line\">        index = <span class=\"built_in\">floor</span>(gradient_angles(n) / angle_step) + <span class=\"number\">1</span>;</div><div class=\"line\">        histogram(index) = histogram(index) + gradient_magnitudes(n);</div><div class=\"line\">    <span class=\"keyword\">end</span>    </div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>Lowe论文中推荐的<code>bin</code>数目为36个，计算主方向的函数如下：</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">direction</span> = <span class=\"title\">ComputeDominantDirection</span><span class=\"params\">(gradient_magnitudes, gradient_angles)</span></span></div><div class=\"line\"><span class=\"comment\">% Computes the dominant gradient direction for the region around a keypoint</span></div><div class=\"line\"><span class=\"comment\">% given the scale of the keypoint and the gradient magnitudes and gradient</span></div><div class=\"line\"><span class=\"comment\">% angles of the pixels in the region surrounding the keypoint.</span></div><div class=\"line\"><span class=\"comment\">%</span></div><div class=\"line\"><span class=\"comment\">% INPUT</span></div><div class=\"line\"><span class=\"comment\">% gradient_magnitudes, gradient_angles:</span></div><div class=\"line\"><span class=\"comment\">%   Two arrays of the same shape where gradient_magnitudes(i) and</span></div><div class=\"line\"><span class=\"comment\">%   gradient_angles(i) give the magnitude and direction of the gradient for</span></div><div class=\"line\"><span class=\"comment\">%   the ith point.</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">% Compute a gradient histogram using the weighted gradient magnitudes.</span></div><div class=\"line\">    <span class=\"comment\">% In David Lowe's paper he suggests using 36 bins for this histogram.</span></div><div class=\"line\">    num_bins = <span class=\"number\">36</span>;</div><div class=\"line\">    <span class=\"comment\">% Step 1:</span></div><div class=\"line\">    <span class=\"comment\">% compute the 36-bin histogram of angles using ComputeGradientHistogram()</span></div><div class=\"line\">    [histogram, angle_bound] = ComputeGradientHistogram(num_bins, gradient_magnitudes, gradient_angles);</div><div class=\"line\">    <span class=\"comment\">% Step 2:</span></div><div class=\"line\">    <span class=\"comment\">% Find the maximum value of the gradient histogram, and set \"direction\"</span></div><div class=\"line\">    <span class=\"comment\">% to the angle corresponding to the maximum. (To match our solutions,</span></div><div class=\"line\">    <span class=\"comment\">% just use the lower-bound angle of the max histogram bin. (E.g. return</span></div><div class=\"line\">    <span class=\"comment\">% 0 radians if it's bin 1.)</span></div><div class=\"line\">    [~, max_index] = max(histogram);</div><div class=\"line\">    direction = angle_bound(max_index);</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>之后，我们更新patch内各点的梯度方向，计算其与主方向的夹角，作为新的方向。并将梯度进行高斯平滑。</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">patch_theta = patch_theta - ComputeDominantDirection(patch_mag, patch_theta);;</div><div class=\"line\">patch_theta = <span class=\"built_in\">mod</span>(patch_theta, <span class=\"number\">2</span>*<span class=\"built_in\">pi</span>);</div><div class=\"line\">patch_mag = patch_mag .* fspecial(<span class=\"string\">'gaussian'</span>, patch_size, patch_size / <span class=\"number\">2</span>); <span class=\"comment\">% patch_size = 16</span></div></pre></td></tr></table></figure>\n<p>遍历cell，计算feature如下：</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">feature = [];</div><div class=\"line\">row_iter = <span class=\"number\">1</span>;</div><div class=\"line\"><span class=\"keyword\">for</span> y = <span class=\"number\">1</span>:num_histograms</div><div class=\"line\">    col_iter = <span class=\"number\">1</span>;</div><div class=\"line\">    <span class=\"keyword\">for</span> x = <span class=\"number\">1</span>:num_histograms</div><div class=\"line\">        cell_mag = patch_mag(row_iter: row_iter + pixelsPerHistogram - <span class=\"number\">1</span>, ...</div><div class=\"line\">                             col_iter: col_iter + pixelsPerHistogram - <span class=\"number\">1</span>);</div><div class=\"line\">        cell_theta = patch_theta(row_iter: row_iter + pixelsPerHistogram - <span class=\"number\">1</span>, ...</div><div class=\"line\">                             col_iter: col_iter + pixelsPerHistogram - <span class=\"number\">1</span>);</div><div class=\"line\">        [histogram, ~] = ComputeGradientHistogram(num_angles, cell_mag, cell_theta);</div><div class=\"line\">        feature = [feature, histogram];</div><div class=\"line\">        col_iter = col_iter + pixelsPerHistogram;</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\">    row_iter = row_iter + pixelsPerHistogram;</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>最后，对feature做normalization。首先将feature化为单位长度，并将其中太大的分量进行限幅（如0.2的阈值），之后再重新将其转换为单位长度。</p>\n<p>这样，就完成了SIFT特征的计算。在Lowe的论文中，有更多对实现细节的讨论，这里只是跟随课程slide和作业走完了算法流程，不再赘述。</p>\n<h2 id=\"应用：图像特征点匹配\"><a href=\"#应用：图像特征点匹配\" class=\"headerlink\" title=\"应用：图像特征点匹配\"></a>应用：图像特征点匹配</h2><p>和Harris角点一样，SIFT特征可以用作两幅图像的特征点匹配，并且具有多种变换不变性的优点。对于两幅图像分别计算得到的特征点SIFT特征向量，可以使用下面简单的方法搜寻匹配点。计算每组点对之间的欧式距离，如果最近的距离比第二近的距离小得多，那么可以认为有一对成功匹配的特征点。其MATLAB代码如下，其中<code>descriptor</code>是两幅图像的SIFT特征向量。阈值默认为取做0.7。</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">match</span> = <span class=\"title\">SIFTSimpleMatcher</span><span class=\"params\">(descriptor1, descriptor2, thresh)</span></span></div><div class=\"line\"><span class=\"comment\">% SIFTSimpleMatcher</span></div><div class=\"line\"><span class=\"comment\">%   Match one set of SIFT descriptors (descriptor1) to another set of</span></div><div class=\"line\"><span class=\"comment\">%   descriptors (decriptor2). Each descriptor from descriptor1 can at</span></div><div class=\"line\"><span class=\"comment\">%   most be matched to one member of descriptor2, but descriptors from</span></div><div class=\"line\"><span class=\"comment\">%   descriptor2 can be matched more than once.</span></div><div class=\"line\"><span class=\"comment\">%   </span></div><div class=\"line\"><span class=\"comment\">%   Matches are determined as follows:</span></div><div class=\"line\"><span class=\"comment\">%   For each descriptor vector in descriptor1, find the Euclidean distance</span></div><div class=\"line\"><span class=\"comment\">%   between it and each descriptor vector in descriptor2. If the smallest</span></div><div class=\"line\"><span class=\"comment\">%   distance is less than thresh*(the next smallest distance), we say that</span></div><div class=\"line\"><span class=\"comment\">%   the two vectors are a match, and we add the row [d1 index, d2 index] to</span></div><div class=\"line\"><span class=\"comment\">%   the \"match\" array.</span></div><div class=\"line\"><span class=\"comment\">%   </span></div><div class=\"line\"><span class=\"comment\">% INPUT:</span></div><div class=\"line\"><span class=\"comment\">%   descriptor1: N1 * 128 matrix, each row is a SIFT descriptor.</span></div><div class=\"line\"><span class=\"comment\">%   descriptor2: N2 * 128 matrix, each row is a SIFT descriptor.</span></div><div class=\"line\"><span class=\"comment\">%   thresh: a given threshold of ratio. Typically 0.7</span></div><div class=\"line\"><span class=\"comment\">%</span></div><div class=\"line\"><span class=\"comment\">% OUTPUT:</span></div><div class=\"line\"><span class=\"comment\">%   Match: N * 2 matrix, each row is a match.</span></div><div class=\"line\"><span class=\"comment\">%          For example, Match(k, :) = [i, j] means i-th descriptor in</span></div><div class=\"line\"><span class=\"comment\">%          descriptor1 is matched to j-th descriptor in descriptor2.</span></div><div class=\"line\">    <span class=\"keyword\">if</span> ~exist(<span class=\"string\">'thresh'</span>, <span class=\"string\">'var'</span>),</div><div class=\"line\">        thresh = <span class=\"number\">0.7</span>;</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\">    match = [];</div><div class=\"line\">    [N1, ~] = <span class=\"built_in\">size</span>(descriptor1);</div><div class=\"line\">    <span class=\"keyword\">for</span> <span class=\"built_in\">i</span> = <span class=\"number\">1</span>:N1</div><div class=\"line\">        fea = descriptor1(<span class=\"built_in\">i</span>, :);</div><div class=\"line\">        err = <span class=\"built_in\">bsxfun</span>(@minus, fea, descriptor2);</div><div class=\"line\">        dis = <span class=\"built_in\">sqrt</span>(sum(err.^<span class=\"number\">2</span>, <span class=\"number\">2</span>));</div><div class=\"line\">        [sorted_dis, ind] = sort(dis, <span class=\"number\">1</span>);</div><div class=\"line\">        <span class=\"keyword\">if</span> sorted_dis(<span class=\"number\">1</span>) &lt; thresh * sorted_dis(<span class=\"number\">2</span>)</div><div class=\"line\">            match = [match; [i, ind(<span class=\"number\">1</span>)]];</div><div class=\"line\">        <span class=\"keyword\">end</span></div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>接下来，我们可以使用最小二乘法计算两幅图像之间的仿射变换矩阵（齐次变换矩阵）$H$。其中$H$满足：</p>\n<script type=\"math/tex; mode=display\">Hp_{\\text{before}} = p_{\\text{after}}</script><p>其中</p>\n<script type=\"math/tex; mode=display\">p = \\begin{bmatrix}x \\\\\\\\ y \\\\\\\\ 1\\end{bmatrix}</script><p>对上式稍作变形，有</p>\n<script type=\"math/tex; mode=display\">p_{\\text{before}}^\\dagger H^\\dagger = p_{\\text{after}}\\dagger</script><p>就可以使用标准的最小二乘正则方程进行求解了。代码如下：</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">H</span> = <span class=\"title\">ComputeAffineMatrix</span><span class=\"params\">( Pt1, Pt2 )</span></span></div><div class=\"line\"><span class=\"comment\">%ComputeAffineMatrix</span></div><div class=\"line\"><span class=\"comment\">%   Computes the transformation matrix that transforms a point from</span></div><div class=\"line\"><span class=\"comment\">%   coordinate frame 1 to coordinate frame 2</span></div><div class=\"line\"><span class=\"comment\">%Input:</span></div><div class=\"line\"><span class=\"comment\">%   Pt1: N * 2 matrix, each row is a point in image 1</span></div><div class=\"line\"><span class=\"comment\">%       (N must be at least 3)</span></div><div class=\"line\"><span class=\"comment\">%   Pt2: N * 2 matrix, each row is the point in image 2 that</span></div><div class=\"line\"><span class=\"comment\">%       matches the same point in image 1 (N should be more than 3)</span></div><div class=\"line\"><span class=\"comment\">%Output:</span></div><div class=\"line\"><span class=\"comment\">%   H: 3 * 3 affine transformation matrix,</span></div><div class=\"line\"><span class=\"comment\">%       such that H*pt1(i,:) = pt2(i,:)</span></div><div class=\"line\"></div><div class=\"line\">    N = <span class=\"built_in\">size</span>(Pt1,<span class=\"number\">1</span>);</div><div class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">size</span>(Pt1, <span class=\"number\">1</span>) ~= <span class=\"built_in\">size</span>(Pt2, <span class=\"number\">1</span>),</div><div class=\"line\">        error(<span class=\"string\">'Dimensions unmatched.'</span>);</div><div class=\"line\">    <span class=\"keyword\">elseif</span> N&lt;<span class=\"number\">3</span></div><div class=\"line\">        error(<span class=\"string\">'At least 3 points are required.'</span>);</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">% Convert the input points to homogeneous coordintes.</span></div><div class=\"line\">    P1 = [Pt1<span class=\"string\">';ones(1,N)];</span></div><div class=\"line\">    P2 = [Pt2';ones(<span class=\"number\">1</span>,N)];</div><div class=\"line\"></div><div class=\"line\">    H = P1*P1'\\P1*P2';</div><div class=\"line\">    H = H';</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">% Sometimes numerical issues cause least-squares to produce a bottom</span></div><div class=\"line\">    <span class=\"comment\">% row which is not exactly [0 0 1], which confuses some of the later</span></div><div class=\"line\">    <span class=\"comment\">% code. So we'll ensure the bottom row is exactly [0 0 1].</span></div><div class=\"line\">    H(<span class=\"number\">3</span>,:) = [<span class=\"number\">0</span> <span class=\"number\">0</span> <span class=\"number\">1</span>];</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>作业中的其他例子也很有趣，这里不再多说了。贴上两张图像拼接的实验结果吧~<br><img src=\"/img/sift_experiment_1.png\" alt=\"result 1\"><br><img src=\"/img/sift_experiment_2.png\" alt=\"result 2\"></p>\n","excerpt":"","more":"<p><a href=\"https://en.wikipedia.org/wiki/Scale-invariant_feature_transform\">SIFT(尺度不变特征变换，Scale Invariant Feature Transform)</a>,最早由Lowe提出，目的是为了解决目标检测（Object Detection）问题中提取图像特征的问题。从名字可以看出，SIFT的优势就在于对尺度变换的不变性，同时SIFT还满足平移变换和旋转变换下的不变性，并对光照变化和3D视角变换有一定的不变性。它的主要步骤如下：</p>\n<ul>\n<li>scale space上的极值检测。使用DoG在不同的scaleast和image position下找到interest point。</li>\n<li>interest point的localization。对上面的interest point进行稳定度检测，并确定其所在的scale和position。</li>\n<li>确定方向。通过计算图像的梯度图，确定key point的方向，下一步的feature operation就是在这个方向，scale和position上进行的。</li>\n<li>确定key point的描述子。使用图像的局部梯度作为key point的描述子，最终构成SIFT特征向量。</li>\n</ul>\n<h2 id=\"SIFT介绍\"><a href=\"#SIFT介绍\" class=\"headerlink\" title=\"SIFT介绍\"></a>SIFT介绍</h2><p>上讲中介绍的Harris角点方法计算简便，并具有平移不变性和旋转不变性。特征$f$对某种变换$\\mathcal{T}$具有不变性，是指在经过变换后原特征保持不变，也就是$f(I) = f(\\mathcal{T}(I))$。但是Harris角点不具有尺度变换不变性，如下图所示。当图像被放大后，原图的角点被判定为了边缘点。<br><img src=\"/img/harris_non_scale_constant.png\" alt=\"harris的尺度变换不满足尺度不变性\"></p>\n<p>而我们想要得到一种对尺度变换保持不变性的特征计算方法。例如图像patch的像素平均亮度，如下图所示。region size缩小为原始的一半后，亮度直方图的形状不变，即平均亮度不变。<br><img src=\"/img/patch_average_intensity_scale_constant.png\" alt=\"平均亮度满足尺度变化呢不变性\"></p>\n<p>而Lowe想到了使用局部极值来作为feature来保证对scale变换的不变性。在算法的具体实现中，他使用DoG来获得局部极值。</p>\n<p><a href=\"http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf\">Lowe的论文</a>中也提到了SIFT特征的应用。SIFT特征可以产生稠密（dense）的key point，例如一张500x500像素大小的图像，一般可以产生~2000个稳定的SIFT特征。在进行image matching和recognition时，可以将ref image的SIFT特征提前计算出来保存在数据库中，并计算待处理图像的SIFT特征，根据特征向量的欧氏距离进行匹配。</p>\n<p>这篇博客主要是<a href=\"http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf\">Lowe上述论文</a>的读书笔记，按照SIFT特征的计算步骤进行组织。</p>\n<h2 id=\"尺度空间极值的检测方法\"><a href=\"#尺度空间极值的检测方法\" class=\"headerlink\" title=\"尺度空间极值的检测方法\"></a>尺度空间极值的检测方法</h2><p>前人研究已经指出，在一系列合理假设下，高斯核是唯一满足尺度不变性的。所谓的尺度空间，就是指原始图像$I(x,y)$和可变尺度的高斯核$G(x,y,\\sigma)$的卷积结果。如下式所示：</p>\n<script type=\"math/tex; mode=display\">L(x,y,\\sigma) = G(x,y,\\sigma)\\ast I(x,y)</script><p>其中，$G(x,y, \\sigma) = \\frac{1}{2\\pi\\sigma^2}\\exp(-(x^2+y^2)/2\\sigma^2)$。不同的$\\sigma$代表不同的尺度。</p>\n<p>DoG(difference of Gaussian)函数定义为不同尺度的高斯核与图像卷积结果之差，即，</p>\n<script type=\"math/tex; mode=display\">D(x,y,\\sigma) = L(x,y,k\\sigma) - L(x,y,\\sigma)</script><p>如下图所示，输入的图像重复地与高斯核进行卷积得到结果图像$L$（左侧），这样构成了一个octave。相邻的$L$之间作差得到DoG图像（右侧）。当一个octave处理完之后，将当前octave的最后一张高斯卷积结果图像降采样两倍，按照前述方法构造下一个octave。在图中，我们将一个octave划分为$s$个间隔（即$s+1$个图像）时，设$\\sigma$最终变成了2倍（即$\\sigma$加倍）。那么，显然有相邻两层之间的$k = 2^{1/s}$。不过为了保证首尾两张图像也能够计算差值，我们实际上需要再补上两张（做一个padding），也就是说一个octave内的总图像为$s+3$（下图中的$s=2$）。<br><img src=\"/img/sift_dog.png\" alt=\"DoG的计算\"></p>\n<p>为何我们要费力气得到DoG呢？论文中作者给出的解释是：DoG对scale-normalized后的Guassian Laplace函数$\\sigma^2\\Delta G$提供了足够的近似。其中前面的$\\sigma^2$系数正是为了保证尺度不变性。而前人的研究则指出，$\\sigma \\Delta G$函数的极值，和其他一大票其他function比较时，能够提供最稳定的feature。</p>\n<p>对于高斯核函数，有以下性质：</p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial G}{\\partial \\sigma} = \\sigma \\Delta G</script><p>我们将式子左侧的微分变成差分，得到了下式：</p>\n<script type=\"math/tex; mode=display\">\\sigma\\Delta G \\approx \\frac{G(x,y,k\\sigma)-G(x,y,\\sigma)}{k\\sigma - \\sigma}</script><p>也就是：</p>\n<script type=\"math/tex; mode=display\">G(x,y,k\\sigma)-G(x,y,\\sigma) \\approx (k-1)\\sigma^2 \\Delta G</script><p>当$k=1$时，上式的近似误差为0（即上面的$s=\\infty$，也就是说octave的划分是连续的）。但是当$k$较大时，如$\\sqrt{2}$（这时$s=2$，octave划分十分粗糙了），仍然保证了稳定性。同时，由于相邻两层的比例$k$是定值，所以$k-1$这个因子对于检测极值没有影响。我们在计算时，无需除以$k-1$。</p>\n<p>构造完了DoG图像金字塔，下面我们的任务就是检测其中的极值。如下图，对于每个点，我们将它与金字塔中相邻的26个点作比较，找到局部极值。<br><img src=\"/img/sift_detection_maximum.png\" alt=\"检测极值\"></p>\n<p>另外，我们将输入图像行列预先使用线性插值的方法resize为原来的2倍，获取更多的key point。</p>\n<p>此外，在Lowe的论文中还提到了使用DoG的泰勒展开和海森矩阵进行key point的精细确定方法，并对key point进行过滤。这里也不再赘述了。</p>\n<h2 id=\"128维feature的获取\"><a href=\"#128维feature的获取\" class=\"headerlink\" title=\"128维feature的获取\"></a>128维feature的获取</h2><p>我们需要在每个key point处提取128维的特征向量。这里结合CS131课程作业2的相关练习作出说明。对于每个key point，我们关注它位于图像金字塔中的具体层数以及像素点位置，也就是说通过索引<code>pyramid{scale}(y, x)</code>就可以获取key point。我们遍历key point，为它们赋予一个128维的特征向量。</p>\n<p>我们选取point周围16x16大小的区域，称为一个patch。将其分为4x4共计16个cell。这样，每个cell内共有像素点16个。对于每个cell，我们计算它的局部梯度方向直方图，直方图共有8个bin。也就是说每个cell可以得到一个8维的特征向量。将16个cell的特征向量首尾相接，就得到了128维的SIFT特征向量。在下面的代码中，使用变量<code>patch_mag</code>和<code>patch_theta</code>分别代表patch的梯度幅值和角度，它们可以很简单地使用卷积和数学运算得到。</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">patch_mag = <span class=\"built_in\">sqrt</span>(patch_dx.^<span class=\"number\">2</span> + patch_dy.^<span class=\"number\">2</span>);</div><div class=\"line\">patch_theta = <span class=\"built_in\">atan2</span>(patch_dy, patch_dx);  <span class=\"comment\">% atan2的返回结果在区间[-pi, pi]上。</span></div><div class=\"line\">patch_theta = <span class=\"built_in\">mod</span>(patch_theta, <span class=\"number\">2</span>*<span class=\"built_in\">pi</span>);   <span class=\"comment\">% 这里我们要将其转换为[0, 2pi]</span></div></pre></td></tr></table></figure>\n<p>之后，我们需要获取key point的主方向。其定义可见slide，即为key point扩展出来的patch的梯度方向直方图的峰值对应的角度。<br><img src=\"/img/sift_dominant_orientation.png\" alt=\"何为主方向\"></p>\n<p>所以我们首先应该设计如何构建局部梯度方向直方图。我们只要将<code>[0, 2pi]</code>区间划分为若干个<code>bin</code>，并将patch内的每个点使用其梯度大小向对应的<code>bin</code>内投票即可。如下所示：</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"params\">[histogram, angles]</span> = <span class=\"title\">ComputeGradientHistogram</span><span class=\"params\">(num_bins, gradient_magnitudes, gradient_angles)</span></span></div><div class=\"line\"><span class=\"comment\">% Compute a gradient histogram using gradient magnitudes and directions.</span></div><div class=\"line\"><span class=\"comment\">% Each point is assigned to one of num_bins depending on its gradient</span></div><div class=\"line\"><span class=\"comment\">% direction; the gradient magnitude of that point is added to its bin.</span></div><div class=\"line\"><span class=\"comment\">%</span></div><div class=\"line\"><span class=\"comment\">% INPUT</span></div><div class=\"line\"><span class=\"comment\">% num_bins: The number of bins to which points should be assigned.</span></div><div class=\"line\"><span class=\"comment\">% gradient_magnitudes, gradient angles:</span></div><div class=\"line\"><span class=\"comment\">%       Two arrays of the same shape where gradient_magnitudes(i) and</span></div><div class=\"line\"><span class=\"comment\">%       gradient_angles(i) give the magnitude and direction of the gradient</span></div><div class=\"line\"><span class=\"comment\">%       for the ith point. gradient_angles ranges from 0 to 2*pi</span></div><div class=\"line\"><span class=\"comment\">%                                      </span></div><div class=\"line\"><span class=\"comment\">% OUTPUT</span></div><div class=\"line\"><span class=\"comment\">% histogram: A 1 x num_bins array containing the gradient histogram. Entry 1 is</span></div><div class=\"line\"><span class=\"comment\">%       the sum of entries in gradient_magnitudes whose corresponding</span></div><div class=\"line\"><span class=\"comment\">%       gradient_angles lie between 0 and angle_step. Similarly, entry 2 is for</span></div><div class=\"line\"><span class=\"comment\">%       angles between angle_step and 2*angle_step. Angle_step is calculated as</span></div><div class=\"line\"><span class=\"comment\">%       2*pi/num_bins.</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">% angles: A 1 x num_bins array which holds the histogram bin lower bounds.</span></div><div class=\"line\"><span class=\"comment\">%       In other words, histogram(i) contains the sum of the</span></div><div class=\"line\"><span class=\"comment\">%       gradient magnitudes of all points whose gradient directions fall</span></div><div class=\"line\"><span class=\"comment\">%       in the range [angles(i), angles(i + 1))</span></div><div class=\"line\"></div><div class=\"line\">    angle_step = <span class=\"number\">2</span> * <span class=\"built_in\">pi</span> / num_bins;</div><div class=\"line\">    angles = <span class=\"number\">0</span> : angle_step : (<span class=\"number\">2</span>*<span class=\"built_in\">pi</span>-angle_step);</div><div class=\"line\"></div><div class=\"line\">    histogram = <span class=\"built_in\">zeros</span>(<span class=\"number\">1</span>, num_bins);</div><div class=\"line\">    num = <span class=\"built_in\">numel</span>(gradient_angles);</div><div class=\"line\">    <span class=\"keyword\">for</span> n = <span class=\"number\">1</span>:num</div><div class=\"line\">        index = <span class=\"built_in\">floor</span>(gradient_angles(n) / angle_step) + <span class=\"number\">1</span>;</div><div class=\"line\">        histogram(index) = histogram(index) + gradient_magnitudes(n);</div><div class=\"line\">    <span class=\"keyword\">end</span>    </div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>Lowe论文中推荐的<code>bin</code>数目为36个，计算主方向的函数如下：</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">direction</span> = <span class=\"title\">ComputeDominantDirection</span><span class=\"params\">(gradient_magnitudes, gradient_angles)</span></span></div><div class=\"line\"><span class=\"comment\">% Computes the dominant gradient direction for the region around a keypoint</span></div><div class=\"line\"><span class=\"comment\">% given the scale of the keypoint and the gradient magnitudes and gradient</span></div><div class=\"line\"><span class=\"comment\">% angles of the pixels in the region surrounding the keypoint.</span></div><div class=\"line\"><span class=\"comment\">%</span></div><div class=\"line\"><span class=\"comment\">% INPUT</span></div><div class=\"line\"><span class=\"comment\">% gradient_magnitudes, gradient_angles:</span></div><div class=\"line\"><span class=\"comment\">%   Two arrays of the same shape where gradient_magnitudes(i) and</span></div><div class=\"line\"><span class=\"comment\">%   gradient_angles(i) give the magnitude and direction of the gradient for</span></div><div class=\"line\"><span class=\"comment\">%   the ith point.</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">% Compute a gradient histogram using the weighted gradient magnitudes.</span></div><div class=\"line\">    <span class=\"comment\">% In David Lowe's paper he suggests using 36 bins for this histogram.</span></div><div class=\"line\">    num_bins = <span class=\"number\">36</span>;</div><div class=\"line\">    <span class=\"comment\">% Step 1:</span></div><div class=\"line\">    <span class=\"comment\">% compute the 36-bin histogram of angles using ComputeGradientHistogram()</span></div><div class=\"line\">    [histogram, angle_bound] = ComputeGradientHistogram(num_bins, gradient_magnitudes, gradient_angles);</div><div class=\"line\">    <span class=\"comment\">% Step 2:</span></div><div class=\"line\">    <span class=\"comment\">% Find the maximum value of the gradient histogram, and set \"direction\"</span></div><div class=\"line\">    <span class=\"comment\">% to the angle corresponding to the maximum. (To match our solutions,</span></div><div class=\"line\">    <span class=\"comment\">% just use the lower-bound angle of the max histogram bin. (E.g. return</span></div><div class=\"line\">    <span class=\"comment\">% 0 radians if it's bin 1.)</span></div><div class=\"line\">    [~, max_index] = max(histogram);</div><div class=\"line\">    direction = angle_bound(max_index);</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>之后，我们更新patch内各点的梯度方向，计算其与主方向的夹角，作为新的方向。并将梯度进行高斯平滑。</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">patch_theta = patch_theta - ComputeDominantDirection(patch_mag, patch_theta);;</div><div class=\"line\">patch_theta = <span class=\"built_in\">mod</span>(patch_theta, <span class=\"number\">2</span>*<span class=\"built_in\">pi</span>);</div><div class=\"line\">patch_mag = patch_mag .* fspecial(<span class=\"string\">'gaussian'</span>, patch_size, patch_size / <span class=\"number\">2</span>); <span class=\"comment\">% patch_size = 16</span></div></pre></td></tr></table></figure>\n<p>遍历cell，计算feature如下：</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">feature = [];</div><div class=\"line\">row_iter = <span class=\"number\">1</span>;</div><div class=\"line\"><span class=\"keyword\">for</span> y = <span class=\"number\">1</span>:num_histograms</div><div class=\"line\">    col_iter = <span class=\"number\">1</span>;</div><div class=\"line\">    <span class=\"keyword\">for</span> x = <span class=\"number\">1</span>:num_histograms</div><div class=\"line\">        cell_mag = patch_mag(row_iter: row_iter + pixelsPerHistogram - <span class=\"number\">1</span>, ...</div><div class=\"line\">                             col_iter: col_iter + pixelsPerHistogram - <span class=\"number\">1</span>);</div><div class=\"line\">        cell_theta = patch_theta(row_iter: row_iter + pixelsPerHistogram - <span class=\"number\">1</span>, ...</div><div class=\"line\">                             col_iter: col_iter + pixelsPerHistogram - <span class=\"number\">1</span>);</div><div class=\"line\">        [histogram, ~] = ComputeGradientHistogram(num_angles, cell_mag, cell_theta);</div><div class=\"line\">        feature = [feature, histogram];</div><div class=\"line\">        col_iter = col_iter + pixelsPerHistogram;</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\">    row_iter = row_iter + pixelsPerHistogram;</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>最后，对feature做normalization。首先将feature化为单位长度，并将其中太大的分量进行限幅（如0.2的阈值），之后再重新将其转换为单位长度。</p>\n<p>这样，就完成了SIFT特征的计算。在Lowe的论文中，有更多对实现细节的讨论，这里只是跟随课程slide和作业走完了算法流程，不再赘述。</p>\n<h2 id=\"应用：图像特征点匹配\"><a href=\"#应用：图像特征点匹配\" class=\"headerlink\" title=\"应用：图像特征点匹配\"></a>应用：图像特征点匹配</h2><p>和Harris角点一样，SIFT特征可以用作两幅图像的特征点匹配，并且具有多种变换不变性的优点。对于两幅图像分别计算得到的特征点SIFT特征向量，可以使用下面简单的方法搜寻匹配点。计算每组点对之间的欧式距离，如果最近的距离比第二近的距离小得多，那么可以认为有一对成功匹配的特征点。其MATLAB代码如下，其中<code>descriptor</code>是两幅图像的SIFT特征向量。阈值默认为取做0.7。</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">match</span> = <span class=\"title\">SIFTSimpleMatcher</span><span class=\"params\">(descriptor1, descriptor2, thresh)</span></span></div><div class=\"line\"><span class=\"comment\">% SIFTSimpleMatcher</span></div><div class=\"line\"><span class=\"comment\">%   Match one set of SIFT descriptors (descriptor1) to another set of</span></div><div class=\"line\"><span class=\"comment\">%   descriptors (decriptor2). Each descriptor from descriptor1 can at</span></div><div class=\"line\"><span class=\"comment\">%   most be matched to one member of descriptor2, but descriptors from</span></div><div class=\"line\"><span class=\"comment\">%   descriptor2 can be matched more than once.</span></div><div class=\"line\"><span class=\"comment\">%   </span></div><div class=\"line\"><span class=\"comment\">%   Matches are determined as follows:</span></div><div class=\"line\"><span class=\"comment\">%   For each descriptor vector in descriptor1, find the Euclidean distance</span></div><div class=\"line\"><span class=\"comment\">%   between it and each descriptor vector in descriptor2. If the smallest</span></div><div class=\"line\"><span class=\"comment\">%   distance is less than thresh*(the next smallest distance), we say that</span></div><div class=\"line\"><span class=\"comment\">%   the two vectors are a match, and we add the row [d1 index, d2 index] to</span></div><div class=\"line\"><span class=\"comment\">%   the \"match\" array.</span></div><div class=\"line\"><span class=\"comment\">%   </span></div><div class=\"line\"><span class=\"comment\">% INPUT:</span></div><div class=\"line\"><span class=\"comment\">%   descriptor1: N1 * 128 matrix, each row is a SIFT descriptor.</span></div><div class=\"line\"><span class=\"comment\">%   descriptor2: N2 * 128 matrix, each row is a SIFT descriptor.</span></div><div class=\"line\"><span class=\"comment\">%   thresh: a given threshold of ratio. Typically 0.7</span></div><div class=\"line\"><span class=\"comment\">%</span></div><div class=\"line\"><span class=\"comment\">% OUTPUT:</span></div><div class=\"line\"><span class=\"comment\">%   Match: N * 2 matrix, each row is a match.</span></div><div class=\"line\"><span class=\"comment\">%          For example, Match(k, :) = [i, j] means i-th descriptor in</span></div><div class=\"line\"><span class=\"comment\">%          descriptor1 is matched to j-th descriptor in descriptor2.</span></div><div class=\"line\">    <span class=\"keyword\">if</span> ~exist(<span class=\"string\">'thresh'</span>, <span class=\"string\">'var'</span>),</div><div class=\"line\">        thresh = <span class=\"number\">0.7</span>;</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\">    match = [];</div><div class=\"line\">    [N1, ~] = <span class=\"built_in\">size</span>(descriptor1);</div><div class=\"line\">    <span class=\"keyword\">for</span> <span class=\"built_in\">i</span> = <span class=\"number\">1</span>:N1</div><div class=\"line\">        fea = descriptor1(<span class=\"built_in\">i</span>, :);</div><div class=\"line\">        err = <span class=\"built_in\">bsxfun</span>(@minus, fea, descriptor2);</div><div class=\"line\">        dis = <span class=\"built_in\">sqrt</span>(sum(err.^<span class=\"number\">2</span>, <span class=\"number\">2</span>));</div><div class=\"line\">        [sorted_dis, ind] = sort(dis, <span class=\"number\">1</span>);</div><div class=\"line\">        <span class=\"keyword\">if</span> sorted_dis(<span class=\"number\">1</span>) &lt; thresh * sorted_dis(<span class=\"number\">2</span>)</div><div class=\"line\">            match = [match; [i, ind(<span class=\"number\">1</span>)]];</div><div class=\"line\">        <span class=\"keyword\">end</span></div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>接下来，我们可以使用最小二乘法计算两幅图像之间的仿射变换矩阵（齐次变换矩阵）$H$。其中$H$满足：</p>\n<script type=\"math/tex; mode=display\">Hp_{\\text{before}} = p_{\\text{after}}</script><p>其中</p>\n<script type=\"math/tex; mode=display\">p = \\begin{bmatrix}x \\\\\\\\ y \\\\\\\\ 1\\end{bmatrix}</script><p>对上式稍作变形，有</p>\n<script type=\"math/tex; mode=display\">p_{\\text{before}}^\\dagger H^\\dagger = p_{\\text{after}}\\dagger</script><p>就可以使用标准的最小二乘正则方程进行求解了。代码如下：</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">H</span> = <span class=\"title\">ComputeAffineMatrix</span><span class=\"params\">( Pt1, Pt2 )</span></span></div><div class=\"line\"><span class=\"comment\">%ComputeAffineMatrix</span></div><div class=\"line\"><span class=\"comment\">%   Computes the transformation matrix that transforms a point from</span></div><div class=\"line\"><span class=\"comment\">%   coordinate frame 1 to coordinate frame 2</span></div><div class=\"line\"><span class=\"comment\">%Input:</span></div><div class=\"line\"><span class=\"comment\">%   Pt1: N * 2 matrix, each row is a point in image 1</span></div><div class=\"line\"><span class=\"comment\">%       (N must be at least 3)</span></div><div class=\"line\"><span class=\"comment\">%   Pt2: N * 2 matrix, each row is the point in image 2 that</span></div><div class=\"line\"><span class=\"comment\">%       matches the same point in image 1 (N should be more than 3)</span></div><div class=\"line\"><span class=\"comment\">%Output:</span></div><div class=\"line\"><span class=\"comment\">%   H: 3 * 3 affine transformation matrix,</span></div><div class=\"line\"><span class=\"comment\">%       such that H*pt1(i,:) = pt2(i,:)</span></div><div class=\"line\"></div><div class=\"line\">    N = <span class=\"built_in\">size</span>(Pt1,<span class=\"number\">1</span>);</div><div class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">size</span>(Pt1, <span class=\"number\">1</span>) ~= <span class=\"built_in\">size</span>(Pt2, <span class=\"number\">1</span>),</div><div class=\"line\">        error(<span class=\"string\">'Dimensions unmatched.'</span>);</div><div class=\"line\">    <span class=\"keyword\">elseif</span> N&lt;<span class=\"number\">3</span></div><div class=\"line\">        error(<span class=\"string\">'At least 3 points are required.'</span>);</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">% Convert the input points to homogeneous coordintes.</span></div><div class=\"line\">    P1 = [Pt1<span class=\"string\">';ones(1,N)];</div><div class=\"line\">    P2 = [Pt2'</span>;ones(<span class=\"number\">1</span>,N)];</div><div class=\"line\"></div><div class=\"line\">    H = P1*P1'\\P1*P2';</div><div class=\"line\">    H = H';</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">% Sometimes numerical issues cause least-squares to produce a bottom</span></div><div class=\"line\">    <span class=\"comment\">% row which is not exactly [0 0 1], which confuses some of the later</span></div><div class=\"line\">    <span class=\"comment\">% code. So we'll ensure the bottom row is exactly [0 0 1].</span></div><div class=\"line\">    H(<span class=\"number\">3</span>,:) = [<span class=\"number\">0</span> <span class=\"number\">0</span> <span class=\"number\">1</span>];</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>作业中的其他例子也很有趣，这里不再多说了。贴上两张图像拼接的实验结果吧~<br><img src=\"/img/sift_experiment_1.png\" alt=\"result 1\"><br><img src=\"/img/sift_experiment_2.png\" alt=\"result 2\"></p>\n"},{"title":"使用 Visual Studio 编译 GSL 科学计算库","date":"2016-12-16T11:00:00.000Z","_content":"\nGSL是一个GNU支持的科学计算库，提供了很丰富的数值计算方法。[GSL 的项目主页](http://www.gnu.org/software/gsl/)提供的说明来看，它支持如下的科学计算：\n\n（下面的这张表格的HTML使用的是[No-Cruft Excel to HTML Table Converter](http://pressbin.com/tools/excel_to_html_table/index.html)生成的）\n{% raw %}\n<table>\n   <tr>\n      <td>Complex Numbers </td>\n      <td>Roots of Polynomials</td>\n   </tr>\n   <tr>\n      <td>Special Functions </td>\n      <td>Vectors and Matrices</td>\n   </tr>\n   <tr>\n      <td>Permutations </td>\n      <td>Sorting</td>\n   </tr>\n   <tr>\n      <td>BLAS Support </td>\n      <td>Linear Algebra</td>\n   </tr>\n   <tr>\n      <td>Eigensystems </td>\n      <td>Fast Fourier Transforms</td>\n   </tr>\n   <tr>\n      <td>Quadrature </td>\n      <td>Random Numbers</td>\n   </tr>\n   <tr>\n      <td>Quasi-Random Sequences </td>\n      <td>Random Distributions</td>\n   </tr>\n   <tr>\n      <td>Statistics </td>\n      <td>Histograms</td>\n   </tr>\n   <tr>\n      <td>N-Tuples </td>\n      <td>Monte Carlo Integration</td>\n   </tr>\n   <tr>\n      <td>Simulated Annealing </td>\n      <td>Differential Equations</td>\n   </tr>\n   <tr>\n      <td>Interpolation </td>\n      <td>Numerical Differentiation</td>\n   </tr>\n   <tr>\n      <td>Chebyshev Approximation </td>\n      <td>Series Acceleration</td>\n   </tr>\n   <tr>\n      <td>Discrete Hankel Transforms </td>\n      <td>Root-Finding</td>\n   </tr>\n   <tr>\n      <td>Minimization </td>\n      <td>Least-Squares Fitting</td>\n   </tr>\n   <tr>\n      <td>Physical Constants </td>\n      <td>IEEE Floating-Point</td>\n   </tr>\n   <tr>\n      <td>Discrete Wavelet Transforms </td>\n      <td>Basis splines</td>\n   </tr>\n</table>\n{% endraw %}\n\nGSL的Linux下的配置很简单，照着它的INSTALL文件一步一步来就可以了。CMAKE大法HAO!\n\n``` bash\n./configure\nmake\nmake install\nmake clean\n```\n\n同样的，GSL也可以在Windows环境下配置，下面记录了如何在Windows环境下使用 Visual Studio 和 CMakeGUI 编译测试GSL。\n\n## 使用CMAKE编译成.SLN文件\n\n打开CMAKEGUI，将输入代码路径选为GSL源代码地址，输出路径设为自己想要的输出路径。点击 “Configure“，选择Visual Studio2013为编译器，点击Finish后会进行必要的配置。然后将表格里面的选项都打上勾，再次点击”Configure“，等待完成之后点击”Generate“。完成之后，就可以在输出路径下看到GSL.sln文件了。\n\n## 使用Visual Studio生成解决方案\n\n使用 Visual Studio 打开刚才生成的.SLN文件，分别在Debug和Release模式下生成解决方案，等待完成即可。\n\n当完成后，你应该可以在路径下看到这样一张图，我们主要关注的文件夹是\\bin，\\gsl，\\Debug和\\Release。\n\n\n## 加入环境变量 \n\n修改环境变量的Path，将\\GSL_Build_Path\\bin\\Debug加入，这主要是为了\\Debug文件夹下面的gsl.dll文件。如果不进行这一步的话，一会虽然可以编译，但是却不能运行。\n\n这里顺便注释一句，当使用第三方库的时候，如果需要动态链接库的支持，其中一种方法就是将DLL文件的路径加入到Path中去。\n\n## 建立Visual Studio属性表\n\nVisual Studio可以通过建立工程属性表的方法来配置工程选项，一个OpenCV的例子可以参见Yuanbo She的这篇博文 [Opencv 完美配置攻略 2014 (Win8.1 + Opencv 2.4.8 + VS 2013)](http://my.phirobot.com/blog/2014-02-opencv_configuration_in_vs.html)。\n\n配置文件中主要是包含文件和静态链接库LIB的路径设置。下面把我的贴出来，只需要根据GSL的生成路径做相应修改即可。注意我的属性表中保留了OpenCV的内容，如果不需要的话，尽可以删掉。上面的博文对这张属性表如何配置讲得很清楚，有问题可以去参考。\n\n``` html\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<Project ToolsVersion=\"4.0\" xmlns=\"http://schemas.microsoft.com/developer/msbuild/2003\">\n  <ImportGroup Label=\"PropertySheets\" />\n  <PropertyGroup Label=\"UserMacros\" />\n  <PropertyGroup>\n        <IncludePath>$(OPENCV249)\\include;E:\\GSLCode\\gsl-build\\;$(IncludePath)</IncludePath>\n        <LibraryPath Condition=\"'$(Platform)'=='Win32'\">$(OPENCV249)\\x86\\vc12\\lib;E:\\GSLCode\\gsl-build\\Debug;$(LibraryPath)</LibraryPath>\n        <LibraryPath Condition=\"'$(Platform)'=='X64'\">$(OPENCV249)\\x64\\vc12\\lib;E:\\GSLCode\\gsl-build\\Debug;$(LibraryPath)</LibraryPath>\n  </PropertyGroup>\n  <ItemDefinitionGroup>\n        <Link Condition=\"'$(Configuration)'=='Debug'\">\n          <AdditionalDependencies>opencv_calib3d249d.lib;opencv_contrib249d.lib;opencv_core249d.lib;opencv_features2d249d.lib;opencv_flann249d.lib;opencv_gpu249d.lib;opencv_highgui249d.lib;opencv_imgproc249d.lib;opencv_legacy249d.lib;opencv_ml249d.lib;opencv_nonfree249d.lib;opencv_objdetect249d.lib;opencv_ocl249d.lib;opencv_photo249d.lib;opencv_stitching249d.lib;opencv_superres249d.lib;opencv_ts249d.lib;opencv_video249d.lib;opencv_videostab249d.lib;gsl.lib;gslcblas.lib;%(AdditionalDependencies)</AdditionalDependencies>\n        </Link>\n        <Link Condition=\"'$(Configuration)'=='Release'\">\n          <AdditionalDependencies>opencv_calib3d249.lib;opencv_contrib249.lib;opencv_core249.lib;opencv_features2d249.lib;opencv_flann249.lib;opencv_gpu249.lib;opencv_highgui249.lib;opencv_imgproc249.lib;opencv_legacy249.lib;opencv_ml249.lib;opencv_nonfree249.lib;opencv_objdetect249.lib;opencv_ocl249.lib;opencv_photo249.lib;opencv_stitching249.lib;opencv_superres249.lib;opencv_ts249.lib;opencv_video249.lib;opencv_videostab249.lib;gsl.lib;gslcblas.lib;%(AdditionalDependencies)</AdditionalDependencies>\n        </Link>\n  </ItemDefinitionGroup>\n  <ItemGroup />\n</Project>\n```\n\n在以后建立Visual Studio工程的时候，在属性窗口直接添加现有属性表就可以了！\n\n## 测试\n\n在项目网站的教程上直接找到一段代码，进行测试，输出贝塞尔函数的值。\n\n\n``` cpp\n#include <stdio.h>\n#include <gsl/gsl_sf_bessel.h>\nint main(void)\n{\n\tdouble x = 5.0;\n\tdouble y = gsl_sf_bessel_J0(x);\n\tprintf(\"J0(%g) = %.18e\\n\", x, y);\n\treturn 0;\n}\n```\n\n控制台输出正确：\n{% raw %}\n<p><img src=\"http://i.imgur.com/uXhVvwS.jpg\" width=\"600\" height=\"200\"></p>\n{% endraw %}\n","source":"_posts/gsl-with-vs.md","raw":"---\ntitle: 使用 Visual Studio 编译 GSL 科学计算库\ndate: 2016-12-16 19:00:00\ntags: \n    - tool\n    - gsl\n---\n\nGSL是一个GNU支持的科学计算库，提供了很丰富的数值计算方法。[GSL 的项目主页](http://www.gnu.org/software/gsl/)提供的说明来看，它支持如下的科学计算：\n\n（下面的这张表格的HTML使用的是[No-Cruft Excel to HTML Table Converter](http://pressbin.com/tools/excel_to_html_table/index.html)生成的）\n{% raw %}\n<table>\n   <tr>\n      <td>Complex Numbers </td>\n      <td>Roots of Polynomials</td>\n   </tr>\n   <tr>\n      <td>Special Functions </td>\n      <td>Vectors and Matrices</td>\n   </tr>\n   <tr>\n      <td>Permutations </td>\n      <td>Sorting</td>\n   </tr>\n   <tr>\n      <td>BLAS Support </td>\n      <td>Linear Algebra</td>\n   </tr>\n   <tr>\n      <td>Eigensystems </td>\n      <td>Fast Fourier Transforms</td>\n   </tr>\n   <tr>\n      <td>Quadrature </td>\n      <td>Random Numbers</td>\n   </tr>\n   <tr>\n      <td>Quasi-Random Sequences </td>\n      <td>Random Distributions</td>\n   </tr>\n   <tr>\n      <td>Statistics </td>\n      <td>Histograms</td>\n   </tr>\n   <tr>\n      <td>N-Tuples </td>\n      <td>Monte Carlo Integration</td>\n   </tr>\n   <tr>\n      <td>Simulated Annealing </td>\n      <td>Differential Equations</td>\n   </tr>\n   <tr>\n      <td>Interpolation </td>\n      <td>Numerical Differentiation</td>\n   </tr>\n   <tr>\n      <td>Chebyshev Approximation </td>\n      <td>Series Acceleration</td>\n   </tr>\n   <tr>\n      <td>Discrete Hankel Transforms </td>\n      <td>Root-Finding</td>\n   </tr>\n   <tr>\n      <td>Minimization </td>\n      <td>Least-Squares Fitting</td>\n   </tr>\n   <tr>\n      <td>Physical Constants </td>\n      <td>IEEE Floating-Point</td>\n   </tr>\n   <tr>\n      <td>Discrete Wavelet Transforms </td>\n      <td>Basis splines</td>\n   </tr>\n</table>\n{% endraw %}\n\nGSL的Linux下的配置很简单，照着它的INSTALL文件一步一步来就可以了。CMAKE大法HAO!\n\n``` bash\n./configure\nmake\nmake install\nmake clean\n```\n\n同样的，GSL也可以在Windows环境下配置，下面记录了如何在Windows环境下使用 Visual Studio 和 CMakeGUI 编译测试GSL。\n\n## 使用CMAKE编译成.SLN文件\n\n打开CMAKEGUI，将输入代码路径选为GSL源代码地址，输出路径设为自己想要的输出路径。点击 “Configure“，选择Visual Studio2013为编译器，点击Finish后会进行必要的配置。然后将表格里面的选项都打上勾，再次点击”Configure“，等待完成之后点击”Generate“。完成之后，就可以在输出路径下看到GSL.sln文件了。\n\n## 使用Visual Studio生成解决方案\n\n使用 Visual Studio 打开刚才生成的.SLN文件，分别在Debug和Release模式下生成解决方案，等待完成即可。\n\n当完成后，你应该可以在路径下看到这样一张图，我们主要关注的文件夹是\\bin，\\gsl，\\Debug和\\Release。\n\n\n## 加入环境变量 \n\n修改环境变量的Path，将\\GSL_Build_Path\\bin\\Debug加入，这主要是为了\\Debug文件夹下面的gsl.dll文件。如果不进行这一步的话，一会虽然可以编译，但是却不能运行。\n\n这里顺便注释一句，当使用第三方库的时候，如果需要动态链接库的支持，其中一种方法就是将DLL文件的路径加入到Path中去。\n\n## 建立Visual Studio属性表\n\nVisual Studio可以通过建立工程属性表的方法来配置工程选项，一个OpenCV的例子可以参见Yuanbo She的这篇博文 [Opencv 完美配置攻略 2014 (Win8.1 + Opencv 2.4.8 + VS 2013)](http://my.phirobot.com/blog/2014-02-opencv_configuration_in_vs.html)。\n\n配置文件中主要是包含文件和静态链接库LIB的路径设置。下面把我的贴出来，只需要根据GSL的生成路径做相应修改即可。注意我的属性表中保留了OpenCV的内容，如果不需要的话，尽可以删掉。上面的博文对这张属性表如何配置讲得很清楚，有问题可以去参考。\n\n``` html\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<Project ToolsVersion=\"4.0\" xmlns=\"http://schemas.microsoft.com/developer/msbuild/2003\">\n  <ImportGroup Label=\"PropertySheets\" />\n  <PropertyGroup Label=\"UserMacros\" />\n  <PropertyGroup>\n        <IncludePath>$(OPENCV249)\\include;E:\\GSLCode\\gsl-build\\;$(IncludePath)</IncludePath>\n        <LibraryPath Condition=\"'$(Platform)'=='Win32'\">$(OPENCV249)\\x86\\vc12\\lib;E:\\GSLCode\\gsl-build\\Debug;$(LibraryPath)</LibraryPath>\n        <LibraryPath Condition=\"'$(Platform)'=='X64'\">$(OPENCV249)\\x64\\vc12\\lib;E:\\GSLCode\\gsl-build\\Debug;$(LibraryPath)</LibraryPath>\n  </PropertyGroup>\n  <ItemDefinitionGroup>\n        <Link Condition=\"'$(Configuration)'=='Debug'\">\n          <AdditionalDependencies>opencv_calib3d249d.lib;opencv_contrib249d.lib;opencv_core249d.lib;opencv_features2d249d.lib;opencv_flann249d.lib;opencv_gpu249d.lib;opencv_highgui249d.lib;opencv_imgproc249d.lib;opencv_legacy249d.lib;opencv_ml249d.lib;opencv_nonfree249d.lib;opencv_objdetect249d.lib;opencv_ocl249d.lib;opencv_photo249d.lib;opencv_stitching249d.lib;opencv_superres249d.lib;opencv_ts249d.lib;opencv_video249d.lib;opencv_videostab249d.lib;gsl.lib;gslcblas.lib;%(AdditionalDependencies)</AdditionalDependencies>\n        </Link>\n        <Link Condition=\"'$(Configuration)'=='Release'\">\n          <AdditionalDependencies>opencv_calib3d249.lib;opencv_contrib249.lib;opencv_core249.lib;opencv_features2d249.lib;opencv_flann249.lib;opencv_gpu249.lib;opencv_highgui249.lib;opencv_imgproc249.lib;opencv_legacy249.lib;opencv_ml249.lib;opencv_nonfree249.lib;opencv_objdetect249.lib;opencv_ocl249.lib;opencv_photo249.lib;opencv_stitching249.lib;opencv_superres249.lib;opencv_ts249.lib;opencv_video249.lib;opencv_videostab249.lib;gsl.lib;gslcblas.lib;%(AdditionalDependencies)</AdditionalDependencies>\n        </Link>\n  </ItemDefinitionGroup>\n  <ItemGroup />\n</Project>\n```\n\n在以后建立Visual Studio工程的时候，在属性窗口直接添加现有属性表就可以了！\n\n## 测试\n\n在项目网站的教程上直接找到一段代码，进行测试，输出贝塞尔函数的值。\n\n\n``` cpp\n#include <stdio.h>\n#include <gsl/gsl_sf_bessel.h>\nint main(void)\n{\n\tdouble x = 5.0;\n\tdouble y = gsl_sf_bessel_J0(x);\n\tprintf(\"J0(%g) = %.18e\\n\", x, y);\n\treturn 0;\n}\n```\n\n控制台输出正确：\n{% raw %}\n<p><img src=\"http://i.imgur.com/uXhVvwS.jpg\" width=\"600\" height=\"200\"></p>\n{% endraw %}\n","slug":"gsl-with-vs","published":1,"updated":"2017-02-01T15:10:29.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciyof8h0x0008cq1hpi4kmgl4","content":"<p>GSL是一个GNU支持的科学计算库，提供了很丰富的数值计算方法。<a href=\"http://www.gnu.org/software/gsl/\" target=\"_blank\" rel=\"external\">GSL 的项目主页</a>提供的说明来看，它支持如下的科学计算：</p>\n<p>（下面的这张表格的HTML使用的是<a href=\"http://pressbin.com/tools/excel_to_html_table/index.html\" target=\"_blank\" rel=\"external\">No-Cruft Excel to HTML Table Converter</a>生成的）<br>\n<table>\n   <tr>\n      <td>Complex Numbers </td>\n      <td>Roots of Polynomials</td>\n   </tr>\n   <tr>\n      <td>Special Functions </td>\n      <td>Vectors and Matrices</td>\n   </tr>\n   <tr>\n      <td>Permutations </td>\n      <td>Sorting</td>\n   </tr>\n   <tr>\n      <td>BLAS Support </td>\n      <td>Linear Algebra</td>\n   </tr>\n   <tr>\n      <td>Eigensystems </td>\n      <td>Fast Fourier Transforms</td>\n   </tr>\n   <tr>\n      <td>Quadrature </td>\n      <td>Random Numbers</td>\n   </tr>\n   <tr>\n      <td>Quasi-Random Sequences </td>\n      <td>Random Distributions</td>\n   </tr>\n   <tr>\n      <td>Statistics </td>\n      <td>Histograms</td>\n   </tr>\n   <tr>\n      <td>N-Tuples </td>\n      <td>Monte Carlo Integration</td>\n   </tr>\n   <tr>\n      <td>Simulated Annealing </td>\n      <td>Differential Equations</td>\n   </tr>\n   <tr>\n      <td>Interpolation </td>\n      <td>Numerical Differentiation</td>\n   </tr>\n   <tr>\n      <td>Chebyshev Approximation </td>\n      <td>Series Acceleration</td>\n   </tr>\n   <tr>\n      <td>Discrete Hankel Transforms </td>\n      <td>Root-Finding</td>\n   </tr>\n   <tr>\n      <td>Minimization </td>\n      <td>Least-Squares Fitting</td>\n   </tr>\n   <tr>\n      <td>Physical Constants </td>\n      <td>IEEE Floating-Point</td>\n   </tr>\n   <tr>\n      <td>Discrete Wavelet Transforms </td>\n      <td>Basis splines</td>\n   </tr>\n</table>\n</p>\n<p>GSL的Linux下的配置很简单，照着它的INSTALL文件一步一步来就可以了。CMAKE大法HAO!</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">make install</div><div class=\"line\">make clean</div></pre></td></tr></table></figure>\n<p>同样的，GSL也可以在Windows环境下配置，下面记录了如何在Windows环境下使用 Visual Studio 和 CMakeGUI 编译测试GSL。</p>\n<h2 id=\"使用CMAKE编译成-SLN文件\"><a href=\"#使用CMAKE编译成-SLN文件\" class=\"headerlink\" title=\"使用CMAKE编译成.SLN文件\"></a>使用CMAKE编译成.SLN文件</h2><p>打开CMAKEGUI，将输入代码路径选为GSL源代码地址，输出路径设为自己想要的输出路径。点击 “Configure“，选择Visual Studio2013为编译器，点击Finish后会进行必要的配置。然后将表格里面的选项都打上勾，再次点击”Configure“，等待完成之后点击”Generate“。完成之后，就可以在输出路径下看到GSL.sln文件了。</p>\n<h2 id=\"使用Visual-Studio生成解决方案\"><a href=\"#使用Visual-Studio生成解决方案\" class=\"headerlink\" title=\"使用Visual Studio生成解决方案\"></a>使用Visual Studio生成解决方案</h2><p>使用 Visual Studio 打开刚才生成的.SLN文件，分别在Debug和Release模式下生成解决方案，等待完成即可。</p>\n<p>当完成后，你应该可以在路径下看到这样一张图，我们主要关注的文件夹是\\bin，\\gsl，\\Debug和\\Release。</p>\n<h2 id=\"加入环境变量\"><a href=\"#加入环境变量\" class=\"headerlink\" title=\"加入环境变量\"></a>加入环境变量</h2><p>修改环境变量的Path，将\\GSL_Build_Path\\bin\\Debug加入，这主要是为了\\Debug文件夹下面的gsl.dll文件。如果不进行这一步的话，一会虽然可以编译，但是却不能运行。</p>\n<p>这里顺便注释一句，当使用第三方库的时候，如果需要动态链接库的支持，其中一种方法就是将DLL文件的路径加入到Path中去。</p>\n<h2 id=\"建立Visual-Studio属性表\"><a href=\"#建立Visual-Studio属性表\" class=\"headerlink\" title=\"建立Visual Studio属性表\"></a>建立Visual Studio属性表</h2><p>Visual Studio可以通过建立工程属性表的方法来配置工程选项，一个OpenCV的例子可以参见Yuanbo She的这篇博文 <a href=\"http://my.phirobot.com/blog/2014-02-opencv_configuration_in_vs.html\" target=\"_blank\" rel=\"external\">Opencv 完美配置攻略 2014 (Win8.1 + Opencv 2.4.8 + VS 2013)</a>。</p>\n<p>配置文件中主要是包含文件和静态链接库LIB的路径设置。下面把我的贴出来，只需要根据GSL的生成路径做相应修改即可。注意我的属性表中保留了OpenCV的内容，如果不需要的话，尽可以删掉。上面的博文对这张属性表如何配置讲得很清楚，有问题可以去参考。</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;</div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Project</span> <span class=\"attr\">ToolsVersion</span>=<span class=\"string\">\"4.0\"</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://schemas.microsoft.com/developer/msbuild/2003\"</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">ImportGroup</span> <span class=\"attr\">Label</span>=<span class=\"string\">\"PropertySheets\"</span> /&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">PropertyGroup</span> <span class=\"attr\">Label</span>=<span class=\"string\">\"UserMacros\"</span> /&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">PropertyGroup</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">IncludePath</span>&gt;</span>$(OPENCV249)\\include;E:\\GSLCode\\gsl-build\\;$(IncludePath)<span class=\"tag\">&lt;/<span class=\"name\">IncludePath</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">LibraryPath</span> <span class=\"attr\">Condition</span>=<span class=\"string\">\"'$(Platform)'=='Win32'\"</span>&gt;</span>$(OPENCV249)\\x86\\vc12\\lib;E:\\GSLCode\\gsl-build\\Debug;$(LibraryPath)<span class=\"tag\">&lt;/<span class=\"name\">LibraryPath</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">LibraryPath</span> <span class=\"attr\">Condition</span>=<span class=\"string\">\"'$(Platform)'=='X64'\"</span>&gt;</span>$(OPENCV249)\\x64\\vc12\\lib;E:\\GSLCode\\gsl-build\\Debug;$(LibraryPath)<span class=\"tag\">&lt;/<span class=\"name\">LibraryPath</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">PropertyGroup</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">ItemDefinitionGroup</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">Link</span> <span class=\"attr\">Condition</span>=<span class=\"string\">\"'$(Configuration)'=='Debug'\"</span>&gt;</span></div><div class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">AdditionalDependencies</span>&gt;</span>opencv_calib3d249d.lib;opencv_contrib249d.lib;opencv_core249d.lib;opencv_features2d249d.lib;opencv_flann249d.lib;opencv_gpu249d.lib;opencv_highgui249d.lib;opencv_imgproc249d.lib;opencv_legacy249d.lib;opencv_ml249d.lib;opencv_nonfree249d.lib;opencv_objdetect249d.lib;opencv_ocl249d.lib;opencv_photo249d.lib;opencv_stitching249d.lib;opencv_superres249d.lib;opencv_ts249d.lib;opencv_video249d.lib;opencv_videostab249d.lib;gsl.lib;gslcblas.lib;%(AdditionalDependencies)<span class=\"tag\">&lt;/<span class=\"name\">AdditionalDependencies</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">Link</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">Link</span> <span class=\"attr\">Condition</span>=<span class=\"string\">\"'$(Configuration)'=='Release'\"</span>&gt;</span></div><div class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">AdditionalDependencies</span>&gt;</span>opencv_calib3d249.lib;opencv_contrib249.lib;opencv_core249.lib;opencv_features2d249.lib;opencv_flann249.lib;opencv_gpu249.lib;opencv_highgui249.lib;opencv_imgproc249.lib;opencv_legacy249.lib;opencv_ml249.lib;opencv_nonfree249.lib;opencv_objdetect249.lib;opencv_ocl249.lib;opencv_photo249.lib;opencv_stitching249.lib;opencv_superres249.lib;opencv_ts249.lib;opencv_video249.lib;opencv_videostab249.lib;gsl.lib;gslcblas.lib;%(AdditionalDependencies)<span class=\"tag\">&lt;/<span class=\"name\">AdditionalDependencies</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">Link</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">ItemDefinitionGroup</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">ItemGroup</span> /&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">Project</span>&gt;</span></div></pre></td></tr></table></figure>\n<p>在以后建立Visual Studio工程的时候，在属性窗口直接添加现有属性表就可以了！</p>\n<h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h2><p>在项目网站的教程上直接找到一段代码，进行测试，输出贝塞尔函数的值。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;gsl/gsl_sf_bessel.h&gt;</span></span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">\t<span class=\"keyword\">double</span> x = <span class=\"number\">5.0</span>;</div><div class=\"line\">\t<span class=\"keyword\">double</span> y = gsl_sf_bessel_J0(x);</div><div class=\"line\">\t<span class=\"built_in\">printf</span>(<span class=\"string\">\"J0(%g) = %.18e\\n\"</span>, x, y);</div><div class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>控制台输出正确：<br>\n</p><p><img src=\"http://i.imgur.com/uXhVvwS.jpg\" width=\"600\" height=\"200\"></p>\n<p></p>\n","excerpt":"","more":"<p>GSL是一个GNU支持的科学计算库，提供了很丰富的数值计算方法。<a href=\"http://www.gnu.org/software/gsl/\">GSL 的项目主页</a>提供的说明来看，它支持如下的科学计算：</p>\n<p>（下面的这张表格的HTML使用的是<a href=\"http://pressbin.com/tools/excel_to_html_table/index.html\">No-Cruft Excel to HTML Table Converter</a>生成的）<br>\n<table>\n   <tr>\n      <td>Complex Numbers </td>\n      <td>Roots of Polynomials</td>\n   </tr>\n   <tr>\n      <td>Special Functions </td>\n      <td>Vectors and Matrices</td>\n   </tr>\n   <tr>\n      <td>Permutations </td>\n      <td>Sorting</td>\n   </tr>\n   <tr>\n      <td>BLAS Support </td>\n      <td>Linear Algebra</td>\n   </tr>\n   <tr>\n      <td>Eigensystems </td>\n      <td>Fast Fourier Transforms</td>\n   </tr>\n   <tr>\n      <td>Quadrature </td>\n      <td>Random Numbers</td>\n   </tr>\n   <tr>\n      <td>Quasi-Random Sequences </td>\n      <td>Random Distributions</td>\n   </tr>\n   <tr>\n      <td>Statistics </td>\n      <td>Histograms</td>\n   </tr>\n   <tr>\n      <td>N-Tuples </td>\n      <td>Monte Carlo Integration</td>\n   </tr>\n   <tr>\n      <td>Simulated Annealing </td>\n      <td>Differential Equations</td>\n   </tr>\n   <tr>\n      <td>Interpolation </td>\n      <td>Numerical Differentiation</td>\n   </tr>\n   <tr>\n      <td>Chebyshev Approximation </td>\n      <td>Series Acceleration</td>\n   </tr>\n   <tr>\n      <td>Discrete Hankel Transforms </td>\n      <td>Root-Finding</td>\n   </tr>\n   <tr>\n      <td>Minimization </td>\n      <td>Least-Squares Fitting</td>\n   </tr>\n   <tr>\n      <td>Physical Constants </td>\n      <td>IEEE Floating-Point</td>\n   </tr>\n   <tr>\n      <td>Discrete Wavelet Transforms </td>\n      <td>Basis splines</td>\n   </tr>\n</table>\n</p>\n<p>GSL的Linux下的配置很简单，照着它的INSTALL文件一步一步来就可以了。CMAKE大法HAO!</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">make install</div><div class=\"line\">make clean</div></pre></td></tr></table></figure>\n<p>同样的，GSL也可以在Windows环境下配置，下面记录了如何在Windows环境下使用 Visual Studio 和 CMakeGUI 编译测试GSL。</p>\n<h2 id=\"使用CMAKE编译成-SLN文件\"><a href=\"#使用CMAKE编译成-SLN文件\" class=\"headerlink\" title=\"使用CMAKE编译成.SLN文件\"></a>使用CMAKE编译成.SLN文件</h2><p>打开CMAKEGUI，将输入代码路径选为GSL源代码地址，输出路径设为自己想要的输出路径。点击 “Configure“，选择Visual Studio2013为编译器，点击Finish后会进行必要的配置。然后将表格里面的选项都打上勾，再次点击”Configure“，等待完成之后点击”Generate“。完成之后，就可以在输出路径下看到GSL.sln文件了。</p>\n<h2 id=\"使用Visual-Studio生成解决方案\"><a href=\"#使用Visual-Studio生成解决方案\" class=\"headerlink\" title=\"使用Visual Studio生成解决方案\"></a>使用Visual Studio生成解决方案</h2><p>使用 Visual Studio 打开刚才生成的.SLN文件，分别在Debug和Release模式下生成解决方案，等待完成即可。</p>\n<p>当完成后，你应该可以在路径下看到这样一张图，我们主要关注的文件夹是\\bin，\\gsl，\\Debug和\\Release。</p>\n<h2 id=\"加入环境变量\"><a href=\"#加入环境变量\" class=\"headerlink\" title=\"加入环境变量\"></a>加入环境变量</h2><p>修改环境变量的Path，将\\GSL_Build_Path\\bin\\Debug加入，这主要是为了\\Debug文件夹下面的gsl.dll文件。如果不进行这一步的话，一会虽然可以编译，但是却不能运行。</p>\n<p>这里顺便注释一句，当使用第三方库的时候，如果需要动态链接库的支持，其中一种方法就是将DLL文件的路径加入到Path中去。</p>\n<h2 id=\"建立Visual-Studio属性表\"><a href=\"#建立Visual-Studio属性表\" class=\"headerlink\" title=\"建立Visual Studio属性表\"></a>建立Visual Studio属性表</h2><p>Visual Studio可以通过建立工程属性表的方法来配置工程选项，一个OpenCV的例子可以参见Yuanbo She的这篇博文 <a href=\"http://my.phirobot.com/blog/2014-02-opencv_configuration_in_vs.html\">Opencv 完美配置攻略 2014 (Win8.1 + Opencv 2.4.8 + VS 2013)</a>。</p>\n<p>配置文件中主要是包含文件和静态链接库LIB的路径设置。下面把我的贴出来，只需要根据GSL的生成路径做相应修改即可。注意我的属性表中保留了OpenCV的内容，如果不需要的话，尽可以删掉。上面的博文对这张属性表如何配置讲得很清楚，有问题可以去参考。</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;</div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Project</span> <span class=\"attr\">ToolsVersion</span>=<span class=\"string\">\"4.0\"</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://schemas.microsoft.com/developer/msbuild/2003\"</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">ImportGroup</span> <span class=\"attr\">Label</span>=<span class=\"string\">\"PropertySheets\"</span> /&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">PropertyGroup</span> <span class=\"attr\">Label</span>=<span class=\"string\">\"UserMacros\"</span> /&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">PropertyGroup</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">IncludePath</span>&gt;</span>$(OPENCV249)\\include;E:\\GSLCode\\gsl-build\\;$(IncludePath)<span class=\"tag\">&lt;/<span class=\"name\">IncludePath</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">LibraryPath</span> <span class=\"attr\">Condition</span>=<span class=\"string\">\"'$(Platform)'=='Win32'\"</span>&gt;</span>$(OPENCV249)\\x86\\vc12\\lib;E:\\GSLCode\\gsl-build\\Debug;$(LibraryPath)<span class=\"tag\">&lt;/<span class=\"name\">LibraryPath</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">LibraryPath</span> <span class=\"attr\">Condition</span>=<span class=\"string\">\"'$(Platform)'=='X64'\"</span>&gt;</span>$(OPENCV249)\\x64\\vc12\\lib;E:\\GSLCode\\gsl-build\\Debug;$(LibraryPath)<span class=\"tag\">&lt;/<span class=\"name\">LibraryPath</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">PropertyGroup</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">ItemDefinitionGroup</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">Link</span> <span class=\"attr\">Condition</span>=<span class=\"string\">\"'$(Configuration)'=='Debug'\"</span>&gt;</span></div><div class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">AdditionalDependencies</span>&gt;</span>opencv_calib3d249d.lib;opencv_contrib249d.lib;opencv_core249d.lib;opencv_features2d249d.lib;opencv_flann249d.lib;opencv_gpu249d.lib;opencv_highgui249d.lib;opencv_imgproc249d.lib;opencv_legacy249d.lib;opencv_ml249d.lib;opencv_nonfree249d.lib;opencv_objdetect249d.lib;opencv_ocl249d.lib;opencv_photo249d.lib;opencv_stitching249d.lib;opencv_superres249d.lib;opencv_ts249d.lib;opencv_video249d.lib;opencv_videostab249d.lib;gsl.lib;gslcblas.lib;%(AdditionalDependencies)<span class=\"tag\">&lt;/<span class=\"name\">AdditionalDependencies</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">Link</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">Link</span> <span class=\"attr\">Condition</span>=<span class=\"string\">\"'$(Configuration)'=='Release'\"</span>&gt;</span></div><div class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">AdditionalDependencies</span>&gt;</span>opencv_calib3d249.lib;opencv_contrib249.lib;opencv_core249.lib;opencv_features2d249.lib;opencv_flann249.lib;opencv_gpu249.lib;opencv_highgui249.lib;opencv_imgproc249.lib;opencv_legacy249.lib;opencv_ml249.lib;opencv_nonfree249.lib;opencv_objdetect249.lib;opencv_ocl249.lib;opencv_photo249.lib;opencv_stitching249.lib;opencv_superres249.lib;opencv_ts249.lib;opencv_video249.lib;opencv_videostab249.lib;gsl.lib;gslcblas.lib;%(AdditionalDependencies)<span class=\"tag\">&lt;/<span class=\"name\">AdditionalDependencies</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">Link</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">ItemDefinitionGroup</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">ItemGroup</span> /&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">Project</span>&gt;</span></div></pre></td></tr></table></figure>\n<p>在以后建立Visual Studio工程的时候，在属性窗口直接添加现有属性表就可以了！</p>\n<h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h2><p>在项目网站的教程上直接找到一段代码，进行测试，输出贝塞尔函数的值。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;gsl/gsl_sf_bessel.h&gt;</span></span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">\t<span class=\"keyword\">double</span> x = <span class=\"number\">5.0</span>;</div><div class=\"line\">\t<span class=\"keyword\">double</span> y = gsl_sf_bessel_J0(x);</div><div class=\"line\">\t<span class=\"built_in\">printf</span>(<span class=\"string\">\"J0(%g) = %.18e\\n\"</span>, x, y);</div><div class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>控制台输出正确：<br>\n<p><img src=\"http://i.imgur.com/uXhVvwS.jpg\" width=\"600\" height=\"200\"></p>\n</p>\n"},{"title":"Hello World","date":"2016-12-16T11:00:00.000Z","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n\n### Code highlight\n\nHello World!\n\n``` cpp\n#include <iostream>\nint main() {\n    std::cout << \"HelloWorld\\n\";\n}\n```\n\n``` py\nprint 'HelloWorld'\n```\n\n### Latex Support by Mathjax\n\nMass-energy equation by Einstein: $E = mc^2$\n\na linear equation:\n    $$\\mathbf{A}\\mathbf{v} = \\mathbf{y}$$\n\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\ndate: 2016-12-16 19:00:00\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n\n### Code highlight\n\nHello World!\n\n``` cpp\n#include <iostream>\nint main() {\n    std::cout << \"HelloWorld\\n\";\n}\n```\n\n``` py\nprint 'HelloWorld'\n```\n\n### Latex Support by Mathjax\n\nMass-energy equation by Einstein: $E = mc^2$\n\na linear equation:\n    $$\\mathbf{A}\\mathbf{v} = \\mathbf{y}$$\n\n","slug":"hello-world","published":1,"updated":"2017-02-01T15:10:29.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciyof8h16000bcq1hyehjdduk","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"external\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"external\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"external\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"external\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"external\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo server</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"external\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo generate</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"external\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo deploy</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"external\">Deployment</a></p>\n<h3 id=\"Code-highlight\"><a href=\"#Code-highlight\" class=\"headerlink\" title=\"Code highlight\"></a>Code highlight</h3><p>Hello World!</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"HelloWorld\\n\"</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">print</span> <span class=\"string\">'HelloWorld'</span></div></pre></td></tr></table></figure>\n<h3 id=\"Latex-Support-by-Mathjax\"><a href=\"#Latex-Support-by-Mathjax\" class=\"headerlink\" title=\"Latex Support by Mathjax\"></a>Latex Support by Mathjax</h3><p>Mass-energy equation by Einstein: $E = mc^2$</p>\n<p>a linear equation:</p>\n<pre><code>$$\\mathbf{A}\\mathbf{v} = \\mathbf{y}$$\n</code></pre>","excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo server</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo generate</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo deploy</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\">Deployment</a></p>\n<h3 id=\"Code-highlight\"><a href=\"#Code-highlight\" class=\"headerlink\" title=\"Code highlight\"></a>Code highlight</h3><p>Hello World!</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"HelloWorld\\n\"</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">print</span> <span class=\"string\">'HelloWorld'</span></div></pre></td></tr></table></figure>\n<h3 id=\"Latex-Support-by-Mathjax\"><a href=\"#Latex-Support-by-Mathjax\" class=\"headerlink\" title=\"Latex Support by Mathjax\"></a>Latex Support by Mathjax</h3><p>Mass-energy equation by Einstein: $E = mc^2$</p>\n<p>a linear equation:</p>\n<pre><code>$$\\mathbf{A}\\mathbf{v} = \\mathbf{y}$$\n</code></pre>"},{"title":"Windows环境下使用Doxygen生成注释文档","date":"2016-12-16T11:00:00.000Z","_content":"\nDoxygen 是一种很好用的代码注释生成工具，然而和很多国外的工具软件一样，在中文环境下，它的使用总是会出现一些问题，也就是中文注释文档出现乱码。经过调试，终于是解决了这个问题。\n\n## 安装 Doxygen\n\nDoxygen 在Windows平台下的安装是简单的，[Doxygen的项目主页](http://www.doxygen.nl/)提供了下载和安装的使用说明，可以下载它们的官方使用手册进行阅读。对于Windows，提供了源代码编译安装和直接安装程序安装两种方式，可以自行选择。\n\n安装成功后，使用命令行命令\n\n``` bash\ndoxygen --help\n```\n\n就可以查看帮助文档，对应参数含义一目了然，降低了入手难度。\n\n使用命令，\n\n\n``` bash\ndoxygen -g doxygen_filename\n```\n\n就可以在当前目录下建立一个doxygen配置文件，用文本编辑器打开就可以编辑里面的配置选项。\n\n使用命令，\n\n``` bash\ndoxygen doxygen_filename\n```\n\n就可以生成注释文档了。\n\n下面就来说一说对中文的支持。\n\n## 生成 HTML 格式文档\n\n中文之所以乱码，很多时候是由于编码和译码格式不同，所以我们需要先知道自己代码文件的编码方式。我的代码都是建立在Visual Studio上的，可以通过VS的高级保存选项查看自己代码文件的存储编码格式。对于中文版的VS，一般应该是GB2312。\n\n我们打开 Doxygen 的配置文件，将里面的 INPUT_ENCODING 改为我们代码文件的编码格式，这里就改成 GB2312。\n\n这样一来，编译出来的 HTML 页面就不会有中文乱码了。\n\n## 生成Latex 格式文档\n\n生成 Latex 需要本机上安装有 Latex 的编译环境。如果是中文用户，推荐的是CTEX套件，可以到他们的网站上去下载。\n\n可以看到，Doxygen为Latex文件的编译生成了make文件，我们在命令行窗口中执行make命令就可以完成编译，然而这时候会发现编译出错，pdf文档无法生成。\n\n打开生成的refman.latex文档，添加宏包 CJKutf8。然后找到 `\\begin{document}`一行，将其改为\n\n``` latex\n\\begin{document}\n\\begin{CJK}{UTF8}{gbsn} \n```\n\n也就是说为正文提供了CJK环境，这样中文文本就可以正常编译了。\n\n相应的，我们要将结尾的 `\\end{document)`改为：\n``` latex\n\\end{CJK} \n\\end{document}\n```\n\n这样，运行make命令之后，就可以看到中文的注释文档了。\n","source":"_posts/use-doxygen.md","raw":"---\ntitle: Windows环境下使用Doxygen生成注释文档\ndate: 2016-12-16 19:00:00\ntags: \n    - tool\n    - doxygen\n---\n\nDoxygen 是一种很好用的代码注释生成工具，然而和很多国外的工具软件一样，在中文环境下，它的使用总是会出现一些问题，也就是中文注释文档出现乱码。经过调试，终于是解决了这个问题。\n\n## 安装 Doxygen\n\nDoxygen 在Windows平台下的安装是简单的，[Doxygen的项目主页](http://www.doxygen.nl/)提供了下载和安装的使用说明，可以下载它们的官方使用手册进行阅读。对于Windows，提供了源代码编译安装和直接安装程序安装两种方式，可以自行选择。\n\n安装成功后，使用命令行命令\n\n``` bash\ndoxygen --help\n```\n\n就可以查看帮助文档，对应参数含义一目了然，降低了入手难度。\n\n使用命令，\n\n\n``` bash\ndoxygen -g doxygen_filename\n```\n\n就可以在当前目录下建立一个doxygen配置文件，用文本编辑器打开就可以编辑里面的配置选项。\n\n使用命令，\n\n``` bash\ndoxygen doxygen_filename\n```\n\n就可以生成注释文档了。\n\n下面就来说一说对中文的支持。\n\n## 生成 HTML 格式文档\n\n中文之所以乱码，很多时候是由于编码和译码格式不同，所以我们需要先知道自己代码文件的编码方式。我的代码都是建立在Visual Studio上的，可以通过VS的高级保存选项查看自己代码文件的存储编码格式。对于中文版的VS，一般应该是GB2312。\n\n我们打开 Doxygen 的配置文件，将里面的 INPUT_ENCODING 改为我们代码文件的编码格式，这里就改成 GB2312。\n\n这样一来，编译出来的 HTML 页面就不会有中文乱码了。\n\n## 生成Latex 格式文档\n\n生成 Latex 需要本机上安装有 Latex 的编译环境。如果是中文用户，推荐的是CTEX套件，可以到他们的网站上去下载。\n\n可以看到，Doxygen为Latex文件的编译生成了make文件，我们在命令行窗口中执行make命令就可以完成编译，然而这时候会发现编译出错，pdf文档无法生成。\n\n打开生成的refman.latex文档，添加宏包 CJKutf8。然后找到 `\\begin{document}`一行，将其改为\n\n``` latex\n\\begin{document}\n\\begin{CJK}{UTF8}{gbsn} \n```\n\n也就是说为正文提供了CJK环境，这样中文文本就可以正常编译了。\n\n相应的，我们要将结尾的 `\\end{document)`改为：\n``` latex\n\\end{CJK} \n\\end{document}\n```\n\n这样，运行make命令之后，就可以看到中文的注释文档了。\n","slug":"use-doxygen","published":1,"updated":"2017-02-01T15:10:29.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciyof8h19000dcq1hm83b3os1","content":"<p>Doxygen 是一种很好用的代码注释生成工具，然而和很多国外的工具软件一样，在中文环境下，它的使用总是会出现一些问题，也就是中文注释文档出现乱码。经过调试，终于是解决了这个问题。</p>\n<h2 id=\"安装-Doxygen\"><a href=\"#安装-Doxygen\" class=\"headerlink\" title=\"安装 Doxygen\"></a>安装 Doxygen</h2><p>Doxygen 在Windows平台下的安装是简单的，<a href=\"http://www.doxygen.nl/\" target=\"_blank\" rel=\"external\">Doxygen的项目主页</a>提供了下载和安装的使用说明，可以下载它们的官方使用手册进行阅读。对于Windows，提供了源代码编译安装和直接安装程序安装两种方式，可以自行选择。</p>\n<p>安装成功后，使用命令行命令</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">doxygen --help</div></pre></td></tr></table></figure>\n<p>就可以查看帮助文档，对应参数含义一目了然，降低了入手难度。</p>\n<p>使用命令，</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">doxygen -g doxygen_filename</div></pre></td></tr></table></figure>\n<p>就可以在当前目录下建立一个doxygen配置文件，用文本编辑器打开就可以编辑里面的配置选项。</p>\n<p>使用命令，</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">doxygen doxygen_filename</div></pre></td></tr></table></figure>\n<p>就可以生成注释文档了。</p>\n<p>下面就来说一说对中文的支持。</p>\n<h2 id=\"生成-HTML-格式文档\"><a href=\"#生成-HTML-格式文档\" class=\"headerlink\" title=\"生成 HTML 格式文档\"></a>生成 HTML 格式文档</h2><p>中文之所以乱码，很多时候是由于编码和译码格式不同，所以我们需要先知道自己代码文件的编码方式。我的代码都是建立在Visual Studio上的，可以通过VS的高级保存选项查看自己代码文件的存储编码格式。对于中文版的VS，一般应该是GB2312。</p>\n<p>我们打开 Doxygen 的配置文件，将里面的 INPUT_ENCODING 改为我们代码文件的编码格式，这里就改成 GB2312。</p>\n<p>这样一来，编译出来的 HTML 页面就不会有中文乱码了。</p>\n<h2 id=\"生成Latex-格式文档\"><a href=\"#生成Latex-格式文档\" class=\"headerlink\" title=\"生成Latex 格式文档\"></a>生成Latex 格式文档</h2><p>生成 Latex 需要本机上安装有 Latex 的编译环境。如果是中文用户，推荐的是CTEX套件，可以到他们的网站上去下载。</p>\n<p>可以看到，Doxygen为Latex文件的编译生成了make文件，我们在命令行窗口中执行make命令就可以完成编译，然而这时候会发现编译出错，pdf文档无法生成。</p>\n<p>打开生成的refman.latex文档，添加宏包 CJKutf8。然后找到 <code>\\begin{document}</code>一行，将其改为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">\\begin&#123;document&#125;</div><div class=\"line\">\\begin&#123;CJK&#125;&#123;UTF8&#125;&#123;gbsn&#125;</div></pre></td></tr></table></figure>\n<p>也就是说为正文提供了CJK环境，这样中文文本就可以正常编译了。</p>\n<p>相应的，我们要将结尾的 <code>\\end{document)</code>改为：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">\\end&#123;CJK&#125; </div><div class=\"line\">\\end&#123;document&#125;</div></pre></td></tr></table></figure></p>\n<p>这样，运行make命令之后，就可以看到中文的注释文档了。</p>\n","excerpt":"","more":"<p>Doxygen 是一种很好用的代码注释生成工具，然而和很多国外的工具软件一样，在中文环境下，它的使用总是会出现一些问题，也就是中文注释文档出现乱码。经过调试，终于是解决了这个问题。</p>\n<h2 id=\"安装-Doxygen\"><a href=\"#安装-Doxygen\" class=\"headerlink\" title=\"安装 Doxygen\"></a>安装 Doxygen</h2><p>Doxygen 在Windows平台下的安装是简单的，<a href=\"http://www.doxygen.nl/\">Doxygen的项目主页</a>提供了下载和安装的使用说明，可以下载它们的官方使用手册进行阅读。对于Windows，提供了源代码编译安装和直接安装程序安装两种方式，可以自行选择。</p>\n<p>安装成功后，使用命令行命令</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">doxygen --help</div></pre></td></tr></table></figure>\n<p>就可以查看帮助文档，对应参数含义一目了然，降低了入手难度。</p>\n<p>使用命令，</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">doxygen -g doxygen_filename</div></pre></td></tr></table></figure>\n<p>就可以在当前目录下建立一个doxygen配置文件，用文本编辑器打开就可以编辑里面的配置选项。</p>\n<p>使用命令，</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">doxygen doxygen_filename</div></pre></td></tr></table></figure>\n<p>就可以生成注释文档了。</p>\n<p>下面就来说一说对中文的支持。</p>\n<h2 id=\"生成-HTML-格式文档\"><a href=\"#生成-HTML-格式文档\" class=\"headerlink\" title=\"生成 HTML 格式文档\"></a>生成 HTML 格式文档</h2><p>中文之所以乱码，很多时候是由于编码和译码格式不同，所以我们需要先知道自己代码文件的编码方式。我的代码都是建立在Visual Studio上的，可以通过VS的高级保存选项查看自己代码文件的存储编码格式。对于中文版的VS，一般应该是GB2312。</p>\n<p>我们打开 Doxygen 的配置文件，将里面的 INPUT_ENCODING 改为我们代码文件的编码格式，这里就改成 GB2312。</p>\n<p>这样一来，编译出来的 HTML 页面就不会有中文乱码了。</p>\n<h2 id=\"生成Latex-格式文档\"><a href=\"#生成Latex-格式文档\" class=\"headerlink\" title=\"生成Latex 格式文档\"></a>生成Latex 格式文档</h2><p>生成 Latex 需要本机上安装有 Latex 的编译环境。如果是中文用户，推荐的是CTEX套件，可以到他们的网站上去下载。</p>\n<p>可以看到，Doxygen为Latex文件的编译生成了make文件，我们在命令行窗口中执行make命令就可以完成编译，然而这时候会发现编译出错，pdf文档无法生成。</p>\n<p>打开生成的refman.latex文档，添加宏包 CJKutf8。然后找到 <code>\\begin{document}</code>一行，将其改为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">\\begin&#123;document&#125;</div><div class=\"line\">\\begin&#123;CJK&#125;&#123;UTF8&#125;&#123;gbsn&#125;</div></pre></td></tr></table></figure>\n<p>也就是说为正文提供了CJK环境，这样中文文本就可以正常编译了。</p>\n<p>相应的，我们要将结尾的 <code>\\end{document)</code>改为：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">\\end&#123;CJK&#125; </div><div class=\"line\">\\end&#123;document&#125;</div></pre></td></tr></table></figure></p>\n<p>这样，运行make命令之后，就可以看到中文的注释文档了。</p>\n"},{"title":"Python Regular Expressions （Python 正则表达式)","date":"2014-07-17T11:00:00.000Z","_content":"\n本文来自于Google Developers中对于Python的介绍。[https://developers.google.com/edu/python/regular-expressions](https://developers.google.com/edu/python/regular-expressions \"Google Python Class, Regular Expression\")。\n\n\n\n## 认识正则表达式 ##\n\nPython的正则表达式是使用 **re 模块**的。\n\n\n``` py    \n    match = re.search(pattern,str)\n    if match:\n    \tprint 'found',match.group()\n    else:\n        print 'NOT Found!'\n        \n```\n\n## 正则表达式的规则 ##\n\n### 基本规则 ###\n- a, x, 9 都是普通字符 (ordinary characters)\n- . (一个点)可以匹配任何单个字符（除了'\\n'）\n- \\w（小写的w）可以匹配一个单词里面的字母，数字或下划线 [a-zA-Z0-9_];\\W （大写的W）可以匹配非单词里的这些元素\n- \\b 匹配单词与非单词的分界\n- \\s（小写的s）匹配一个 whitespace character，包括 space，newline，return，tab，form(\\n\\r\\t\\f)；\\S（大写的S）匹配一个非 whitespace character\n- \\d 匹配十进制数字 [0-9]\n- ^=start，$=end 用来匹配字符串的开始和结束\n- \\ 是转义字符，用 \\. 来匹配串里的'.'，等\n### 一些基本的例子 ###\n\n``` py\n    ## 在字符串'piiig'中查找'iii'\n    match = re.search(r'iii', 'piiig')  # found, match.group() == \"iii\"\n    match = re.search(r'igs', 'piiig')  #  not found, match == None\n\n    ## . 匹配除了\\n的任意字符\n    match = re.search(r'..g', 'piiig')  #  found, match.group() == \"iig\"\n\n    ## \\d 匹配0-9的数字字符, \\w 匹配单词里的字符\n    match = re.search(r'\\d\\d\\d', 'p123g') #  found, match.group() == \"123\"\n    match = re.search(r'\\w\\w\\w', '@@abcd!!') #  found, match.group() == \"abc\"   \n```\n\n### 重复 ###\n可以用'+' '*' '?'来匹配0个，1个或多个重复字符。\n\n- '+' 用来匹配1个或者多个字符\n- '*' 用来匹配0个或者多个字符\n- '?' 用来匹配0个或1个字符\n\n注意，'+'和'*'会匹配尽可能多的字符。\n\n### 一些重复字符的例子 ###\n\n``` py\n    ## i+  匹配1个或者多个'i'\n    match = re.search(r'pi+', 'piiig') #  found, match.group() == \"piii\"\n\n    ## 找到字符串中最左边尽可能长的模式。\n    ## 注意，并没有匹配到第二个 'i+'\n    match = re.search(r'i+', 'piigiiii')  #  found, match.group() == \"ii\"\n\n    ## \\s*  匹配0个或1个空白字符 whitespace\n    match = re.search(r'\\d\\s*\\d\\s*\\d', 'xx1 2   3xx')  #  found, match.group() == \"1 2   3\"\n    match = re.search(r'\\d\\s*\\d\\s*\\d', 'xx12  3xx')    #  found, match.group() == \"12  3\"\n    match = re.search(r'\\d\\s*\\d\\s*\\d', 'xx123xx')      # found, match.group() == \"123\"\n\n    ## ^ 匹配字符串的第一个字符\n    match = re.search(r'^b\\w+', 'foobar')  # not found, match == None\n    ## 与上例对比\n    match = re.search(r'b\\w+', 'foobar')   # found, match.group() == \"bar\"\n```\n\n### Email ###\n考虑一个典型的Email地址：someone@host.com，可以用如下的方式匹配：\n\n``` py\n    match = re.search(r'\\w+@\\w+',str)\n```    \n\n但是，对于这种Email地址 'xyz alice-b@google.com purple monkey' 则不能奏效。\n\n### 使用方括号 ###\n方括号里面的字符表示一个字符集合。[abc]可以被用来匹配'a'或者'b'或者'c'。\\w \\s等都可以用在方括号里，除了'.'以外，它只能用来表示字面意义上的‘点’。所以上面的Email规则可以扩充如下：\n    \n``` py\n    match = re.search('r[\\w.-]+@[\\w.-]+',str)\n```\n\n你还可以使用'-'来指定范围，如[a-z]指示的是所有小写字母的集合。所以如果你想构造的字符集合中有'-'，请把它放到末尾[ab-]。另外，前方加上'^'，用来表示取集合的补集，例如[^ab]表示除了'a'和'b'之外的其他字符。\n\n## 操作 ##\n以Email地址为例，如果我们想要分别提取该地址的用户名'someone'和主机名'host.com'该怎么办呢？\n可以在模式中用圆括号指定。\n\n``` py\n    str = 'purple alice-b@google.com monkey dishwasher'\n    match = re.search('([\\w.-]+)@([\\w.-]+)', str)   #用圆括号指定分割\n    if match:\n        print match.group()   ## 'alice-b@google.com' (the whole match)\n        print match.group(1)  ## 'alice-b' (the username, group 1)\n      \tprint match.group(2)  ## 'google.com' (the host, group 2)\n```\n\n### findall 函数\n与group函数只找到最左端的一个匹配不同，findall函数找到字符串中所有与模式匹配的串。\n\n``` py\n    str = 'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'\n    ## findall返回一个包含所有匹配结果的 list\n    emails = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', str) ## ['alice@google.com', 'bob@abc.com']\n    for email in emails:\n        print email\n```\n\n### 在文件中使用findall\n当然可以读入文件的每一行，然后对每一行的内容调用findall，但是为什么不让这一切自动发生呢？\n\n``` py\n\tf = open(filename.txt,'r')\n\tmatches = re.findall(pattern,f.read())\n```\n\n### findall 和分组\n和group的用法相似，也可以指定分组。\n\n``` py\n    str = 'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'\n    ##　返回了一个list\n    tuples = re.findall(r'([\\w\\.-]+)@([\\w\\.-]+)', str)\n    print tuples  ## [('alice', 'google.com'), ('bob', 'abc.com')]\n    ##　list中的元素是tuple \n    for tuple in tuples:\n      print tuple[0]  ## username\n      print tuple[1]  ## host\n```\n\n## 调试 ##\n\n正则表达式异常强大，使用简单的几条规则就可以演变出很多的模式组合。在确定你的模式之前，可能需要很多的调试工作。在一个小的测试集合上测试正则表达式。\n\n## 其他选项\n\n正则表达式还可以设置“选项”。\n\n``` py\n    match = re.search(pat,str,opt)\n```\n\n这些可选项如下：\n\n- IGNORECASE  忽视大小写\n- DOTALL  允许'.'匹配'\\n'\n- MULTILINE  在一个由许多行组成的字符串中，允许'^'和'$'匹配每一行的开始和结束\n","source":"_posts/python-reg-exp.md","raw":"---\ntitle: Python Regular Expressions （Python 正则表达式)\ndate: 2014-07-17 19:00:00\ntags: \n    - python\n---\n\n本文来自于Google Developers中对于Python的介绍。[https://developers.google.com/edu/python/regular-expressions](https://developers.google.com/edu/python/regular-expressions \"Google Python Class, Regular Expression\")。\n\n\n\n## 认识正则表达式 ##\n\nPython的正则表达式是使用 **re 模块**的。\n\n\n``` py    \n    match = re.search(pattern,str)\n    if match:\n    \tprint 'found',match.group()\n    else:\n        print 'NOT Found!'\n        \n```\n\n## 正则表达式的规则 ##\n\n### 基本规则 ###\n- a, x, 9 都是普通字符 (ordinary characters)\n- . (一个点)可以匹配任何单个字符（除了'\\n'）\n- \\w（小写的w）可以匹配一个单词里面的字母，数字或下划线 [a-zA-Z0-9_];\\W （大写的W）可以匹配非单词里的这些元素\n- \\b 匹配单词与非单词的分界\n- \\s（小写的s）匹配一个 whitespace character，包括 space，newline，return，tab，form(\\n\\r\\t\\f)；\\S（大写的S）匹配一个非 whitespace character\n- \\d 匹配十进制数字 [0-9]\n- ^=start，$=end 用来匹配字符串的开始和结束\n- \\ 是转义字符，用 \\. 来匹配串里的'.'，等\n### 一些基本的例子 ###\n\n``` py\n    ## 在字符串'piiig'中查找'iii'\n    match = re.search(r'iii', 'piiig')  # found, match.group() == \"iii\"\n    match = re.search(r'igs', 'piiig')  #  not found, match == None\n\n    ## . 匹配除了\\n的任意字符\n    match = re.search(r'..g', 'piiig')  #  found, match.group() == \"iig\"\n\n    ## \\d 匹配0-9的数字字符, \\w 匹配单词里的字符\n    match = re.search(r'\\d\\d\\d', 'p123g') #  found, match.group() == \"123\"\n    match = re.search(r'\\w\\w\\w', '@@abcd!!') #  found, match.group() == \"abc\"   \n```\n\n### 重复 ###\n可以用'+' '*' '?'来匹配0个，1个或多个重复字符。\n\n- '+' 用来匹配1个或者多个字符\n- '*' 用来匹配0个或者多个字符\n- '?' 用来匹配0个或1个字符\n\n注意，'+'和'*'会匹配尽可能多的字符。\n\n### 一些重复字符的例子 ###\n\n``` py\n    ## i+  匹配1个或者多个'i'\n    match = re.search(r'pi+', 'piiig') #  found, match.group() == \"piii\"\n\n    ## 找到字符串中最左边尽可能长的模式。\n    ## 注意，并没有匹配到第二个 'i+'\n    match = re.search(r'i+', 'piigiiii')  #  found, match.group() == \"ii\"\n\n    ## \\s*  匹配0个或1个空白字符 whitespace\n    match = re.search(r'\\d\\s*\\d\\s*\\d', 'xx1 2   3xx')  #  found, match.group() == \"1 2   3\"\n    match = re.search(r'\\d\\s*\\d\\s*\\d', 'xx12  3xx')    #  found, match.group() == \"12  3\"\n    match = re.search(r'\\d\\s*\\d\\s*\\d', 'xx123xx')      # found, match.group() == \"123\"\n\n    ## ^ 匹配字符串的第一个字符\n    match = re.search(r'^b\\w+', 'foobar')  # not found, match == None\n    ## 与上例对比\n    match = re.search(r'b\\w+', 'foobar')   # found, match.group() == \"bar\"\n```\n\n### Email ###\n考虑一个典型的Email地址：someone@host.com，可以用如下的方式匹配：\n\n``` py\n    match = re.search(r'\\w+@\\w+',str)\n```    \n\n但是，对于这种Email地址 'xyz alice-b@google.com purple monkey' 则不能奏效。\n\n### 使用方括号 ###\n方括号里面的字符表示一个字符集合。[abc]可以被用来匹配'a'或者'b'或者'c'。\\w \\s等都可以用在方括号里，除了'.'以外，它只能用来表示字面意义上的‘点’。所以上面的Email规则可以扩充如下：\n    \n``` py\n    match = re.search('r[\\w.-]+@[\\w.-]+',str)\n```\n\n你还可以使用'-'来指定范围，如[a-z]指示的是所有小写字母的集合。所以如果你想构造的字符集合中有'-'，请把它放到末尾[ab-]。另外，前方加上'^'，用来表示取集合的补集，例如[^ab]表示除了'a'和'b'之外的其他字符。\n\n## 操作 ##\n以Email地址为例，如果我们想要分别提取该地址的用户名'someone'和主机名'host.com'该怎么办呢？\n可以在模式中用圆括号指定。\n\n``` py\n    str = 'purple alice-b@google.com monkey dishwasher'\n    match = re.search('([\\w.-]+)@([\\w.-]+)', str)   #用圆括号指定分割\n    if match:\n        print match.group()   ## 'alice-b@google.com' (the whole match)\n        print match.group(1)  ## 'alice-b' (the username, group 1)\n      \tprint match.group(2)  ## 'google.com' (the host, group 2)\n```\n\n### findall 函数\n与group函数只找到最左端的一个匹配不同，findall函数找到字符串中所有与模式匹配的串。\n\n``` py\n    str = 'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'\n    ## findall返回一个包含所有匹配结果的 list\n    emails = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', str) ## ['alice@google.com', 'bob@abc.com']\n    for email in emails:\n        print email\n```\n\n### 在文件中使用findall\n当然可以读入文件的每一行，然后对每一行的内容调用findall，但是为什么不让这一切自动发生呢？\n\n``` py\n\tf = open(filename.txt,'r')\n\tmatches = re.findall(pattern,f.read())\n```\n\n### findall 和分组\n和group的用法相似，也可以指定分组。\n\n``` py\n    str = 'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'\n    ##　返回了一个list\n    tuples = re.findall(r'([\\w\\.-]+)@([\\w\\.-]+)', str)\n    print tuples  ## [('alice', 'google.com'), ('bob', 'abc.com')]\n    ##　list中的元素是tuple \n    for tuple in tuples:\n      print tuple[0]  ## username\n      print tuple[1]  ## host\n```\n\n## 调试 ##\n\n正则表达式异常强大，使用简单的几条规则就可以演变出很多的模式组合。在确定你的模式之前，可能需要很多的调试工作。在一个小的测试集合上测试正则表达式。\n\n## 其他选项\n\n正则表达式还可以设置“选项”。\n\n``` py\n    match = re.search(pat,str,opt)\n```\n\n这些可选项如下：\n\n- IGNORECASE  忽视大小写\n- DOTALL  允许'.'匹配'\\n'\n- MULTILINE  在一个由许多行组成的字符串中，允许'^'和'$'匹配每一行的开始和结束\n","slug":"python-reg-exp","published":1,"updated":"2017-02-01T15:10:29.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciyof8h1c000gcq1hn81xmnua","content":"<p>本文来自于Google Developers中对于Python的介绍。<a href=\"https://developers.google.com/edu/python/regular-expressions\" title=\"Google Python Class, Regular Expression\" target=\"_blank\" rel=\"external\">https://developers.google.com/edu/python/regular-expressions</a>。</p>\n<h2 id=\"认识正则表达式\"><a href=\"#认识正则表达式\" class=\"headerlink\" title=\"认识正则表达式\"></a>认识正则表达式</h2><p>Python的正则表达式是使用 <strong>re 模块</strong>的。</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">match = re.search(pattern,str)</div><div class=\"line\"><span class=\"keyword\">if</span> match:</div><div class=\"line\">\t<span class=\"keyword\">print</span> <span class=\"string\">'found'</span>,match.group()</div><div class=\"line\"><span class=\"keyword\">else</span>:</div><div class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'NOT Found!'</span></div></pre></td></tr></table></figure>\n<h2 id=\"正则表达式的规则\"><a href=\"#正则表达式的规则\" class=\"headerlink\" title=\"正则表达式的规则\"></a>正则表达式的规则</h2><h3 id=\"基本规则\"><a href=\"#基本规则\" class=\"headerlink\" title=\"基本规则\"></a>基本规则</h3><ul>\n<li>a, x, 9 都是普通字符 (ordinary characters)</li>\n<li>. (一个点)可以匹配任何单个字符（除了’\\n’）</li>\n<li>\\w（小写的w）可以匹配一个单词里面的字母，数字或下划线 [a-zA-Z0-9_];\\W （大写的W）可以匹配非单词里的这些元素</li>\n<li>\\b 匹配单词与非单词的分界</li>\n<li>\\s（小写的s）匹配一个 whitespace character，包括 space，newline，return，tab，form(\\n\\r\\t\\f)；\\S（大写的S）匹配一个非 whitespace character</li>\n<li>\\d 匹配十进制数字 [0-9]</li>\n<li>^=start，$=end 用来匹配字符串的开始和结束</li>\n<li>\\ 是转义字符，用 . 来匹配串里的’.’，等<h3 id=\"一些基本的例子\"><a href=\"#一些基本的例子\" class=\"headerlink\" title=\"一些基本的例子\"></a>一些基本的例子</h3></li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">## 在字符串'piiig'中查找'iii'</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'iii'</span>, <span class=\"string\">'piiig'</span>)  <span class=\"comment\"># found, match.group() == \"iii\"</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'igs'</span>, <span class=\"string\">'piiig'</span>)  <span class=\"comment\">#  not found, match == None</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## . 匹配除了\\n的任意字符</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'..g'</span>, <span class=\"string\">'piiig'</span>)  <span class=\"comment\">#  found, match.group() == \"iig\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## \\d 匹配0-9的数字字符, \\w 匹配单词里的字符</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'\\d\\d\\d'</span>, <span class=\"string\">'p123g'</span>) <span class=\"comment\">#  found, match.group() == \"123\"</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'\\w\\w\\w'</span>, <span class=\"string\">'@@abcd!!'</span>) <span class=\"comment\">#  found, match.group() == \"abc\"</span></div></pre></td></tr></table></figure>\n<h3 id=\"重复\"><a href=\"#重复\" class=\"headerlink\" title=\"重复\"></a>重复</h3><p>可以用’+’ ‘*’ ‘?’来匹配0个，1个或多个重复字符。</p>\n<ul>\n<li>‘+’ 用来匹配1个或者多个字符</li>\n<li>‘*’ 用来匹配0个或者多个字符</li>\n<li>‘?’ 用来匹配0个或1个字符</li>\n</ul>\n<p>注意，’+’和’*’会匹配尽可能多的字符。</p>\n<h3 id=\"一些重复字符的例子\"><a href=\"#一些重复字符的例子\" class=\"headerlink\" title=\"一些重复字符的例子\"></a>一些重复字符的例子</h3><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">## i+  匹配1个或者多个'i'</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'pi+'</span>, <span class=\"string\">'piiig'</span>) <span class=\"comment\">#  found, match.group() == \"piii\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## 找到字符串中最左边尽可能长的模式。</span></div><div class=\"line\"><span class=\"comment\">## 注意，并没有匹配到第二个 'i+'</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'i+'</span>, <span class=\"string\">'piigiiii'</span>)  <span class=\"comment\">#  found, match.group() == \"ii\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## \\s*  匹配0个或1个空白字符 whitespace</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'\\d\\s*\\d\\s*\\d'</span>, <span class=\"string\">'xx1 2   3xx'</span>)  <span class=\"comment\">#  found, match.group() == \"1 2   3\"</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'\\d\\s*\\d\\s*\\d'</span>, <span class=\"string\">'xx12  3xx'</span>)    <span class=\"comment\">#  found, match.group() == \"12  3\"</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'\\d\\s*\\d\\s*\\d'</span>, <span class=\"string\">'xx123xx'</span>)      <span class=\"comment\"># found, match.group() == \"123\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## ^ 匹配字符串的第一个字符</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'^b\\w+'</span>, <span class=\"string\">'foobar'</span>)  <span class=\"comment\"># not found, match == None</span></div><div class=\"line\"><span class=\"comment\">## 与上例对比</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'b\\w+'</span>, <span class=\"string\">'foobar'</span>)   <span class=\"comment\"># found, match.group() == \"bar\"</span></div></pre></td></tr></table></figure>\n<h3 id=\"Email\"><a href=\"#Email\" class=\"headerlink\" title=\"Email\"></a>Email</h3><p>考虑一个典型的Email地址：someone@host.com，可以用如下的方式匹配：</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">    match = re.search(<span class=\"string\">r'\\w+@\\w+'</span>,str)</div><div class=\"line\">```    </div><div class=\"line\"></div><div class=\"line\">但是，对于这种Email地址 <span class=\"string\">'xyz alice-b@google.com purple monkey'</span> 则不能奏效。</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">### 使用方括号 ###</span></div><div class=\"line\">方括号里面的字符表示一个字符集合。[abc]可以被用来匹配<span class=\"string\">'a'</span>或者<span class=\"string\">'b'</span>或者<span class=\"string\">'c'</span>。\\w \\s等都可以用在方括号里，除了<span class=\"string\">'.'</span>以外，它只能用来表示字面意义上的‘点’。所以上面的Email规则可以扩充如下：</div><div class=\"line\">    </div><div class=\"line\">``` py</div><div class=\"line\">    match = re.search(<span class=\"string\">'r[\\w.-]+@[\\w.-]+'</span>,str)</div></pre></td></tr></table></figure>\n<p>你还可以使用’-‘来指定范围，如[a-z]指示的是所有小写字母的集合。所以如果你想构造的字符集合中有’-‘，请把它放到末尾[ab-]。另外，前方加上’^’，用来表示取集合的补集，例如<sup><a href=\"#fn_ab\" id=\"reffn_ab\">ab</a></sup>表示除了’a’和’b’之外的其他字符。</p>\n<h2 id=\"操作\"><a href=\"#操作\" class=\"headerlink\" title=\"操作\"></a>操作</h2><p>以Email地址为例，如果我们想要分别提取该地址的用户名’someone’和主机名’host.com’该怎么办呢？<br>可以在模式中用圆括号指定。</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">str = <span class=\"string\">'purple alice-b@google.com monkey dishwasher'</span></div><div class=\"line\">match = re.search(<span class=\"string\">'([\\w.-]+)@([\\w.-]+)'</span>, str)   <span class=\"comment\">#用圆括号指定分割</span></div><div class=\"line\"><span class=\"keyword\">if</span> match:</div><div class=\"line\">    <span class=\"keyword\">print</span> match.group()   <span class=\"comment\">## 'alice-b@google.com' (the whole match)</span></div><div class=\"line\">    <span class=\"keyword\">print</span> match.group(<span class=\"number\">1</span>)  <span class=\"comment\">## 'alice-b' (the username, group 1)</span></div><div class=\"line\">  \t<span class=\"keyword\">print</span> match.group(<span class=\"number\">2</span>)  <span class=\"comment\">## 'google.com' (the host, group 2)</span></div></pre></td></tr></table></figure>\n<h3 id=\"findall-函数\"><a href=\"#findall-函数\" class=\"headerlink\" title=\"findall 函数\"></a>findall 函数</h3><p>与group函数只找到最左端的一个匹配不同，findall函数找到字符串中所有与模式匹配的串。</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">str = <span class=\"string\">'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'</span></div><div class=\"line\"><span class=\"comment\">## findall返回一个包含所有匹配结果的 list</span></div><div class=\"line\">emails = re.findall(<span class=\"string\">r'[\\w\\.-]+@[\\w\\.-]+'</span>, str) <span class=\"comment\">## ['alice@google.com', 'bob@abc.com']</span></div><div class=\"line\"><span class=\"keyword\">for</span> email <span class=\"keyword\">in</span> emails:</div><div class=\"line\">    <span class=\"keyword\">print</span> email</div></pre></td></tr></table></figure>\n<h3 id=\"在文件中使用findall\"><a href=\"#在文件中使用findall\" class=\"headerlink\" title=\"在文件中使用findall\"></a>在文件中使用findall</h3><p>当然可以读入文件的每一行，然后对每一行的内容调用findall，但是为什么不让这一切自动发生呢？</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">f = open(filename.txt,<span class=\"string\">'r'</span>)</div><div class=\"line\">matches = re.findall(pattern,f.read())</div></pre></td></tr></table></figure>\n<h3 id=\"findall-和分组\"><a href=\"#findall-和分组\" class=\"headerlink\" title=\"findall 和分组\"></a>findall 和分组</h3><p>和group的用法相似，也可以指定分组。</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">str = <span class=\"string\">'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'</span></div><div class=\"line\"><span class=\"comment\">##　返回了一个list</span></div><div class=\"line\">tuples = re.findall(<span class=\"string\">r'([\\w\\.-]+)@([\\w\\.-]+)'</span>, str)</div><div class=\"line\"><span class=\"keyword\">print</span> tuples  <span class=\"comment\">## [('alice', 'google.com'), ('bob', 'abc.com')]</span></div><div class=\"line\"><span class=\"comment\">##　list中的元素是tuple </span></div><div class=\"line\"><span class=\"keyword\">for</span> tuple <span class=\"keyword\">in</span> tuples:</div><div class=\"line\">  <span class=\"keyword\">print</span> tuple[<span class=\"number\">0</span>]  <span class=\"comment\">## username</span></div><div class=\"line\">  <span class=\"keyword\">print</span> tuple[<span class=\"number\">1</span>]  <span class=\"comment\">## host</span></div></pre></td></tr></table></figure>\n<h2 id=\"调试\"><a href=\"#调试\" class=\"headerlink\" title=\"调试\"></a>调试</h2><p>正则表达式异常强大，使用简单的几条规则就可以演变出很多的模式组合。在确定你的模式之前，可能需要很多的调试工作。在一个小的测试集合上测试正则表达式。</p>\n<h2 id=\"其他选项\"><a href=\"#其他选项\" class=\"headerlink\" title=\"其他选项\"></a>其他选项</h2><p>正则表达式还可以设置“选项”。</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">match = re.search(pat,str,opt)</div></pre></td></tr></table></figure>\n<p>这些可选项如下：</p>\n<ul>\n<li>IGNORECASE  忽视大小写</li>\n<li>DOTALL  允许’.’匹配’\\n’</li>\n<li>MULTILINE  在一个由许多行组成的字符串中，允许’^’和’$’匹配每一行的开始和结束</li>\n</ul>\n","excerpt":"","more":"<p>本文来自于Google Developers中对于Python的介绍。<a href=\"https://developers.google.com/edu/python/regular-expressions\" title=\"Google Python Class, Regular Expression\">https://developers.google.com/edu/python/regular-expressions</a>。</p>\n<h2 id=\"认识正则表达式\"><a href=\"#认识正则表达式\" class=\"headerlink\" title=\"认识正则表达式\"></a>认识正则表达式</h2><p>Python的正则表达式是使用 <strong>re 模块</strong>的。</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">match = re.search(pattern,str)</div><div class=\"line\"><span class=\"keyword\">if</span> match:</div><div class=\"line\">\t<span class=\"keyword\">print</span> <span class=\"string\">'found'</span>,match.group()</div><div class=\"line\"><span class=\"keyword\">else</span>:</div><div class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'NOT Found!'</span></div></pre></td></tr></table></figure>\n<h2 id=\"正则表达式的规则\"><a href=\"#正则表达式的规则\" class=\"headerlink\" title=\"正则表达式的规则\"></a>正则表达式的规则</h2><h3 id=\"基本规则\"><a href=\"#基本规则\" class=\"headerlink\" title=\"基本规则\"></a>基本规则</h3><ul>\n<li>a, x, 9 都是普通字符 (ordinary characters)</li>\n<li>. (一个点)可以匹配任何单个字符（除了’\\n’）</li>\n<li>\\w（小写的w）可以匹配一个单词里面的字母，数字或下划线 [a-zA-Z0-9_];\\W （大写的W）可以匹配非单词里的这些元素</li>\n<li>\\b 匹配单词与非单词的分界</li>\n<li>\\s（小写的s）匹配一个 whitespace character，包括 space，newline，return，tab，form(\\n\\r\\t\\f)；\\S（大写的S）匹配一个非 whitespace character</li>\n<li>\\d 匹配十进制数字 [0-9]</li>\n<li>^=start，$=end 用来匹配字符串的开始和结束</li>\n<li>\\ 是转义字符，用 . 来匹配串里的’.’，等<h3 id=\"一些基本的例子\"><a href=\"#一些基本的例子\" class=\"headerlink\" title=\"一些基本的例子\"></a>一些基本的例子</h3></li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">## 在字符串'piiig'中查找'iii'</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'iii'</span>, <span class=\"string\">'piiig'</span>)  <span class=\"comment\"># found, match.group() == \"iii\"</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'igs'</span>, <span class=\"string\">'piiig'</span>)  <span class=\"comment\">#  not found, match == None</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## . 匹配除了\\n的任意字符</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'..g'</span>, <span class=\"string\">'piiig'</span>)  <span class=\"comment\">#  found, match.group() == \"iig\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## \\d 匹配0-9的数字字符, \\w 匹配单词里的字符</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'\\d\\d\\d'</span>, <span class=\"string\">'p123g'</span>) <span class=\"comment\">#  found, match.group() == \"123\"</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'\\w\\w\\w'</span>, <span class=\"string\">'@@abcd!!'</span>) <span class=\"comment\">#  found, match.group() == \"abc\"</span></div></pre></td></tr></table></figure>\n<h3 id=\"重复\"><a href=\"#重复\" class=\"headerlink\" title=\"重复\"></a>重复</h3><p>可以用’+’ ‘*’ ‘?’来匹配0个，1个或多个重复字符。</p>\n<ul>\n<li>‘+’ 用来匹配1个或者多个字符</li>\n<li>‘*’ 用来匹配0个或者多个字符</li>\n<li>‘?’ 用来匹配0个或1个字符</li>\n</ul>\n<p>注意，’+’和’*’会匹配尽可能多的字符。</p>\n<h3 id=\"一些重复字符的例子\"><a href=\"#一些重复字符的例子\" class=\"headerlink\" title=\"一些重复字符的例子\"></a>一些重复字符的例子</h3><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">## i+  匹配1个或者多个'i'</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'pi+'</span>, <span class=\"string\">'piiig'</span>) <span class=\"comment\">#  found, match.group() == \"piii\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## 找到字符串中最左边尽可能长的模式。</span></div><div class=\"line\"><span class=\"comment\">## 注意，并没有匹配到第二个 'i+'</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'i+'</span>, <span class=\"string\">'piigiiii'</span>)  <span class=\"comment\">#  found, match.group() == \"ii\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## \\s*  匹配0个或1个空白字符 whitespace</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'\\d\\s*\\d\\s*\\d'</span>, <span class=\"string\">'xx1 2   3xx'</span>)  <span class=\"comment\">#  found, match.group() == \"1 2   3\"</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'\\d\\s*\\d\\s*\\d'</span>, <span class=\"string\">'xx12  3xx'</span>)    <span class=\"comment\">#  found, match.group() == \"12  3\"</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'\\d\\s*\\d\\s*\\d'</span>, <span class=\"string\">'xx123xx'</span>)      <span class=\"comment\"># found, match.group() == \"123\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## ^ 匹配字符串的第一个字符</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'^b\\w+'</span>, <span class=\"string\">'foobar'</span>)  <span class=\"comment\"># not found, match == None</span></div><div class=\"line\"><span class=\"comment\">## 与上例对比</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'b\\w+'</span>, <span class=\"string\">'foobar'</span>)   <span class=\"comment\"># found, match.group() == \"bar\"</span></div></pre></td></tr></table></figure>\n<h3 id=\"Email\"><a href=\"#Email\" class=\"headerlink\" title=\"Email\"></a>Email</h3><p>考虑一个典型的Email地址：someone@host.com，可以用如下的方式匹配：</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">    match = re.search(<span class=\"string\">r'\\w+@\\w+'</span>,str)</div><div class=\"line\">```    </div><div class=\"line\"></div><div class=\"line\">但是，对于这种Email地址 <span class=\"string\">'xyz alice-b@google.com purple monkey'</span> 则不能奏效。</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">### 使用方括号 ###</span></div><div class=\"line\">方括号里面的字符表示一个字符集合。[abc]可以被用来匹配<span class=\"string\">'a'</span>或者<span class=\"string\">'b'</span>或者<span class=\"string\">'c'</span>。\\w \\s等都可以用在方括号里，除了<span class=\"string\">'.'</span>以外，它只能用来表示字面意义上的‘点’。所以上面的Email规则可以扩充如下：</div><div class=\"line\">    </div><div class=\"line\">``` py</div><div class=\"line\">    match = re.search(<span class=\"string\">'r[\\w.-]+@[\\w.-]+'</span>,str)</div></pre></td></tr></table></figure>\n<p>你还可以使用’-‘来指定范围，如[a-z]指示的是所有小写字母的集合。所以如果你想构造的字符集合中有’-‘，请把它放到末尾[ab-]。另外，前方加上’^’，用来表示取集合的补集，例如<sup><a href=\"#fn_ab\" id=\"reffn_ab\">ab</a></sup>表示除了’a’和’b’之外的其他字符。</p>\n<h2 id=\"操作\"><a href=\"#操作\" class=\"headerlink\" title=\"操作\"></a>操作</h2><p>以Email地址为例，如果我们想要分别提取该地址的用户名’someone’和主机名’host.com’该怎么办呢？<br>可以在模式中用圆括号指定。</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">str = <span class=\"string\">'purple alice-b@google.com monkey dishwasher'</span></div><div class=\"line\">match = re.search(<span class=\"string\">'([\\w.-]+)@([\\w.-]+)'</span>, str)   <span class=\"comment\">#用圆括号指定分割</span></div><div class=\"line\"><span class=\"keyword\">if</span> match:</div><div class=\"line\">    <span class=\"keyword\">print</span> match.group()   <span class=\"comment\">## 'alice-b@google.com' (the whole match)</span></div><div class=\"line\">    <span class=\"keyword\">print</span> match.group(<span class=\"number\">1</span>)  <span class=\"comment\">## 'alice-b' (the username, group 1)</span></div><div class=\"line\">  \t<span class=\"keyword\">print</span> match.group(<span class=\"number\">2</span>)  <span class=\"comment\">## 'google.com' (the host, group 2)</span></div></pre></td></tr></table></figure>\n<h3 id=\"findall-函数\"><a href=\"#findall-函数\" class=\"headerlink\" title=\"findall 函数\"></a>findall 函数</h3><p>与group函数只找到最左端的一个匹配不同，findall函数找到字符串中所有与模式匹配的串。</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">str = <span class=\"string\">'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'</span></div><div class=\"line\"><span class=\"comment\">## findall返回一个包含所有匹配结果的 list</span></div><div class=\"line\">emails = re.findall(<span class=\"string\">r'[\\w\\.-]+@[\\w\\.-]+'</span>, str) <span class=\"comment\">## ['alice@google.com', 'bob@abc.com']</span></div><div class=\"line\"><span class=\"keyword\">for</span> email <span class=\"keyword\">in</span> emails:</div><div class=\"line\">    <span class=\"keyword\">print</span> email</div></pre></td></tr></table></figure>\n<h3 id=\"在文件中使用findall\"><a href=\"#在文件中使用findall\" class=\"headerlink\" title=\"在文件中使用findall\"></a>在文件中使用findall</h3><p>当然可以读入文件的每一行，然后对每一行的内容调用findall，但是为什么不让这一切自动发生呢？</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">f = open(filename.txt,<span class=\"string\">'r'</span>)</div><div class=\"line\">matches = re.findall(pattern,f.read())</div></pre></td></tr></table></figure>\n<h3 id=\"findall-和分组\"><a href=\"#findall-和分组\" class=\"headerlink\" title=\"findall 和分组\"></a>findall 和分组</h3><p>和group的用法相似，也可以指定分组。</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">str = <span class=\"string\">'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'</span></div><div class=\"line\"><span class=\"comment\">##　返回了一个list</span></div><div class=\"line\">tuples = re.findall(<span class=\"string\">r'([\\w\\.-]+)@([\\w\\.-]+)'</span>, str)</div><div class=\"line\"><span class=\"keyword\">print</span> tuples  <span class=\"comment\">## [('alice', 'google.com'), ('bob', 'abc.com')]</span></div><div class=\"line\"><span class=\"comment\">##　list中的元素是tuple </span></div><div class=\"line\"><span class=\"keyword\">for</span> tuple <span class=\"keyword\">in</span> tuples:</div><div class=\"line\">  <span class=\"keyword\">print</span> tuple[<span class=\"number\">0</span>]  <span class=\"comment\">## username</span></div><div class=\"line\">  <span class=\"keyword\">print</span> tuple[<span class=\"number\">1</span>]  <span class=\"comment\">## host</span></div></pre></td></tr></table></figure>\n<h2 id=\"调试\"><a href=\"#调试\" class=\"headerlink\" title=\"调试\"></a>调试</h2><p>正则表达式异常强大，使用简单的几条规则就可以演变出很多的模式组合。在确定你的模式之前，可能需要很多的调试工作。在一个小的测试集合上测试正则表达式。</p>\n<h2 id=\"其他选项\"><a href=\"#其他选项\" class=\"headerlink\" title=\"其他选项\"></a>其他选项</h2><p>正则表达式还可以设置“选项”。</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">match = re.search(pat,str,opt)</div></pre></td></tr></table></figure>\n<p>这些可选项如下：</p>\n<ul>\n<li>IGNORECASE  忽视大小写</li>\n<li>DOTALL  允许’.’匹配’\\n’</li>\n<li>MULTILINE  在一个由许多行组成的字符串中，允许’^’和’$’匹配每一行的开始和结束</li>\n</ul>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"ciyof8h0v0007cq1hb0ygumo9","tag_id":"ciyof8h0g0002cq1hdxa7rf57","_id":"ciyof8h15000acq1hutaoryyk"},{"post_id":"ciyof8h0v0007cq1hb0ygumo9","tag_id":"ciyof8h0u0006cq1hvze4gi5h","_id":"ciyof8h19000ccq1h6sqdanxz"},{"post_id":"ciyof8h060000cq1hyw87e08a","tag_id":"ciyof8h0g0002cq1hdxa7rf57","_id":"ciyof8h1c000fcq1h57c8y3lt"},{"post_id":"ciyof8h060000cq1hyw87e08a","tag_id":"ciyof8h0u0006cq1hvze4gi5h","_id":"ciyof8h1e000hcq1h7utzbyll"},{"post_id":"ciyof8h0c0001cq1hi7obv7j8","tag_id":"ciyof8h0g0002cq1hdxa7rf57","_id":"ciyof8h1f000jcq1habmhhv1g"},{"post_id":"ciyof8h0c0001cq1hi7obv7j8","tag_id":"ciyof8h0u0006cq1hvze4gi5h","_id":"ciyof8h1g000kcq1hgn0jfzb6"},{"post_id":"ciyof8h0j0003cq1hpilis28r","tag_id":"ciyof8h0g0002cq1hdxa7rf57","_id":"ciyof8h1j000ncq1hgkqyo7wh"},{"post_id":"ciyof8h0j0003cq1hpilis28r","tag_id":"ciyof8h0u0006cq1hvze4gi5h","_id":"ciyof8h1k000ocq1hso94abno"},{"post_id":"ciyof8h0n0004cq1hdzl9brfg","tag_id":"ciyof8h0g0002cq1hdxa7rf57","_id":"ciyof8h1n000qcq1h7ux7o87d"},{"post_id":"ciyof8h0n0004cq1hdzl9brfg","tag_id":"ciyof8h0u0006cq1hvze4gi5h","_id":"ciyof8h1p000rcq1h4cny9kg7"},{"post_id":"ciyof8h0u0005cq1h65s3tl67","tag_id":"ciyof8h0g0002cq1hdxa7rf57","_id":"ciyof8h1v000tcq1ha2s95x8y"},{"post_id":"ciyof8h0u0005cq1h65s3tl67","tag_id":"ciyof8h0u0006cq1hvze4gi5h","_id":"ciyof8h1w000ucq1hmc8967t4"},{"post_id":"ciyof8h0x0008cq1hpi4kmgl4","tag_id":"ciyof8h1q000scq1h1bjzoq7z","_id":"ciyof8h1z000xcq1hui4lxmgl"},{"post_id":"ciyof8h0x0008cq1hpi4kmgl4","tag_id":"ciyof8h1w000vcq1hr43e7inu","_id":"ciyof8h1z000ycq1hgdooxh4s"},{"post_id":"ciyof8h19000dcq1hm83b3os1","tag_id":"ciyof8h1q000scq1h1bjzoq7z","_id":"ciyof8h220011cq1hrrze6dil"},{"post_id":"ciyof8h19000dcq1hm83b3os1","tag_id":"ciyof8h1z000zcq1hq5agfg4u","_id":"ciyof8h220012cq1ha29f4lbb"},{"post_id":"ciyof8h1c000gcq1hn81xmnua","tag_id":"ciyof8h210010cq1h16vodm2k","_id":"ciyof8h220013cq1hg479zc0m"}],"Tag":[{"name":"cs131","_id":"ciyof8h0g0002cq1hdxa7rf57"},{"name":"公开课","_id":"ciyof8h0u0006cq1hvze4gi5h"},{"name":"tool","_id":"ciyof8h1q000scq1h1bjzoq7z"},{"name":"gsl","_id":"ciyof8h1w000vcq1hr43e7inu"},{"name":"doxygen","_id":"ciyof8h1z000zcq1hq5agfg4u"},{"name":"python","_id":"ciyof8h210010cq1h16vodm2k"}]}}